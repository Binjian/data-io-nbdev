{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return \"\\n\".join(\n",
    "            self.template.format(a, eval(a)._repr_html_()) for a in self.args\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\\n\".join(a + \"\\n\" + repr(eval(a)) for a in self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 5, 3, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a\n",
    "\n",
    "b = a.flatten()\n",
    "b\n",
    "c = a.flatten(\"F\")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ordered_set import OrderedSet\n",
    "from tspace.config.drivers import drivers\n",
    "from tspace.config.vehicles import trucks_by_id\n",
    "from tspace.config.drivers import drivers_by_id\n",
    "\n",
    "# DriverSet = OrderedSet(\n",
    "#     [\n",
    "#         'wang-cheng',\n",
    "#         'li-changlong',\n",
    "#         'chen-hongmei',\n",
    "#         'zheng-longfei',\n",
    "#     ]\n",
    "# )\n",
    "# DriverSet[0]\n",
    "# DriverSet.get_loc('wang-cheng')\n",
    "# DriverSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/zg00xvpj2597p3wtxcmy_c100000gp/T/ipykernel_43444/1885882896.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  ts_ind = ts + pd.to_timedelta(np.arange(2), \"H\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-06-25 16:45:58.982114', '2024-06-25 17:45:58.982114'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-25 16:45:58.982114</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-25 17:45:58.982114</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            c1  c2  c3\n",
       "2024-06-25 16:45:58.982114   1   2   3\n",
       "2024-06-25 17:45:58.982114   4   5   6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-06-25 16:45:58.982114')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "ts = pd.to_datetime(datetime.now())\n",
    "ts_ind = ts + pd.to_timedelta(np.arange(2), \"H\")\n",
    "ts_ind\n",
    "df = pd.DataFrame(a, index=ts_ind, columns=[\"c1\", \"c2\", \"c3\"])\n",
    "df\n",
    "df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-06-25 16:45:58.982114')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-06-25 16:45:58.993386')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:00:00.011272')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:00:00.002818')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-06-25 16:45:58.984932', '2024-06-25 16:45:58.987750',\n",
       "               '2024-06-25 16:45:58.990568', '2024-06-25 16:45:58.993386'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts\n",
    "ts_end = pd.to_datetime(datetime.now())\n",
    "ts_end\n",
    "span = ts_end - ts\n",
    "span\n",
    "span_each_row = span / 4\n",
    "span_each_row\n",
    "np.linspace(0, 4, 5)\n",
    "ts_ser = ts + pd.to_timedelta(np.linspace(1, 4, 4) * span_each_row, unit=\"s\")\n",
    "ts_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp\n",
       "0 2024-06-25 16:45:58.982114"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts = pd.DataFrame(np.array([ts]), columns=[\"timestamp\"])\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.arange(10)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>v</th>\n",
       "      <th>p</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  v   p   b\n",
       "0  0  1   2   3\n",
       "1  4  5   6   7\n",
       "2  8  9  10  11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = np.arange(12)\n",
    "a1 = ss[:4].tolist()\n",
    "a2 = ss[4:8].tolist()\n",
    "a3 = ss[8:].tolist()\n",
    "ss = [a1, a2, a3]\n",
    "ss\n",
    "df_s = pd.DataFrame(ss, columns=[\"t\", \"v\", \"p\", \"b\"])  # .set_index('t')\n",
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 20, 40, 60])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 4 * 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-06-25 16:45:58.982114', '2024-06-25 16:45:59.002114',\n",
       "               '2024-06-25 16:45:59.022114', '2024-06-25 16:45:59.042114'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tuple</th>\n",
       "      <th>timestep</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thrust</th>\n",
       "      <th>brake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-25 16:45:59.002114</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-25 16:45:59.022114</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-25 16:45:59.042114</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tuple                   timestep  velocity  thrust  brake\n",
       "0     2024-06-25 16:45:58.982114         0       4      8\n",
       "1     2024-06-25 16:45:59.002114         1       5      9\n",
       "2     2024-06-25 16:45:59.022114         2       6     10\n",
       "3     2024-06-25 16:45:59.042114         3       7     11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tuple</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thrust</th>\n",
       "      <th>brake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tuple  velocity  thrust  brake\n",
       "0             0       4      8\n",
       "1             1       5      9\n",
       "2             2       6     10\n",
       "3             3       7     11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_ind = ts + pd.to_timedelta(np.arange(0, 4 * 20, 20), \"ms\")\n",
    "ts_ind\n",
    "ss = np.arange(12)\n",
    "a1 = ss[:4]\n",
    "a2 = ss[4:8]\n",
    "a3 = ss[8:]\n",
    "df_ss = pd.DataFrame(\n",
    "    {\"timestep\": ts_ind, \"velocity\": a1, \"thrust\": a2, \"brake\": a3}\n",
    ")  # .set_index('timestep')\n",
    "df_ss.columns.name = \"tuple\"\n",
    "df_ss\n",
    "df_ss[[\"velocity\", \"thrust\", \"brake\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_ss_flatten = df_ss[[\"velocity\", \"thrust\", \"brake\"]].to_numpy().flatten()\n",
    "npa_ss_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tuple</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thrust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tuple  velocity  thrust\n",
       "0             0       4\n",
       "1             1       5\n",
       "2             2       6\n",
       "3             3       7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     5\n",
       "2    12\n",
       "3    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_t = df_ss.loc[:, [\"velocity\", \"thrust\"]]\n",
    "ui_t\n",
    "power_t = ui_t.prod(axis=1)\n",
    "power_t\n",
    "power_t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rows      idx\n",
       "brake     0                               8\n",
       "          1                               9\n",
       "          2                              10\n",
       "          3                              11\n",
       "thrust    0                               4\n",
       "          1                               5\n",
       "          2                               6\n",
       "          3                               7\n",
       "timestep  0      2024-06-25 16:45:58.982114\n",
       "          1      2024-06-25 16:45:59.002114\n",
       "          2      2024-06-25 16:45:59.022114\n",
       "          3      2024-06-25 16:45:59.042114\n",
       "velocity  0                               0\n",
       "          1                               1\n",
       "          2                               2\n",
       "          3                               3\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = df_ss.stack().swaplevel(0, 1)\n",
    "state.name = \"state\"\n",
    "state.index.names = [\"rows\", \"idx\"]\n",
    "state.sort_index(inplace=True)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rows      idx\n",
       "brake     0                               8\n",
       "          1                               9\n",
       "          2                              10\n",
       "          3                              11\n",
       "thrust    0                               4\n",
       "          1                               5\n",
       "          2                               6\n",
       "          3                               7\n",
       "timestep  0      2024-06-25 16:45:58.982114\n",
       "          1      2024-06-25 16:45:59.002114\n",
       "          2      2024-06-25 16:45:59.022114\n",
       "          3      2024-06-25 16:45:59.042114\n",
       "velocity  0                               0\n",
       "          1                               1\n",
       "          2                               2\n",
       "          3                               3\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 10, 11, 4, 5, 6, 7, Timestamp('2024-06-25 16:45:58.982114'),\n",
       "       Timestamp('2024-06-25 16:45:59.002114'),\n",
       "       Timestamp('2024-06-25 16:45:59.022114'),\n",
       "       Timestamp('2024-06-25 16:45:59.042114'), 0, 1, 2, 3], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rows      idx\n",
       "velocity  0       0\n",
       "          1       1\n",
       "          2       2\n",
       "          3       3\n",
       "thrust    0       4\n",
       "          1       5\n",
       "          2       6\n",
       "          3       7\n",
       "brake     0       8\n",
       "          1       9\n",
       "          2      10\n",
       "          3      11\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = pd.IndexSlice\n",
    "state_stripped = state[[\"velocity\", \"thrust\", \"brake\"]]\n",
    "state_stripped\n",
    "state_stripped.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "#\n",
    "#\n",
    "# velocity = pd.Series(ss[:4], name='velocity')\n",
    "# thrust = pd.Series(ss[4:8], name='thrust')\n",
    "# brake = pd.Series(ss[8:], name='brake')\n",
    "# series = [velocity, thrust, brake]\n",
    "# state = reduce(\n",
    "#     lambda x, y: pd.merge(x, y, how='outer', left_index=True, right_index=True), series\n",
    "# )\n",
    "# state = state.stack().swaplevel(0, 1).sort_index()\n",
    "# state.name = 'state'\n",
    "# state\n",
    "# len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "#\n",
    "#\n",
    "# velocity = pd.Series(s[:4], name='velocity')\n",
    "# thrust = pd.Series(s[4:7], name='thrust')\n",
    "# brake = pd.Series(s[7:], name='brake')\n",
    "# series = [velocity, thrust, brake]\n",
    "# state = reduce(\n",
    "#     lambda x, y: pd.merge(x, y, how='outer', left_index=True, right_index=True), series\n",
    "# )\n",
    "# state = state.stack().swaplevel(0, 1).sort_index()\n",
    "# state.name = 'state'\n",
    "# state\n",
    "# len(state)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r0': array([12, 13, 14, 15, 16]),\n",
       " 'r1': array([17, 18, 19, 20, 21]),\n",
       " 'r2': array([22, 23, 24, 25, 26])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[12, 17, 22],\n",
       "       [13, 18, 23],\n",
       "       [14, 19, 24],\n",
       "       [15, 20, 25],\n",
       "       [16, 21, 26]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r0  r1  r2\n",
       "0  12  17  22\n",
       "1  13  18  23\n",
       "2  14  19  24\n",
       "3  15  20  25\n",
       "4  16  21  26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "a = len(ss) + np.arange(15)\n",
    "speed_ser = pd.Series(np.linspace(40, 60, 3), name=\"speed\")\n",
    "# row_ser\n",
    "row_dict = {f\"r{i}\": a[i * 5 : i * 5 + 5] for i in np.arange(3)}\n",
    "row_dict\n",
    "row_array = a.reshape(3, 5).transpose()\n",
    "row_array\n",
    "rows_df = pd.DataFrame(row_array)\n",
    "rows_df.columns = [f\"r{i}\" for i in np.arange(3)]\n",
    "rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(      'r0', 0),\n",
       "            (      'r0', 1),\n",
       "            (      'r0', 2),\n",
       "            (      'r0', 3),\n",
       "            (      'r0', 4),\n",
       "            (      'r1', 0),\n",
       "            (      'r1', 1),\n",
       "            (      'r1', 2),\n",
       "            (      'r1', 3),\n",
       "            (      'r1', 4),\n",
       "            (      'r2', 0),\n",
       "            (      'r2', 1),\n",
       "            (      'r2', 2),\n",
       "            (      'r2', 3),\n",
       "            (      'r2', 4),\n",
       "            (   'speed', 0),\n",
       "            (   'speed', 1),\n",
       "            (   'speed', 2),\n",
       "            ('throttle', 0),\n",
       "            ('throttle', 1),\n",
       "            ('throttle', 2),\n",
       "            ('throttle', 3),\n",
       "            ('throttle', 4),\n",
       "            ('timestep', 0),\n",
       "            ('timestep', 1),\n",
       "            ('timestep', 2)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rows      idx\n",
       "r0        0                              12\n",
       "          1                              13\n",
       "          2                              14\n",
       "          3                              15\n",
       "          4                              16\n",
       "r1        0                              17\n",
       "          1                              18\n",
       "          2                              19\n",
       "          3                              20\n",
       "          4                              21\n",
       "r2        0                              22\n",
       "          1                              23\n",
       "          2                              24\n",
       "          3                              25\n",
       "          4                              26\n",
       "speed     0                            40.0\n",
       "          1                            50.0\n",
       "          2                            60.0\n",
       "throttle  0                             0.0\n",
       "          1                            0.25\n",
       "          2                             0.5\n",
       "          3                            0.75\n",
       "          4                             1.0\n",
       "timestep  0      2024-06-25 16:45:59.082114\n",
       "          1      2024-06-25 16:45:59.102114\n",
       "          2      2024-06-25 16:45:59.122114\n",
       "Name: action, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_ind = ts + pd.to_timedelta(np.arange(5 * 20, 8 * 20, 20), \"ms\")\n",
    "ts_ser = pd.Series(ts_ind, name=\"timestep\")\n",
    "throttle_ser = pd.Series(np.linspace(0, 1.0, 5), name=\"throttle\")\n",
    "# throttle_ser\n",
    "dfs = [rows_df, ts_ser, speed_ser, throttle_ser]\n",
    "action = (\n",
    "    reduce(\n",
    "        lambda left, right: pd.merge(\n",
    "            left, right, how=\"outer\", left_index=True, right_index=True\n",
    "        ),\n",
    "        dfs,\n",
    "    )\n",
    "    .stack()\n",
    "    .swaplevel(0, 1)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "action.name = \"action\"\n",
    "action.index.names = [\"rows\", \"idx\"]\n",
    "action.index\n",
    "action\n",
    "# action = pd.concat([df.DataFrame(row_dict),df.Series(row_ind),df.Series(ts_ind),df.Series(pedal_ind)],axis=1)\n",
    "# action\n",
    "# pedal_ind\n",
    "# action_ind = pd.MultiIndex.from_product([row_ind, ts_ind], names=['row', 'timestamp'])\n",
    "# a\n",
    "# speed_row, row_name = *row_dict\n",
    "# action = (\n",
    "#     pd.DataFrame(\n",
    "#         {\n",
    "#             **row_dict,\n",
    "#             'throttle': pedal_ind,\n",
    "#             'speed': [r[1] for r in row_ind],\n",
    "#         }\n",
    "#     )  # .set_index('pedal')\n",
    "#     # .stack()\n",
    "#     # .swaplevel(0, 1)\n",
    "#     .sort_index()\n",
    "# )\n",
    "# action\n",
    "# action.columns\n",
    "# action.columns = pd.MultiIndex.from_arrays(\n",
    "#     [action.columns, ts_ind], names=['nominalspeed', 'timestep']\n",
    "# )\n",
    "# action = action.stack([0, 1]).swaplevel(0, 1).swaplevel(1, 2).sort_index()\n",
    "# action.name = 'action'\n",
    "# # action.index.names = ['nominalspeed', 'timestamp']\n",
    "# # action.index\n",
    "# action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>timestep</th>\n",
       "      <th>speed</th>\n",
       "      <th>throttle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>2024-06-25 16:45:59.082114</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>2024-06-25 16:45:59.102114</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-06-25 16:45:59.122114</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r0  r1  r2                   timestep  speed  throttle\n",
       "0  12  17  22 2024-06-25 16:45:59.082114   40.0      0.00\n",
       "1  13  18  23 2024-06-25 16:45:59.102114   50.0      0.25\n",
       "2  14  19  24 2024-06-25 16:45:59.122114   60.0      0.50\n",
       "3  15  20  25                        NaT    NaN      0.75\n",
       "4  16  21  26                        NaT    NaN      1.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# action = (\n",
    "#     reduce(\n",
    "#         lambda left, right: pd.merge(\n",
    "#             left, right, how='outer', left_index=True, right_index=True\n",
    "#         ),\n",
    "#         dfs,\n",
    "#     )\n",
    "#     .stack()\n",
    "#     .swaplevel(0, 1)\n",
    "#     .sort_index()\n",
    "# )\n",
    "#\n",
    "# action.name = 'action'\n",
    "# action.index.names = ['rows', 'idx']\n",
    "# action.index\n",
    "# action\n",
    "action1 = reduce(\n",
    "    lambda left, right: pd.merge(\n",
    "        left, right, how=\"outer\", left_index=True, right_index=True\n",
    "    ),\n",
    "    dfs,\n",
    ")\n",
    "action1\n",
    "action2 = action1.stack()\n",
    "type(action2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-06-25 16:45:58.982114')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-06-25 16:45:59.006114', '2024-06-25 16:45:59.030114',\n",
       "               '2024-06-25 16:45:59.054114', '2024-06-25 16:45:59.078114',\n",
       "               '2024-06-25 16:45:59.102114'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0   2024-06-25 16:45:59.006114\n",
       "1   2024-06-25 16:45:59.030114\n",
       "2   2024-06-25 16:45:59.054114\n",
       "3   2024-06-25 16:45:59.078114\n",
       "4   2024-06-25 16:45:59.102114\n",
       "Name: timestep, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts\n",
    "span = (ts_ind[1] - ts) / 5\n",
    "# span\n",
    "timestep = pd.to_datetime(ts + np.linspace(1, 5, 5) * span)\n",
    "timestep\n",
    "timeseries = pd.Series(timestep, name=\"timestep\")\n",
    "timeseries\n",
    "isinstance(timeseries, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = len(state) + np.arange(6)\n",
    "# ar0 = pd.Series(a[:2], name='row0')\n",
    "# ar1 = pd.Series(a[2:4], name='row1')\n",
    "# ar2 = pd.Series(a[4:], name='row2')\n",
    "# series = [ar0, ar1, ar2]\n",
    "# action = reduce(\n",
    "#     lambda x, y: pd.merge(x, y, how='outer', left_index=True, right_index=True), series\n",
    "# )\n",
    "# action = action.stack().swaplevel(0, 1).sort_index()\n",
    "# action.name = 'action'\n",
    "# action\n",
    "# len(action) + len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('timestep', 0),\n",
       "            (    'work', 0)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rows      idx\n",
       "timestep  0      2024-06-25 16:45:59.082114\n",
       "work      0                              27\n",
       "Name: reward, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = (\n",
    "    pd.DataFrame({\"work\": len(ss) + len(a), \"timestep\": ts_ind[0]}, index=[0])\n",
    "    .stack()\n",
    "    .swaplevel(0, 1)\n",
    "    .sort_index()\n",
    ")\n",
    "# reward_index = (reward.name,  ts_ind[0], 0)\n",
    "reward.index.names = [\"rows\", \"idx\"]\n",
    "reward.name = \"reward\"\n",
    "reward.index\n",
    "reward\n",
    "# reward.name = 'reward'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward[\"work\"][0]\n",
    "reward.loc[(\"work\", 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-06-25 16:46:03.982114', '2024-06-25 16:46:04.002114',\n",
       "               '2024-06-25 16:46:04.022114', '2024-06-25 16:46:04.042114'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rows      idx\n",
       "brake     0                              36\n",
       "          1                              37\n",
       "          2                              38\n",
       "          3                              39\n",
       "thrust    0                              32\n",
       "          1                              33\n",
       "          2                              34\n",
       "          3                              35\n",
       "timestep  0      2024-06-25 16:46:03.982114\n",
       "          1      2024-06-25 16:46:04.002114\n",
       "          2      2024-06-25 16:46:04.022114\n",
       "          3      2024-06-25 16:46:04.042114\n",
       "velocity  0                              28\n",
       "          1                              29\n",
       "          2                              30\n",
       "          3                              31\n",
       "Name: nstate, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# velocity = pd.Series(len(state) + len(action) + len(reward) + s[:4], name='velocity')\n",
    "# thrust = pd.Series(len(state) + len(action) + len(reward) + s[4:7], name='thrust')\n",
    "# brake = pd.Series(len(state) + len(action) + len(reward) + s[7:], name='brake')\n",
    "# series = [velocity, thrust, brake]\n",
    "# nstate = reduce(\n",
    "#     lambda x, y: pd.merge(x, y, how='outer', left_index=True, right_index=True), series\n",
    "# )\n",
    "# nstate = nstate.stack().swaplevel(0, 1).sort_index()\n",
    "# nstate.name = 'nstate'\n",
    "# nstate\n",
    "# len(nstate)\n",
    "ts_ind = ts + pd.to_timedelta(5, \"s\") + pd.to_timedelta(np.arange(0, 4 * 20, 20), \"ms\")\n",
    "ts_ind\n",
    "ss = (\n",
    "    np.arange(12) + len(ss) + len(a) + len(reward) - 1\n",
    ")  # exclude the timestamp in reward\n",
    "a1 = ss[:4]\n",
    "a2 = ss[4:8]\n",
    "a3 = ss[8:]\n",
    "nstate = (\n",
    "    pd.DataFrame({\"timestep\": ts_ind, \"velocity\": a1, \"thrust\": a2, \"brake\": a3})\n",
    "    # .set_index('timestamp')\n",
    "    .stack()\n",
    "    .swaplevel(0, 1)\n",
    "    .sort_index()\n",
    ")\n",
    "nstate.name = \"nstate\"\n",
    "nstate.index.names = [\"rows\", \"idx\"]\n",
    "len(nstate)\n",
    "nstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(0, 0)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   'brake', 0),\n",
       "            (   'brake', 1),\n",
       "            (   'brake', 2),\n",
       "            (   'brake', 3),\n",
       "            (  'thrust', 0),\n",
       "            (  'thrust', 1),\n",
       "            (  'thrust', 2),\n",
       "            (  'thrust', 3),\n",
       "            ('timestep', 0),\n",
       "            ('timestep', 1),\n",
       "            ('timestep', 2),\n",
       "            ('timestep', 3),\n",
       "            ('velocity', 0),\n",
       "            ('velocity', 1),\n",
       "            ('velocity', 2),\n",
       "            ('velocity', 3)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([(      'r0', 0),\n",
       "            (      'r0', 1),\n",
       "            (      'r0', 2),\n",
       "            (      'r0', 3),\n",
       "            (      'r0', 4),\n",
       "            (      'r1', 0),\n",
       "            (      'r1', 1),\n",
       "            (      'r1', 2),\n",
       "            (      'r1', 3),\n",
       "            (      'r1', 4),\n",
       "            (      'r2', 0),\n",
       "            (      'r2', 1),\n",
       "            (      'r2', 2),\n",
       "            (      'r2', 3),\n",
       "            (      'r2', 4),\n",
       "            (   'speed', 0),\n",
       "            (   'speed', 1),\n",
       "            (   'speed', 2),\n",
       "            ('throttle', 0),\n",
       "            ('throttle', 1),\n",
       "            ('throttle', 2),\n",
       "            ('throttle', 3),\n",
       "            ('throttle', 4),\n",
       "            ('timestep', 0),\n",
       "            ('timestep', 1),\n",
       "            ('timestep', 2)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('timestep', 0),\n",
       "            (    'work', 0)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   'brake', 0),\n",
       "            (   'brake', 1),\n",
       "            (   'brake', 2),\n",
       "            (   'brake', 3),\n",
       "            (  'thrust', 0),\n",
       "            (  'thrust', 1),\n",
       "            (  'thrust', 2),\n",
       "            (  'thrust', 3),\n",
       "            ('timestep', 0),\n",
       "            ('timestep', 1),\n",
       "            ('timestep', 2),\n",
       "            ('timestep', 3),\n",
       "            ('velocity', 0),\n",
       "            ('velocity', 1),\n",
       "            ('velocity', 2),\n",
       "            ('velocity', 3)],\n",
       "           names=['rows', 'idx'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = pd.Series([ts], name=\"timestamp\")\n",
    "timestamp.index = pd.MultiIndex.from_product(\n",
    "    [timestamp.index, [0]], names=[\"rows\", \"idx\"]\n",
    ")\n",
    "timestamp.index\n",
    "state.index\n",
    "action.index\n",
    "reward.index\n",
    "nstate.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('timestamp',         '', 0),\n",
       "            (    'state',    'brake', 0),\n",
       "            (    'state',    'brake', 1),\n",
       "            (    'state',    'brake', 2),\n",
       "            (    'state',    'brake', 3),\n",
       "            (    'state',   'thrust', 0),\n",
       "            (    'state',   'thrust', 1),\n",
       "            (    'state',   'thrust', 2),\n",
       "            (    'state',   'thrust', 3),\n",
       "            (    'state', 'timestep', 0),\n",
       "            (    'state', 'timestep', 1),\n",
       "            (    'state', 'timestep', 2),\n",
       "            (    'state', 'timestep', 3),\n",
       "            (    'state', 'velocity', 0),\n",
       "            (    'state', 'velocity', 1),\n",
       "            (    'state', 'velocity', 2),\n",
       "            (    'state', 'velocity', 3),\n",
       "            (   'action',       'r0', 0),\n",
       "            (   'action',       'r0', 1),\n",
       "            (   'action',       'r0', 2),\n",
       "            (   'action',       'r0', 3),\n",
       "            (   'action',       'r0', 4),\n",
       "            (   'action',       'r1', 0),\n",
       "            (   'action',       'r1', 1),\n",
       "            (   'action',       'r1', 2),\n",
       "            (   'action',       'r1', 3),\n",
       "            (   'action',       'r1', 4),\n",
       "            (   'action',       'r2', 0),\n",
       "            (   'action',       'r2', 1),\n",
       "            (   'action',       'r2', 2),\n",
       "            (   'action',       'r2', 3),\n",
       "            (   'action',       'r2', 4),\n",
       "            (   'action',    'speed', 0),\n",
       "            (   'action',    'speed', 1),\n",
       "            (   'action',    'speed', 2),\n",
       "            (   'action', 'throttle', 0),\n",
       "            (   'action', 'throttle', 1),\n",
       "            (   'action', 'throttle', 2),\n",
       "            (   'action', 'throttle', 3),\n",
       "            (   'action', 'throttle', 4),\n",
       "            (   'action', 'timestep', 0),\n",
       "            (   'action', 'timestep', 1),\n",
       "            (   'action', 'timestep', 2),\n",
       "            (   'reward', 'timestep', 0),\n",
       "            (   'reward',     'work', 0),\n",
       "            (   'nstate',    'brake', 0),\n",
       "            (   'nstate',    'brake', 1),\n",
       "            (   'nstate',    'brake', 2),\n",
       "            (   'nstate',    'brake', 3),\n",
       "            (   'nstate',   'thrust', 0),\n",
       "            (   'nstate',   'thrust', 1),\n",
       "            (   'nstate',   'thrust', 2),\n",
       "            (   'nstate',   'thrust', 3),\n",
       "            (   'nstate', 'timestep', 0),\n",
       "            (   'nstate', 'timestep', 1),\n",
       "            (   'nstate', 'timestep', 2),\n",
       "            (   'nstate', 'timestep', 3),\n",
       "            (   'nstate', 'velocity', 0),\n",
       "            (   'nstate', 'velocity', 1),\n",
       "            (   'nstate', 'velocity', 2),\n",
       "            (   'nstate', 'velocity', 3)],\n",
       "           )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_index = (timestamp.name, \"\", 0)\n",
    "# timestamp_index\n",
    "state_index = [(state.name, *i) for i in state.index]\n",
    "# state_index\n",
    "reward_index = [(reward.name, *i) for i in reward.index]\n",
    "# reward_index\n",
    "action_index = [(action.name, *i) for i in action.index]\n",
    "# action_index\n",
    "nstate_index = [(nstate.name, *i) for i in nstate.index]\n",
    "# nstate_index\n",
    "\n",
    "multiindex = pd.MultiIndex.from_tuples(\n",
    "    [timestamp_index, *state_index, *action_index, *reward_index, *nstate_index]\n",
    ")\n",
    "multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp            0    2024-06-25 16:45:58.982114\n",
       "state      brake     0                             8\n",
       "                     1                             9\n",
       "                     2                            10\n",
       "                     3                            11\n",
       "                                     ...            \n",
       "nstate     timestep  3    2024-06-25 16:46:04.042114\n",
       "           velocity  0                            28\n",
       "                     1                            29\n",
       "                     2                            30\n",
       "                     3                            31\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_list = [timestamp, state, action, reward, nstate]\n",
    "observation = pd.concat(observation_list)\n",
    "observation.index = multiindex\n",
    "observation\n",
    "observation.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "timestamp            0    2024-06-25 16:45:58.982114\n",
       "state      brake     0                             8\n",
       "                     1                             9\n",
       "                     2                            10\n",
       "                     3                            11\n",
       "                                     ...            \n",
       "nstate     timestep  3    2024-06-25 16:46:04.042114\n",
       "           velocity  0                            28\n",
       "                     1                            29\n",
       "                     2                            30\n",
       "                     3                            31\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(observation)\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation0 = observation.copy()\n",
    "observation0.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(1, \"h\")\n",
    "observation1 = observation.copy()\n",
    "observation1.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(2, \"h\")\n",
    "observation2 = observation.copy()\n",
    "observation2.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(3, \"h\")\n",
    "observation3 = observation.copy()\n",
    "observation3.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(4, \"h\")\n",
    "observation4 = observation.copy()\n",
    "observation4.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(5, \"h\")\n",
    "observation_list = [\n",
    "    observation0,\n",
    "    observation1,\n",
    "    observation2,\n",
    "    observation3,\n",
    "    observation4,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract state action reward nstate from list of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp            0    2024-06-25 17:45:58.982114\n",
       "state      brake     0                             8\n",
       "                     1                             9\n",
       "                     2                            10\n",
       "                     3                            11\n",
       "                                     ...            \n",
       "nstate     timestep  3    2024-06-25 16:46:04.042114\n",
       "           velocity  0                            28\n",
       "                     1                            29\n",
       "                     2                            30\n",
       "                     3                            31\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('timestamp',         '', 0),\n",
       "            (    'state',    'brake', 0),\n",
       "            (    'state',    'brake', 1),\n",
       "            (    'state',    'brake', 2),\n",
       "            (    'state',    'brake', 3),\n",
       "            (    'state',   'thrust', 0),\n",
       "            (    'state',   'thrust', 1),\n",
       "            (    'state',   'thrust', 2),\n",
       "            (    'state',   'thrust', 3),\n",
       "            (    'state', 'timestep', 0),\n",
       "            (    'state', 'timestep', 1),\n",
       "            (    'state', 'timestep', 2),\n",
       "            (    'state', 'timestep', 3),\n",
       "            (    'state', 'velocity', 0),\n",
       "            (    'state', 'velocity', 1),\n",
       "            (    'state', 'velocity', 2),\n",
       "            (    'state', 'velocity', 3),\n",
       "            (   'action',       'r0', 0),\n",
       "            (   'action',       'r0', 1),\n",
       "            (   'action',       'r0', 2),\n",
       "            (   'action',       'r0', 3),\n",
       "            (   'action',       'r0', 4),\n",
       "            (   'action',       'r1', 0),\n",
       "            (   'action',       'r1', 1),\n",
       "            (   'action',       'r1', 2),\n",
       "            (   'action',       'r1', 3),\n",
       "            (   'action',       'r1', 4),\n",
       "            (   'action',       'r2', 0),\n",
       "            (   'action',       'r2', 1),\n",
       "            (   'action',       'r2', 2),\n",
       "            (   'action',       'r2', 3),\n",
       "            (   'action',       'r2', 4),\n",
       "            (   'action',    'speed', 0),\n",
       "            (   'action',    'speed', 1),\n",
       "            (   'action',    'speed', 2),\n",
       "            (   'action', 'throttle', 0),\n",
       "            (   'action', 'throttle', 1),\n",
       "            (   'action', 'throttle', 2),\n",
       "            (   'action', 'throttle', 3),\n",
       "            (   'action', 'throttle', 4),\n",
       "            (   'action', 'timestep', 0),\n",
       "            (   'action', 'timestep', 1),\n",
       "            (   'action', 'timestep', 2),\n",
       "            (   'reward', 'timestep', 0),\n",
       "            (   'reward',     'work', 0),\n",
       "            (   'nstate',    'brake', 0),\n",
       "            (   'nstate',    'brake', 1),\n",
       "            (   'nstate',    'brake', 2),\n",
       "            (   'nstate',    'brake', 3),\n",
       "            (   'nstate',   'thrust', 0),\n",
       "            (   'nstate',   'thrust', 1),\n",
       "            (   'nstate',   'thrust', 2),\n",
       "            (   'nstate',   'thrust', 3),\n",
       "            (   'nstate', 'timestep', 0),\n",
       "            (   'nstate', 'timestep', 1),\n",
       "            (   'nstate', 'timestep', 2),\n",
       "            (   'nstate', 'timestep', 3),\n",
       "            (   'nstate', 'velocity', 0),\n",
       "            (   'nstate', 'velocity', 1),\n",
       "            (   'nstate', 'velocity', 2),\n",
       "            (   'nstate', 'velocity', 3)],\n",
       "           )"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([27], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "observation_list[0]\n",
    "observation_list[0].index\n",
    "observation_list[0].loc[idx[\"state\", [\"velocity\", \"thrust\", \"brake\"]]].values\n",
    "observation_list[0].loc[idx[\"action\", [\"r0\", \"r1\", \"r2\"]]].values\n",
    "observation_list[0].loc[idx[\"reward\", [\"work\"]]].values\n",
    "observation_list[0].loc[idx[\"nstate\", [\"velocity\", \"thrust\", \"brake\"]]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[27],\n",
       "       [27],\n",
       "       [27],\n",
       "       [27],\n",
       "       [27]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "state = []\n",
    "action = []\n",
    "reward = []\n",
    "nstate = []\n",
    "for observation in observation_list:\n",
    "    state.append(observation.loc[idx[\"state\", [\"velocity\", \"thrust\", \"brake\"]]].values)\n",
    "    action.append(observation.loc[idx[\"action\", [\"r0\", \"r1\", \"r2\"]]].values)\n",
    "    reward.append(observation.loc[idx[\"reward\", [\"work\"]]].values)\n",
    "    nstate.append(\n",
    "        observation.loc[idx[\"nstate\", [\"velocity\", \"thrust\", \"brake\"]]].values\n",
    "    )\n",
    "npa_state = np.stack(state)\n",
    "npa_action = np.stack(action)\n",
    "npa_reward = np.stack(reward)\n",
    "npa_nstate = np.stack(nstate)\n",
    "npa_state\n",
    "npa_action\n",
    "npa_reward\n",
    "npa_nstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_state = np.stack(state)\n",
    "type(npa_state)\n",
    "npa_state.shape\n",
    "state_npa = np.array(state)\n",
    "type(state_npa)\n",
    "state_npa.shape\n",
    "npa_state == state_npa\n",
    "npa_vstate = np.vstack(state)\n",
    "npa_vstate.shape\n",
    "type(npa_vstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_nstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27],\n",
       "       [27],\n",
       "       [27],\n",
       "       [27],\n",
       "       [27]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('timestamp',         '', 0),\n",
       "            (    'state',    'brake', 0),\n",
       "            (    'state',    'brake', 1),\n",
       "            (    'state',    'brake', 2),\n",
       "            (    'state',    'brake', 3),\n",
       "            (    'state',   'thrust', 0),\n",
       "            (    'state',   'thrust', 1),\n",
       "            (    'state',   'thrust', 2),\n",
       "            (    'state',   'thrust', 3),\n",
       "            (    'state', 'timestep', 0),\n",
       "            (    'state', 'timestep', 1),\n",
       "            (    'state', 'timestep', 2),\n",
       "            (    'state', 'timestep', 3),\n",
       "            (    'state', 'velocity', 0),\n",
       "            (    'state', 'velocity', 1),\n",
       "            (    'state', 'velocity', 2),\n",
       "            (    'state', 'velocity', 3),\n",
       "            (   'action',       'r0', 0),\n",
       "            (   'action',       'r0', 1),\n",
       "            (   'action',       'r0', 2),\n",
       "            (   'action',       'r0', 3),\n",
       "            (   'action',       'r0', 4),\n",
       "            (   'action',       'r1', 0),\n",
       "            (   'action',       'r1', 1),\n",
       "            (   'action',       'r1', 2),\n",
       "            (   'action',       'r1', 3),\n",
       "            (   'action',       'r1', 4),\n",
       "            (   'action',       'r2', 0),\n",
       "            (   'action',       'r2', 1),\n",
       "            (   'action',       'r2', 2),\n",
       "            (   'action',       'r2', 3),\n",
       "            (   'action',       'r2', 4),\n",
       "            (   'action',    'speed', 0),\n",
       "            (   'action',    'speed', 1),\n",
       "            (   'action',    'speed', 2),\n",
       "            (   'action', 'throttle', 0),\n",
       "            (   'action', 'throttle', 1),\n",
       "            (   'action', 'throttle', 2),\n",
       "            (   'action', 'throttle', 3),\n",
       "            (   'action', 'throttle', 4),\n",
       "            (   'action', 'timestep', 0),\n",
       "            (   'action', 'timestep', 1),\n",
       "            (   'action', 'timestep', 2),\n",
       "            (   'reward', 'timestep', 0),\n",
       "            (   'reward',     'work', 0),\n",
       "            (   'nstate',    'brake', 0),\n",
       "            (   'nstate',    'brake', 1),\n",
       "            (   'nstate',    'brake', 2),\n",
       "            (   'nstate',    'brake', 3),\n",
       "            (   'nstate',   'thrust', 0),\n",
       "            (   'nstate',   'thrust', 1),\n",
       "            (   'nstate',   'thrust', 2),\n",
       "            (   'nstate',   'thrust', 3),\n",
       "            (   'nstate', 'timestep', 0),\n",
       "            (   'nstate', 'timestep', 1),\n",
       "            (   'nstate', 'timestep', 2),\n",
       "            (   'nstate', 'timestep', 3),\n",
       "            (   'nstate', 'velocity', 0),\n",
       "            (   'nstate', 'velocity', 1),\n",
       "            (   'nstate', 'velocity', 2),\n",
       "            (   'nstate', 'velocity', 3)],\n",
       "           names=['tuple', 'rows', 'idx'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tuple</th>\n",
       "      <th>timestamp</th>\n",
       "      <th colspan=\"9\" halign=\"left\">state</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">nstate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">brake</th>\n",
       "      <th colspan=\"4\" halign=\"left\">thrust</th>\n",
       "      <th>timestep</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">thrust</th>\n",
       "      <th colspan=\"4\" halign=\"left\">timestep</th>\n",
       "      <th colspan=\"4\" halign=\"left\">velocity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-25 17:45:58.982114</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-06-25 16:46:03.982114</td>\n",
       "      <td>2024-06-25 16:46:04.002114</td>\n",
       "      <td>2024-06-25 16:46:04.022114</td>\n",
       "      <td>2024-06-25 16:46:04.042114</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-25 18:45:58.982114</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-06-25 16:46:03.982114</td>\n",
       "      <td>2024-06-25 16:46:04.002114</td>\n",
       "      <td>2024-06-25 16:46:04.022114</td>\n",
       "      <td>2024-06-25 16:46:04.042114</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-25 19:45:58.982114</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-06-25 16:46:03.982114</td>\n",
       "      <td>2024-06-25 16:46:04.002114</td>\n",
       "      <td>2024-06-25 16:46:04.022114</td>\n",
       "      <td>2024-06-25 16:46:04.042114</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-25 20:45:58.982114</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-06-25 16:46:03.982114</td>\n",
       "      <td>2024-06-25 16:46:04.002114</td>\n",
       "      <td>2024-06-25 16:46:04.022114</td>\n",
       "      <td>2024-06-25 16:46:04.042114</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-25 21:45:58.982114</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-06-25 16:46:03.982114</td>\n",
       "      <td>2024-06-25 16:46:04.002114</td>\n",
       "      <td>2024-06-25 16:46:04.022114</td>\n",
       "      <td>2024-06-25 16:46:04.042114</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tuple                   timestamp state                             \\\n",
       "rows                              brake            thrust            \n",
       "idx                             0     0  1   2   3      0  1  2  3   \n",
       "0      2024-06-25 17:45:58.982114     8  9  10  11      4  5  6  7   \n",
       "1      2024-06-25 18:45:58.982114     8  9  10  11      4  5  6  7   \n",
       "2      2024-06-25 19:45:58.982114     8  9  10  11      4  5  6  7   \n",
       "3      2024-06-25 20:45:58.982114     8  9  10  11      4  5  6  7   \n",
       "4      2024-06-25 21:45:58.982114     8  9  10  11      4  5  6  7   \n",
       "\n",
       "tuple                              ... nstate                                  \\\n",
       "rows                     timestep  ... thrust                        timestep   \n",
       "idx                             0  ...      2   3                           0   \n",
       "0      2024-06-25 16:45:58.982114  ...     34  35  2024-06-25 16:46:03.982114   \n",
       "1      2024-06-25 16:45:58.982114  ...     34  35  2024-06-25 16:46:03.982114   \n",
       "2      2024-06-25 16:45:58.982114  ...     34  35  2024-06-25 16:46:03.982114   \n",
       "3      2024-06-25 16:45:58.982114  ...     34  35  2024-06-25 16:46:03.982114   \n",
       "4      2024-06-25 16:45:58.982114  ...     34  35  2024-06-25 16:46:03.982114   \n",
       "\n",
       "tuple                                                          \\\n",
       "rows                                                            \n",
       "idx                             1                           2   \n",
       "0      2024-06-25 16:46:04.002114  2024-06-25 16:46:04.022114   \n",
       "1      2024-06-25 16:46:04.002114  2024-06-25 16:46:04.022114   \n",
       "2      2024-06-25 16:46:04.002114  2024-06-25 16:46:04.022114   \n",
       "3      2024-06-25 16:46:04.002114  2024-06-25 16:46:04.022114   \n",
       "4      2024-06-25 16:46:04.002114  2024-06-25 16:46:04.022114   \n",
       "\n",
       "tuple                                                   \n",
       "rows                              velocity              \n",
       "idx                             3        0   1   2   3  \n",
       "0      2024-06-25 16:46:04.042114       28  29  30  31  \n",
       "1      2024-06-25 16:46:04.042114       28  29  30  31  \n",
       "2      2024-06-25 16:46:04.042114       28  29  30  31  \n",
       "3      2024-06-25 16:46:04.042114       28  29  30  31  \n",
       "4      2024-06-25 16:46:04.042114       28  29  30  31  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_epi = pd.concat(observation_list, axis=1).transpose()\n",
    "dfs_epi.columns.names = [\"tuple\", \"rows\", \"idx\"]\n",
    "dfs_epi.columns\n",
    "dfs_epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/x/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tuple</th>\n",
       "      <th colspan=\"10\" halign=\"left\">action</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <th colspan=\"5\" halign=\"left\">r0</th>\n",
       "      <th colspan=\"5\" halign=\"left\">r1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">thrust</th>\n",
       "      <th colspan=\"4\" halign=\"left\">timestep</th>\n",
       "      <th colspan=\"4\" halign=\"left\">velocity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-25 17:45:58.982114</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>2024-06-25 16:45:59.002114</td>\n",
       "      <td>2024-06-25 16:45:59.022114</td>\n",
       "      <td>2024-06-25 16:45:59.042114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-25 18:45:58.982114</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>2024-06-25 16:45:59.002114</td>\n",
       "      <td>2024-06-25 16:45:59.022114</td>\n",
       "      <td>2024-06-25 16:45:59.042114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-25 19:45:58.982114</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>2024-06-25 16:45:59.002114</td>\n",
       "      <td>2024-06-25 16:45:59.022114</td>\n",
       "      <td>2024-06-25 16:45:59.042114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-25 20:45:58.982114</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>2024-06-25 16:45:59.002114</td>\n",
       "      <td>2024-06-25 16:45:59.022114</td>\n",
       "      <td>2024-06-25 16:45:59.042114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-25 21:45:58.982114</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-06-25 16:45:58.982114</td>\n",
       "      <td>2024-06-25 16:45:59.002114</td>\n",
       "      <td>2024-06-25 16:45:59.022114</td>\n",
       "      <td>2024-06-25 16:45:59.042114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tuple                      action                                      ...  \\\n",
       "rows                           r0                  r1                  ...   \n",
       "idx                             0   1   2   3   4   0   1   2   3   4  ...   \n",
       "timestamp                                                              ...   \n",
       "2024-06-25 17:45:58.982114     12  13  14  15  16  17  18  19  20  21  ...   \n",
       "2024-06-25 18:45:58.982114     12  13  14  15  16  17  18  19  20  21  ...   \n",
       "2024-06-25 19:45:58.982114     12  13  14  15  16  17  18  19  20  21  ...   \n",
       "2024-06-25 20:45:58.982114     12  13  14  15  16  17  18  19  20  21  ...   \n",
       "2024-06-25 21:45:58.982114     12  13  14  15  16  17  18  19  20  21  ...   \n",
       "\n",
       "tuple                       state                                 \\\n",
       "rows                       thrust                       timestep   \n",
       "idx                             2  3                           0   \n",
       "timestamp                                                          \n",
       "2024-06-25 17:45:58.982114      6  7  2024-06-25 16:45:58.982114   \n",
       "2024-06-25 18:45:58.982114      6  7  2024-06-25 16:45:58.982114   \n",
       "2024-06-25 19:45:58.982114      6  7  2024-06-25 16:45:58.982114   \n",
       "2024-06-25 20:45:58.982114      6  7  2024-06-25 16:45:58.982114   \n",
       "2024-06-25 21:45:58.982114      6  7  2024-06-25 16:45:58.982114   \n",
       "\n",
       "tuple                                                   \\\n",
       "rows                                                     \n",
       "idx                                                  1   \n",
       "timestamp                                                \n",
       "2024-06-25 17:45:58.982114  2024-06-25 16:45:59.002114   \n",
       "2024-06-25 18:45:58.982114  2024-06-25 16:45:59.002114   \n",
       "2024-06-25 19:45:58.982114  2024-06-25 16:45:59.002114   \n",
       "2024-06-25 20:45:58.982114  2024-06-25 16:45:59.002114   \n",
       "2024-06-25 21:45:58.982114  2024-06-25 16:45:59.002114   \n",
       "\n",
       "tuple                                                   \\\n",
       "rows                                                     \n",
       "idx                                                  2   \n",
       "timestamp                                                \n",
       "2024-06-25 17:45:58.982114  2024-06-25 16:45:59.022114   \n",
       "2024-06-25 18:45:58.982114  2024-06-25 16:45:59.022114   \n",
       "2024-06-25 19:45:58.982114  2024-06-25 16:45:59.022114   \n",
       "2024-06-25 20:45:58.982114  2024-06-25 16:45:59.022114   \n",
       "2024-06-25 21:45:58.982114  2024-06-25 16:45:59.022114   \n",
       "\n",
       "tuple                                                                     \n",
       "rows                                                   velocity           \n",
       "idx                                                  3        0  1  2  3  \n",
       "timestamp                                                                 \n",
       "2024-06-25 17:45:58.982114  2024-06-25 16:45:59.042114        0  1  2  3  \n",
       "2024-06-25 18:45:58.982114  2024-06-25 16:45:59.042114        0  1  2  3  \n",
       "2024-06-25 19:45:58.982114  2024-06-25 16:45:59.042114        0  1  2  3  \n",
       "2024-06-25 20:45:58.982114  2024-06-25 16:45:59.042114        0  1  2  3  \n",
       "2024-06-25 21:45:58.982114  2024-06-25 16:45:59.042114        0  1  2  3  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_episode1 = dfs_epi.copy().sort_index(axis=1)\n",
    "dfs_episode1.set_index((\"timestamp\", \"\", 0), inplace=True)\n",
    "dfs_episode1.index.name = \"timestamp\"\n",
    "idx = pd.IndexSlice\n",
    "dfs_episode1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dfs_episode1\u001b[38;5;241m.\u001b[39mloc[:, idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m, :, :, :]] \u001b[38;5;241m=\u001b[39m \u001b[43mdfs_episode1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m----> 3\u001b[0m \u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m dfs_episode1\n\u001b[1;32m      5\u001b[0m dfs_episode1\u001b[38;5;241m.\u001b[39mdtypes\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-3.11-24.1.2-0/envs/tspace/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "dfs_episode1.loc[:, idx[\"action\":\"state\", :, :, :]] = dfs_episode1.loc[\n",
    "    :, idx[\"action\":\"state\", :, :, :]\n",
    "].astype(\"int\")\n",
    "dfs_episode1\n",
    "dfs_episode1.dtypes\n",
    "dfs_episode1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns types to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_epi\n",
    "dfs_episode = dfs_epi.copy()\n",
    "dfs_episode.index\n",
    "dfs_episode.set_index((\"timestamp\", \"\", 0), inplace=True)\n",
    "dfs_episode.sort_index(axis=1, inplace=True)\n",
    "dfs_episode.index\n",
    "dfs_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode.index.name = \"timestamp\"\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# # dfs_episode = dfs_episode.astype({idx['state', 'velocity', :]: 'int'})  # Error unhashable type: 'slice' for dictionary\n",
    "# # sorted_idx = **(idx['state', :, :]:'int')\n",
    "# # sorted_idx\n",
    "# dfs_episode.loc[:, idx['state', ['brake', 'thrust', 'velocity'], :]] = dfs_episode.loc[\n",
    "#     :, idx['state', ['brake', 'thrust', 'velocity'], :]\n",
    "# ].astype(\n",
    "#     'float'\n",
    "# )  # float16 not allowed in parquet\n",
    "#\n",
    "# dfs_episode.loc[:, idx['action', ['r0', 'r1', 'r2'], :]] = dfs_episode.loc[\n",
    "#     :, idx['action', ['r0', 'r1', 'r2'], :]\n",
    "# ].astype(\n",
    "#     'float'\n",
    "# )  # float16 not allowed in parquet\n",
    "# # dfs_episode['action'] = dfs_episode['action'].astype('float')\n",
    "# # dfs_episode['reward'] = dfs_episode['reward'].astype('float')\n",
    "# dfs_episode.loc[:, idx['reward', 'work', 0]] = dfs_episode.loc[\n",
    "#     :, idx['reward', 'work', 0]\n",
    "# ].astype(\n",
    "#     'float'\n",
    "# )  # float16 not allowed in parquet\n",
    "#\n",
    "# # dfs_episode['nstate'] = dfs_episode['nstate'].astype('float')\n",
    "# dfs_episode.loc[:, idx['nstate', ['brake', 'thrust', 'velocity'], :]] = dfs_episode.loc[\n",
    "#     :, idx['nstate', ['brake', 'thrust', 'velocity'], :]\n",
    "# ].astype(\n",
    "#     'float'\n",
    "# )  # float16 not allowed in parquet\n",
    "state_cols_float = [(\"state\", col) for col in [\"brake\", \"thrust\", \"velocity\"]]\n",
    "action_cols_float = [(\"action\", col) for col in [\"r0\", \"r1\", \"r2\", \"speed\", \"throttle\"]]\n",
    "reward_cols_float = [(\"reward\", \"work\")]\n",
    "nstate_cols_float = [(\"nstate\", col) for col in [\"brake\", \"thrust\", \"velocity\"]]\n",
    "for col in action_cols_float + state_cols_float + reward_cols_float + nstate_cols_float:\n",
    "    dfs_episode[col[0], col[1]] = dfs_episode[col[0], col[1]].astype(\n",
    "        \"float\"\n",
    "    )  # float16 not allowed in parquet\n",
    "dfs_episode\n",
    "dfs_episode.dtypes\n",
    "# dfs_episode.columns\n",
    "# dfs_epi\n",
    "# dfs_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepend two levels of index \"vehicle\" and \"driver\" to the DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode = pd.concat(\n",
    "    [dfs_episode], keys=[drivers_by_id[\"wang-cheng\"].pid], names=[\"driver\"]\n",
    ")\n",
    "dfs_episode = pd.concat(\n",
    "    [dfs_episode], keys=[trucks_by_id[\"VB7\"].vid], names=[\"vehicle\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode.index\n",
    "dfs_episode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode.columns.set_names(\n",
    "#     [\n",
    "#         'tuple',\n",
    "#         'rows',\n",
    "#         'idx',\n",
    "#     ],\n",
    "#     level=[0, 1, 2],\n",
    "#     inplace=True,\n",
    "# )\n",
    "dfs_episode\n",
    "dfs_episode.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode['state', 'thrust'] = dfs_episode['state', 'thrust'].astype('float')\n",
    "# # dfs_episode.loc[:, idx['state', ['brake', 'thrust', 'velocity'], :]] = dfs_episode.loc[\n",
    "# #     :, idx['state', ['brake', 'thrust', 'velocity'], :]\n",
    "# # ].astype(\n",
    "# #     'float'\n",
    "# # )  # float16 not allowed in parquet\n",
    "# dfs_episode.loc[:, ('state', ['brake', 'thrust', 'velocity'])] = dfs_episode.loc[\n",
    "#     :, ('state', ['brake', 'thrust', 'velocity'])\n",
    "# ].astype(\n",
    "#     'float'\n",
    "# )  # float16 not allowed in parquet\n",
    "# dfs_episode['action', 'r0'] = dfs_episode['action', 'r0'].astype(\n",
    "#     'float'\n",
    "# )  # float16 not allowed in parquet\n",
    "#\n",
    "# dfs_episode.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = pd.IndexSlice\n",
    "# dfs_episode.loc[:, idx['state', :, :]] = dfs_episode.loc[:, idx['state', :, :]].astype(\n",
    "#     'int'\n",
    "# )\n",
    "# dfs_episode.loc[:, idx['action', :, :]] = dfs_episode.loc[\n",
    "#     :, idx['action', :, :]\n",
    "# ].astype('float16')\n",
    "# dfs_episode.loc[:, idx['reward', :, :]] = dfs_episode.loc[\n",
    "#     :, idx['reward', :, :]\n",
    "# ].astype('float16')\n",
    "# dfs_episode.loc[:, idx['nstate', :, :]] = dfs_episode.loc[\n",
    "#     :, idx['nstate', :, :]\n",
    "# ].astype('float16')\n",
    "#\n",
    "# vel_1 = dfs_episode[[('state', 'velocity', 1)]]\n",
    "# vel_1.dtypes\n",
    "# vel_1.index\n",
    "# vel_1.values\n",
    "# # type(vel_1)\n",
    "# vel_1.iloc[0]\n",
    "# type(vel_1.iloc[0])\n",
    "# type(vel_1.iloc[0].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a level of index for episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodestart = ts - pd.Timedelta(1, \"h\")\n",
    "dfs_episode = pd.concat([dfs_episode], keys=[ts], names=[\"episodestart\"])\n",
    "dfs_episode = dfs_episode.swaplevel(1, 0, axis=0)\n",
    "dfs_episode = dfs_episode.swaplevel(1, 2, axis=0)\n",
    "dfs_episode.sort_index(inplace=True)\n",
    "dfs_episode.index\n",
    "dfs_episode.columns\n",
    "dfs_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb7 = trucks_by_id[\"VB7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eos.data_io.eos_struct import PoolQuery\n",
    "\n",
    "query = PoolQuery(\n",
    "    site=trucks_by_id[\"VB7\"].site,\n",
    "    vehicle=trucks_by_id[\"VB7\"].vid,\n",
    "    driver=drivers_by_id[\"zheng-longfei\"].pid,\n",
    "    start=episodestart,\n",
    "    end=ts,\n",
    ")\n",
    "isinstance(query, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_new = pd.to_datetime((datetime.now()))\n",
    "ts_new\n",
    "episodestart = ts_new - pd.Timedelta(2, \"d\")\n",
    "episodestart\n",
    "\n",
    "dfs_episode0 = dfs_episode.copy()\n",
    "dfs_episode0.index = dfs_episode0.index.set_levels([episodestart], level=\"episodestart\")\n",
    "dfs_episode0.index = dfs_episode0.index.set_levels(\n",
    "    [[trucks_by_id[\"VB7\"].vid], [drivers_by_id[\"zheng-longfei\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "dfs_episode1 = dfs_episode.copy()\n",
    "dfs_episode1.index = dfs_episode1.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(3, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode1.index = dfs_episode1.index.set_levels(\n",
    "    [[trucks_by_id[\"MP73\"].vid], [drivers_by_id[\"wang-cheng\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "dfs_episode2 = dfs_episode.copy()\n",
    "dfs_episode2.index = dfs_episode2.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(4, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode2.index = dfs_episode2.index.set_levels(\n",
    "    [[trucks_by_id[\"VB7\"].vid], [drivers_by_id[\"wang-cheng\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "dfs_episode3 = dfs_episode.copy()\n",
    "dfs_episode3.index = dfs_episode3.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(5, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode3.index = dfs_episode3.index.set_levels(\n",
    "    [[trucks_by_id[\"MP73\"].vid], [drivers_by_id[\"zheng-longfei\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "dfs_episode0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode_concat = pd.concat([dfs_episode, dfs_episode0], axis=0)\n",
    "# display('dfs_episode_concat')\n",
    "# dfs_episode_concat.index\n",
    "# dfs_episode_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "episodes = [dfs_episode, dfs_episode0, dfs_episode1, dfs_episode2, dfs_episode3]\n",
    "try:\n",
    "    dfs_episode_all = reduce(\n",
    "        lambda left, right,: pd.concat([left, right], axis=0), episodes\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# dfs_episode_all.sort_index(inplace=True)\n",
    "dfs_episode_all = dfs_episode_all.swaplevel(1, 0, axis=0)\n",
    "dfs_episode_all = dfs_episode_all.swaplevel(1, 2, axis=0)\n",
    "dfs_episode_all.sort_index(inplace=True)\n",
    "dfs_episode_all = dfs_episode_all[[\"state\", \"action\", \"reward\", \"nstate\"]]\n",
    "display(\"dfs_episode_all\")\n",
    "dfs_episode_all.index\n",
    "dfs_episode_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make MultiIndex to Rows by adding levels of \"Vehicle\" and \"Driver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  reset index to move vehicle and driver to columns, preprocessing for dask manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes = dfs_episode_all.reset_index(\n",
    "    level=[\"vehicle\", \"driver\"]\n",
    ")  # unstack vehicle and driver to columns in level 0 with default '' in level 1\n",
    "# # dfs_episodes.columns\n",
    "# # dfs_episode0.index = dfs_episode0.index.set_levels([[trucks[0].vid],[drivers[1].pid]], level=['vehicle', 'driver'], verify_integrity=False)\n",
    "# old_columns = dfs_episodes.columns\n",
    "# # old_columns[0]= (old_columns[0][0],0)\n",
    "# new_columns_tuples = [(old_columns[0][0],0), (old_columns[1][0],0)] + old_columns[2:].to_list()\n",
    "# prepend_columns = pd.MultiIndex.from_tuples(new_columns_tuples, names=old_columns.names)\n",
    "# # prepend_columns\n",
    "\n",
    "# dfs_episodes.columns = prepend_columns\n",
    "dfs_episodes\n",
    "# dfs_episodes.columns\n",
    "# dfs_episodes.dtypes\n",
    "# dfs_episode_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes[\"vehicle\"] = dfs_episodes[\"vehicle\"].astype(\"category\")\n",
    "dfs_episodes[\"driver\"] = dfs_episodes[\"driver\"].astype(\"category\")\n",
    "# dfs_episodes.dtypes\n",
    "# dfs_episodes.columns\n",
    "# dfs_episodes[['vehicle','driver']].dtypes\n",
    "# dfs_episodes[['vehicle','driver']]\n",
    "# dfs_episodes[['vehicle','driver']].iloc[:3].dtypes\n",
    "# sliced = dfs_episodes[['vehicle']].iloc[:3].stack(level=[-1,-2])\n",
    "# type(sliced)\n",
    "# sliced.index\n",
    "# sliced.values\n",
    "\n",
    "dfs_episodes_sorted = dfs_episodes.sort_index(\n",
    "    axis=1, level=[0, 1, 2], ascending=[True, True, True]\n",
    ")\n",
    "dfs_episodes_sorted.sort_index(axis=0, inplace=True)\n",
    "# dfs_episodes_sorted = dfs_episodes.sort_index(axis=1, level=[0,1], ascending=[True, True])\n",
    "# dfs_episodes_sorted = dfs_episodes.sort_index(axis=0, level=[0,1], ascending=[True, True])\n",
    "# dfs_episodes_sorted.sort_index(axis=1,inplace=True)\n",
    "dfs_episodes_sorted\n",
    "dfs_episodes_sorted.columns\n",
    "\n",
    "# dfs_episodes[['driver'], ['vehicle']] = dfs_episodes[['driver', 'vehicle']].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts\n",
    "ep_start = ts - pd.Timedelta(9, \"D\")\n",
    "ep_start\n",
    "# time_slice\n",
    "episode_slice = pd.date_range(ep_start, periods=6, freq=\"D\")\n",
    "episode_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_slice = pd.date_range(ts, periods=3, freq=\"H\") + pd.Timedelta(10, \"min\")\n",
    "timestamp_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_sorted.index\n",
    "dfs_episodes_sorted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode_all.loc['VB7', 'zheng-longfei', episode_slice[0]:episode_slice[3]]\n",
    "# dfs_selected_episodes = dfs_episodes_sorted.loc[trucks[0].vid, drivers[1].pid, episode_slice[0]:episode_slice[3], timestamp_slice[0]:timestamp_slice[2]]\n",
    "idx = pd.IndexSlice\n",
    "dfs_selected_episodes = dfs_episodes_sorted.loc[\n",
    "    idx[episode_slice[0] : episode_slice[5], timestamp_slice[0] : timestamp_slice[2]],\n",
    "    idx[\"action\":\"driver\"],\n",
    "]\n",
    "dfs_selected_episodes\n",
    "# dfs_selected_episodes[['action', 'reward']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_selected_episodes_columns = dfs_episode_all.loc['VB7', 'zheng-longfei', episode_slice[0]:episode_slice[3], timestamp_slice[0]:timestamp_slice[2]][['action', 'reward']]\n",
    "# dfs_selected_episodes_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode_all_sorted = dfs_episode_all.sort_index(axis=1)\n",
    "# dfs_episode_all_sorted = dfs_episode_all_sorted.sort_index(axis=0)\n",
    "# dfs_episode_all_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_selected_episodes_columns = dfs_episode_all_sorted.loc[(slice('VB6'), slice('wang-cheng'), slice(None), slice(None)),:]\n",
    "# idx = pd.IndexSlice\n",
    "# dfs_episode_all_sorted.loc[(idx['VB6'], idx['wang-cheng','zheng-longfei'], slice(None), slice(None)),:]\n",
    "# dfs_selected_episodes_columns = dfs_episode_all_sorted.loc[(idx['VB7'], idx['zheng-longfei'], slice(None), slice(None)),['state','n_state']]\n",
    "# dfs_selected_episodes_columns = dfs_episodes_sorted.loc[(idx['VB7'], idx['zheng-longfei'], slice(None), slice(None)),['state','n_state']]\n",
    "# dfs_selected_episodes_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_new = pd.to_datetime((datetime.now()))\n",
    "episodestart = ts_new - pd.Timedelta(10, \"d\") - pd.Timedelta(6, \"h\")\n",
    "episodestart\n",
    "episode_slice = pd.date_range(episodestart, periods=20, freq=\"d\") + pd.Timedelta(\n",
    "    10, \"min\"\n",
    ")\n",
    "episode_slice\n",
    "ts\n",
    "time_slice = pd.date_range(ts, periods=6, freq=\"h\") - pd.Timedelta(10, \"min\")\n",
    "time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_slice[4]: episode_slice[8]\n",
    "idx[episode_slice[4] : episode_slice[8]]\n",
    "idx[episode_slice[4] : episode_slice[8], slice(None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_slice[4]\n",
    "episode_slice[11]\n",
    "# dfs_selected_episodes = dfs_episodes_sorted.loc[idx['VB7'], slice(None), episode_slice[4]:episode_slice[11]]\n",
    "# dfs_selected_episodes\n",
    "# dfs_selected_episodes = dfs_episodes_sorted.loc[slice(None), idx['zheng-longfei'], episode_slice[4]:episode_slice[11]]\n",
    "# dfs_selected_episodes\n",
    "# dfs_selected_episodes = dfs_episode_all.loc[slice(None), idx['zheng-longfei'], episode_slice[4]:episode_slice[11], time_slice[0]:time_slice[3]]\n",
    "# dfs_selected_episodes\n",
    "# epislice = idx(episode_slice[4]:episode_slice[11])\n",
    "\n",
    "# dfs_selected_episodes = dfs_episodes_sorted.loc[idx[episode_slice[4]:episode_slice[11],slice(None)], idx[dfs_episodes_sorted['driver']==drivers[0].pid]]\n",
    "dfs_selected_episodes1 = dfs_episodes_sorted.loc[\n",
    "    dfs_episodes_sorted[\"driver\"] == drivers_by_id[\"wang-cheng\"].pid\n",
    "]\n",
    "dfs_selected_episodes1\n",
    "dfs_selected_episodes2 = dfs_episodes_sorted.loc[\n",
    "    dfs_episodes_sorted[\"driver\"] == drivers_by_id[\"wang-cheng\"].pid\n",
    "].loc[idx[episode_slice[4] : episode_slice[8]]]\n",
    "dfs_selected_episodes2\n",
    "dfs_selected_episodes3 = dfs_episodes_sorted.loc[\n",
    "    (dfs_episodes_sorted[\"driver\"] == drivers_by_id[\"wang-cheng\"].pid)\n",
    "    & (dfs_episodes_sorted[\"vehicle\"] == trucks_by_id[\"VB7\"].vid)\n",
    "].loc[idx[episode_slice[4] : episode_slice[8]]]\n",
    "dfs_selected_episodes3\n",
    "# dfs_selected_episodes31 = dfs_episodes_sorted.loc[idx[episode_slice[4]:episode_slice[8],slice(None)]].loc[ (dfs_episodes_sorted['driver']==drivers[0].pid) & (dfs_episodes_sorted['vehicle']==trucks[0].vid)]\n",
    "# dfs_selected_episodes31 = dfs_episodes_sorted.loc[ (dfs_episodes_sorted['driver']==drivers[0].pid) & (dfs_episodes_sorted['vehicle']==trucks[0].vid) & (idx[episode_slice[4]:episode_slice[8],slice(None)])]\n",
    "# dfs_selected_episodes31\n",
    "# dfs_selected_episodes3.index\n",
    "# dfs_selected_episodes3.columns\n",
    "# dfs_selected_episodes = dfs_episodes_sorted.loc[slice(None), idx['zheng-longfei'], episode_slice[4]:episode_slice[11]]\n",
    "# dfs_selected_episodes\n",
    "# dfs_selected_episodes = dfs_episode_all.loc[slice(None), idx['zheng-longfei'], episode_slice[4]:episode_slice[11], time_slice[0]:time_slice[3]]\n",
    "# dfs_selected_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[time_slice[0] : time_slice[3]]\n",
    "dfs_selected_episodes3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice2 = pd.date_range(ts, periods=6, freq=\"S\")\n",
    "time_slice2\n",
    "dfs_selected_episodes3_sorted = dfs_selected_episodes3.sort_index(axis=0).sort_index(\n",
    "    axis=1\n",
    ")[[\"action\"]]\n",
    "dfs_selected_episodes3_sorted\n",
    "# dfs_selected_episodes3.loc[:, idx[:, :, 0:2, :]]\n",
    "# dfs_selected_episodes3_sorted.loc[:, idx[:, :,time_slice2[0]:time_slice2[1], :]]\n",
    "# dfs_selected_episodes3.loc[idx[:,time_slice[0]:time_slice[2]],:]\n",
    "dfs_selected_episodes3.loc[idx[:, time_slice[0] : time_slice[3]], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_selected_episodes3.index\n",
    "# dfs_selected_episodes3.columns\n",
    "time_slice[0]\n",
    "time_slice[3]\n",
    "idx[:, time_slice[0] : time_slice[3]]\n",
    "dfs_selected_episodes4 = dfs_selected_episodes3.loc[\n",
    "    idx[:, time_slice[0] : time_slice[3]], :\n",
    "]\n",
    "# dfs_selected_episodes4 = dfs_selected_episodes3.loc[idx[:,time_slice[0]:time_slice[3],:],:]\n",
    "\n",
    "dfs_selected_episodes4\n",
    "dfs_selected_episodes41 = dfs_selected_episodes3.loc[\n",
    "    idx[:, time_slice[0] : time_slice[3]], \"action\":\"driver\"\n",
    "]\n",
    "dfs_selected_episodes41\n",
    "# dfs_selected_episodes4 = dfs_episodes_sorted.loc[ (dfs_episodes_sorted['driver']==drivers[0].pid) & (dfs_episodes_sorted['vehicle']==trucks[0].vid)].loc[idx[episode_slice[4]:episode_slice[8],time_slice[0]:time_slice[3]]]\n",
    "# dfs_selected_episodes4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_selected_episodes = dfs_episode_all.loc['VB7', 'zheng-longfei', episode_slice[0]:episode_slice[3], timestamp_slice[0]:timestamp_slice[2]]\n",
    "# dfs_selected_episodes_columns = dfs_episode_all_sorted.loc[(idx['VB7'], idx['zheng-longfei'], slice(None), slice(None)),['state','n_state']]\n",
    "# dfs_selected_episodes_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_sorted\n",
    "# dfs_episode.loc[:,'state']\n",
    "dfs_slice = dfs_episodes_sorted.loc[\n",
    "    dfs_episodes_sorted[\"vehicle\"] == \"MP73\", [\"vehicle\", \"driver\", \"state\", \"reward\"]\n",
    "]\n",
    "dfs_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved episodes as parquet in multi-level folders \"vehicle/driver/episode/tuple.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import platform\n",
    "\n",
    "print(\"Python: \", platform.python_version())\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"pyarrow: \", pa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_sorted\n",
    "dfs_episodes_sorted.index\n",
    "dfs_episodes_sorted.columns\n",
    "dfs_episodes_sorted.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_complete_episodes = dfs_episodes_sorted.reset_index(\"episodestart\")\n",
    "dfs_complete_episodes\n",
    "dfs_complete_episodes.index\n",
    "dfs_complete_episodes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode4dask = dfs_episode_all_sorted.swaplevel(0,-1, axis=0).swaplevel(1,3, axis=0).swaplevel(2,3, axis=0).unstack()\n",
    "# dfs_episode4dask = dfs_episode4dask.swaplevel(0,-1, axis=1).swaplevel(-2,-1, axis=1)\n",
    "# dfs_episode4dask\n",
    "# # dfs_episode4dask = dfs_episode4dask.swaplevel(0,-1, axis=1).swaplevel(-2,-1, axis=1)\n",
    "# # dfs_episode4dask.index\n",
    "# # dfs_episode4dask.index\n",
    "# # dfs_episode4dask.columns\n",
    "# # dfs_episode4dask\n",
    "# # dfs_episode_all_stack = dfs_episode_all.unstack(level=[-1,-2,-3,])\n",
    "# # dfs_episode_all_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_episode4dask1 = dfs_episode4dask.unstack().swaplevel(-2,-1, axis=1).swaplevel(-2,-3,axis=1).swaplevel(-3,-4,axis=1)\n",
    "# # dfs_episode4dask1\n",
    "# dfs_episode4dask2 = dfs_episode4dask1.unstack().swaplevel(-2,-1, axis=1).swaplevel(-2,-3,axis=1).swaplevel(-3,-4,axis=1).swaplevel(-4,-5,axis=1)\n",
    "# dfs_episode4dask2.sort_index(axis=1, inplace=True)\n",
    "# dfs_episode4dask2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding multiindex dataframe to flat index for Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_complete_episodes.columns\n",
    "cols = dfs_complete_episodes.columns.to_flat_index()\n",
    "cols\n",
    "\n",
    "## 3 level index\n",
    "# cols_str = [\n",
    "#     f'{x[0]}_{x[1]}_{x[2]}'\n",
    "#     if (x[1] != '')\n",
    "#     else f'{x[0]}__{x[2]}'\n",
    "#     if (x[2] != '')\n",
    "#     else f'{x[0]}'\n",
    "#     for x in cols\n",
    "# ]\n",
    "\n",
    "## 4 level index\n",
    "cols_str = [\n",
    "    f\"{x[0]}_{x[1]}_{x[2]}\"\n",
    "    if (x[1] != \"\" and x[2] != \"\")\n",
    "    else f\"{x[0]}_{x[1]}_\"\n",
    "    if (x[1] != \"\" and x[2] == \"\")\n",
    "    else f\"{x[0]}__{x[2]}\"\n",
    "    if (x[2] != \"\")\n",
    "    else f\"{x[0]}__\"\n",
    "    for x in cols\n",
    "]\n",
    "cols_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding index and columns\n",
    "dfs_complete_episodes_flat = dfs_complete_episodes.copy()\n",
    "cols = dfs_complete_episodes.columns.to_flat_index()\n",
    "dfs_complete_episodes_flat.columns = [\n",
    "    f\"{x[0]}_{x[1]}_{x[2]}\"\n",
    "    if (x[1] != \"\" and x[2] != \"\")\n",
    "    else f\"{x[0]}_{x[1]}_\"\n",
    "    if (x[1] != \"\" and x[2] == \"\")\n",
    "    else f\"{x[0]}__{x[2]}\"\n",
    "    if (x[2] != \"\")\n",
    "    else f\"{x[0]}__\"\n",
    "    for x in cols\n",
    "]\n",
    "dfs_complete_episodes_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_complete_episodes_flat\n",
    "dfs_complete_episodes_flat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_complete_episodes_flat[\"vehicle__\"].iloc[0:2].values.dtype\n",
    "dfs_complete_episodes_flat[\"vehicle__\"].dtype\n",
    "dfs_complete_episodes_flat[\"state_velocity_0\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ddf_episodes = dd.from_pandas(dfs_complete_episodes_flat, npartitions=1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    ddf_episodes.index\n",
    "    ddf_episodes.columns\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "ddf_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_metadata = {\n",
    "    b\"eos\": b'{\"length\":[3, 600, 5],\"timezeone\":\"sh\",\"units\":[\"kph\",\"pct\",\"pct\"],\"data_propensity\":[50, 1, 4],\"Dataset Description\": \"MP vehicle from TBox\"}'\n",
    "}\n",
    "custom_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with ProgressBar():\n",
    "        ddf_episodes.to_parquet(\n",
    "            \"eos_complete_episodes\",\n",
    "            engine=\"pyarrow\",\n",
    "            compression=\"snappy\",\n",
    "            partition_on=[\"vehicle__\", \"driver__\", \"episodestart__\"],\n",
    "            write_metadata_file=True,\n",
    "            custom_metadata=custom_metadata,\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read saved parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\n",
    "    \"eos_complete_episodes\",\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    "    ignore_metadata_file=False,\n",
    "    infer_divisions=True,\n",
    ")\n",
    "ddf.head(5)\n",
    "ddf.dtypes\n",
    "ddf.npartitions\n",
    "ddf.divisions\n",
    "ddf._meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get customized metadata with pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "\n",
    "# print('pyarrow: ', pa.__version__)\n",
    "\n",
    "# table = pq.read_table('ddf_episodes')\n",
    "# table_meta = table.schema.metadata[b'eos']\n",
    "# print(table_meta)\n",
    "# # custom_metadata_info = json.loads(table.schema.metadata[b'eos'])\n",
    "# # print(custom_metadata_info)\n",
    "# try:\n",
    "#     custom_meta_info = json.loads(table_meta)\n",
    "# except Exception as e:\n",
    "#     print(f'Exception: {e}')\n",
    "\n",
    "# print(custom_meta_info)\n",
    "\n",
    "# # Print formatted output of the dichtionary custom_meta_info:\n",
    "# for key, val in custom_meta_info.items():\n",
    "#     print('{:15}: {}'.format(key, val))\n",
    "\n",
    "# ALTERNATE:\n",
    "\n",
    "table_meta = pq.read_metadata(\"eos_complete_episodes/_common_metadata\")\n",
    "# print(table_meta)\n",
    "# print(table_meta.metadata[b'eos'])\n",
    "custom_meta_info = table_meta.metadata[b\"eos\"]\n",
    "custom_meta_info = json.loads(custom_meta_info)\n",
    "# custom_meta_info\n",
    "\n",
    "for key, val in custom_meta_info.items():\n",
    "    print(f\"{key}: {val}\")\n",
    "\n",
    "# table_meta = pq.read_metadata('ddf_episodes/_metadata')\n",
    "# # print(table_meta)\n",
    "# # print(table_meta.metadata[b'eos'])\n",
    "# custom_meta_info = table_meta.metadata[b'eos']\n",
    "# custom_meta_info = json.loads(custom_meta_info)\n",
    "# custom_meta_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding flat_index of dask dataframe to multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episodes_read = ddf.compute()\n",
    "df_episodes_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding\n",
    "multi_cols = [tuple(col.split(\"_\")) for col in df_episodes_read.columns]\n",
    "multi_cols\n",
    "# multi_cols = [(col[0], int(col[1])) if len(col)==2 else col for col in multi_cols]\n",
    "# multi_cols\n",
    "df_episodes_read_multicol = df_episodes_read.copy()\n",
    "multi_idx = pd.MultiIndex.from_tuples(multi_cols)\n",
    "# multi_idx\n",
    "multi_idx.names = [\"tuple\", \"rows\", \"idx\"]\n",
    "driver_vehicle = [\n",
    "    idx\n",
    "    for idx in multi_idx\n",
    "    if idx[0] == \"driver\" or idx[0] == \"vehicle\" or idx[0] == \"episodestart\"\n",
    "]\n",
    "driver_vehicle\n",
    "# multi_idx = multi_idx.set_levels([multi_idx.levels[0], multi_idx.levels[1].astype(int)])\n",
    "# multi_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series([1, np.nan,2,None])\n",
    "# pd.Series([1,np.nan,2,None,pd.NA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding columns\n",
    "from datetime import datetime\n",
    "\n",
    "multi_tpl = [tuple(col.split(\"_\")) for col in df_episodes_read.columns]\n",
    "# multi_tpl\n",
    "# multi_cols = [(col[0], int(col[1])) if len(col)==2 else col for col in multi_cols]\n",
    "# multi_cols\n",
    "df_episodes_read_multicol = df_episodes_read.copy()\n",
    "multi_col = pd.MultiIndex.from_tuples(multi_tpl)\n",
    "# multi_idx\n",
    "# multi_col\n",
    "i1 = multi_col.get_level_values(0)\n",
    "i1 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i1\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "i1\n",
    "# i2 = multi_col.get_level_values(1).fillna('') # must be null string instead of the default pd.NA or np.nan\n",
    "# i2 = [idx if isinstance(idx, int) else '' for idx in i2]\n",
    "i2 = multi_col.get_level_values(\n",
    "    1\n",
    ")  # must be null string instead of the default pd.NA or np.nan\n",
    "i2 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i2\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "i2\n",
    "# i2 = [idx if isinstance(idx, str) else '' for idx in i2]\n",
    "# i2.astype('int')\n",
    "i3 = multi_col.get_level_values(\n",
    "    2\n",
    ")  # must be null string instead of the default pd.NA or np.nan\n",
    "i3 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else int(idx) for idx in i3\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "i3\n",
    "\n",
    "\n",
    "multi_col = pd.MultiIndex.from_arrays([i1, i2, i3])\n",
    "multi_col.names = [\"tuple\", \"rows\", \"idx\"]\n",
    "multi_col\n",
    "\n",
    "\n",
    "# i2[-1]\n",
    "# i2.dropna()\n",
    "# i2\n",
    "# l2 = ['' if i==nan else i  for i in i2]\n",
    "# l2\n",
    "# i2= i2[:-2].astype('int')\n",
    "# i2 = i2.append(pd.Index(['','']))\n",
    "# l2 = [''] + list(l2.values[:-1])\n",
    "# print(l2)\n",
    "# arrays = [ for i2 in l2 for i1 in l1]\n",
    "# l2 = l2[:-2].astype('int') + ['', '']\n",
    "# multi_col.set_levels(ll, level=['tuple','step'])\n",
    "# driver_vehicle = [idx for idx in multi_idx if idx[0]=='driver' or idx[0]=='vehicle']\n",
    "# multi_tpl =  [(col[0],)  if col[0]=='driver' or col[0]=='vehicle' else (col[0],int(col[1])) for col in multi_col]\n",
    "# multi_idx1 = pd.MultiIndex.from_tuples(multi_idx1)\n",
    "# multi_idx = multi_idx.set_levels([multi_idx.levels[0], multi_idx.levels[1].astype(int)])\n",
    "# multi_col = pd.MultiIndex.from_tuples(multi_tpl)\n",
    "# multi_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # decoding index\n",
    "# multi_tuple = [tuple(idx.split('_')) for idx in df_episodes_read.index]\n",
    "# multi_idx = pd.MultiIndex.from_tuples(multi_tuple)\n",
    "# # multi_idx\n",
    "# i0 = multi_idx.get_level_values(\n",
    "#     0\n",
    "# )  # must be null string instead of the default pd.NA or np.nan\n",
    "# i0 = [\n",
    "#     ''\n",
    "#     if str(idx) in (str(pd.NA), 'nan', '')\n",
    "#     else datetime.strptime(idx, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     for idx in i0\n",
    "# ]  # convert index of level 2 type to int and '' if NA\n",
    "# i1 = multi_idx.get_level_values(\n",
    "#     1\n",
    "# )  # must be null string instead of the default pd.NA or np.nan\n",
    "# i1 = [\n",
    "#     ''\n",
    "#     if str(idx) in (str(pd.NA), 'nan', '')\n",
    "#     else datetime.strptime(idx, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     for idx in i1\n",
    "# ]  # convert index of level 2 type to int and '' if NA\n",
    "# df_episodes_read_multiidx = df_episodes_read.copy()\n",
    "# multi_idx = pd.MultiIndex.from_arrays([i0, i1], names=('episodestart', 'timestamp'))\n",
    "#\n",
    "# multi_idx.dtypes\n",
    "# multi_idx\n",
    "# len(multi_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episodes_read_multi = df_episodes_read.copy()\n",
    "df_episodes_read_multi.columns = multi_col\n",
    "# df_episodes_read_multi.index = multi_idx\n",
    "df_episodes_read_multi\n",
    "df_episodes_read_multi.columns\n",
    "df_episodes_read_multi.index\n",
    "df_episodes_read_multi.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recover deep multiindex from columns ['vehicle','driver','episodestart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episodes_read_multi_setindex = df_episodes_read_multi.set_index(\n",
    "    [\"vehicle\", \"driver\", \"episodestart\", df_episodes_read_multi.index]\n",
    ")\n",
    "# df_episodes_read_multi_setindex\n",
    "# df_episodes_read_multi_setindex.sort_index(inplace=True)\n",
    "df_episodes_read_multi_setindex = df_episodes_read_multi_setindex.swaplevel(\n",
    "    1, 2, axis=0\n",
    ").swaplevel(0, 1, axis=0)\n",
    "# df_episodes_read_multi_setindex.index\n",
    "# df_episodes_read_multi_setindex.columns\n",
    "df_episodes_read_multi_setindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## append new episode to the specific parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode4 = dfs_episode.copy()\n",
    "dfs_episode4.index = dfs_episode3.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(8, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode4.index = dfs_episode3.index.set_levels(\n",
    "    [[trucks_by_id[\"VB4\"].vid], [drivers_by_id[\"zheng-longfei\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "# dfs_episode4\n",
    "dfs_episode4 = dfs_episode4.swaplevel(1, 2, axis=0).swaplevel(0, 1, axis=0)\n",
    "dfs_episode4\n",
    "\n",
    "# dfs_episode5 = dfs_episode.copy()\n",
    "# dfs_episode5.index = dfs_episode3.index.set_levels([episodestart-pd.Timedelta(9,'d')], level='episode')\n",
    "# df_episodes_read_multi_setindex.columns\n",
    "# df_episodes_read_multi_setindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_new = pd.concat([df_episodes_read_multi_setindex, dfs_episode4], axis=0)\n",
    "dfs_episodes_new.index.names = [\"episodestart\", \"vehicle\", \"driver\", \"timestamp\"]\n",
    "dfs_episodes_new\n",
    "dfs_episodes_new.columns\n",
    "dfs_episodes_new.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save new dataframe back to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_new_flat = dfs_episodes_new.copy()\n",
    "dfs_episodes_new_flat = dfs_episodes_new_flat.reset_index(\n",
    "    level=[\"vehicle\", \"driver\", \"episodestart\"]\n",
    ")\n",
    "dfs_episodes_new_flat.columns\n",
    "dfs_episodes_new_flat.index\n",
    "dfs_episodes_new_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding index\n",
    "# from datetime import datetime\n",
    "\n",
    "# flat_idx = dfs_episodes_new_flat.index.to_flat_index()\n",
    "# flat_idx = [\n",
    "#     f'{x[0].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}_{x[1].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}'\n",
    "#     if x[1] != ''\n",
    "#     else f'{x[0].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}'\n",
    "#     for x in flat_idx\n",
    "# ]\n",
    "# # flat_idx\n",
    "\n",
    "# encoding columns\n",
    "flat_cols = dfs_episodes_new_flat.columns.to_flat_index()\n",
    "# flat_cols\n",
    "# flat_cols = [\n",
    "#     f'{x[0]}_{x[1]}_{x[2].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}_{x[3]}'\n",
    "#     if (x[1] != '' and x[3] not in ('', pd.NaT, str(pd.NA)))\n",
    "#     else f'{x[0]}_{x[1]}_{x[2].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}_'\n",
    "#     if (x[1] != '' and x[3] in ('', pd.NaT, str(pd.NA)))\n",
    "#     else f'{x[0]}__{x[2].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}_'\n",
    "#     if (x[2] not in ('', pd.NaT, str(pd.NA)))\n",
    "#     else f'{x[0]}___'\n",
    "#     for x in flat_cols\n",
    "# ]\n",
    "flat_cols = [\n",
    "    f\"{x[0]}_{x[1]}_{x[2]}\"\n",
    "    if (x[1] != \"\" and x[2] not in (\"\", pd.NaT, str(pd.NA)))\n",
    "    else f\"{x[0]}_{x[1]}_\"\n",
    "    if (x[1] != \"\" and x[2] in (\"\", pd.NaT, str(pd.NA)))\n",
    "    else f\"{x[0]}__{x[2]}\"\n",
    "    if (x[2] not in (\"\", pd.NaT, str(pd.NA)))\n",
    "    else f\"{x[0]}__\"\n",
    "    for x in flat_cols\n",
    "]\n",
    "flat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episodes_new_flat.columns = flat_cols\n",
    "# dfs_episodes_new_flat.index = flat_idx\n",
    "dfs_episodes_new_flat[\"vehicle__\"] = dfs_episodes_new_flat[\"vehicle__\"].astype(\n",
    "    \"category\"\n",
    ")\n",
    "dfs_episodes_new_flat[\"driver__\"] = dfs_episodes_new_flat[\"driver__\"].astype(\"category\")\n",
    "dfs_episodes_new_flat[\"episodestart__\"] = dfs_episodes_new_flat[\n",
    "    \"episodestart__\"\n",
    "].astype(\"datetime64[ns]\")\n",
    "# dfs_episodes_new_flat.index.name = 'episodestart_timestamp'\n",
    "dfs_episodes_new_flat.index\n",
    "dfs_episodes_new_flat.dtypes\n",
    "# dfs_episodes_new_flat.columns.name = 'episodestart_timestamp'\n",
    "dfs_episodes_new_flat.columns\n",
    "dfs_episodes_new_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ddf_episodes_new = dd.from_pandas(dfs_episodes_new_flat, npartitions=1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "ddf_episodes_new.dtypes\n",
    "# dfs_episodes_new_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "custom_metadata = {\n",
    "    b\"eos\": b'{\"length\":[6, 600, 5],\"timezeone\":\"sh\",\"units\":[\"kph\",\"pct\",\"pct\"],\"data_propensity\":[50, 1, 4],\"Dataset Description\": \"MP vehicle from TBox\"}'\n",
    "}\n",
    "\n",
    "try:\n",
    "    with ProgressBar():\n",
    "        ddf_episodes_new.to_parquet(\n",
    "            \"eos_complete_episodes\",\n",
    "            engine=\"pyarrow\",\n",
    "            compression=\"snappy\",\n",
    "            partition_on=[\"vehicle__\", \"driver__\", \"episodestart__\"],\n",
    "            write_metadata_file=True,\n",
    "            custom_metadata=custom_metadata,\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\n",
    "    \"eos_complete_episodes\",\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    "    ignore_metadata_file=False,\n",
    "    infer_divisions=True,\n",
    ")\n",
    "pq_meta = pq.read_metadata(\"eos_episodes/_common_metadata\")\n",
    "custom_meta_info = pq_meta.metadata[b\"eos\"]\n",
    "custom_meta_info = json.loads(custom_meta_info)\n",
    "for key, val in custom_meta_info.items():\n",
    "    print(f\"{key}: {val}\")\n",
    "ddf.dtypes\n",
    "df = ddf.compute()\n",
    "\n",
    "# decoding columns index\n",
    "multi_tpl = [tuple(col.split(\"_\")) for col in df.columns]\n",
    "multi_col = pd.MultiIndex.from_tuples(multi_tpl)\n",
    "i1 = multi_col.get_level_values(0)\n",
    "i1 = [\"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i1]\n",
    "i2 = multi_col.get_level_values(\n",
    "    1\n",
    ")  # must be null string instead of the default pd.NA or np.nan\n",
    "i2 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i2\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "i3 = multi_col.get_level_values(\n",
    "    2\n",
    ")  # must be null string instead of the default pd.NA or np.nan\n",
    "i3 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else int(idx) for idx in i3\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "\n",
    "\n",
    "multi_col = pd.MultiIndex.from_arrays([i1, i2, i3])\n",
    "multi_col.names = [\"tuple\", \"rows\", \"idx\"]\n",
    "multi_col\n",
    "\n",
    "# # decoding index\n",
    "# multi_tuple = [tuple(idx.split('_')) for idx in df.index]\n",
    "# multi_idx = pd.MultiIndex.from_tuples(multi_tuple)\n",
    "\n",
    "# i0 = multi_idx.get_level_values(\n",
    "#     0\n",
    "# )  # must be null string instead of the default pd.NA or np.nan\n",
    "# i0 = [\n",
    "#     ''\n",
    "#     if str(idx) in (str(pd.NA), 'nan', '')\n",
    "#     else datetime.strptime(idx, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     for idx in i0\n",
    "# ]  # convert index of level 2 type to int and '' if NA\n",
    "# i1 = multi_idx.get_level_values(\n",
    "#     1\n",
    "# )  # must be null string instead of the default pd.NA or np.nan\n",
    "# i1 = [\n",
    "#     ''\n",
    "#     if str(idx) in (str(pd.NA), 'nan', '')\n",
    "#     else datetime.strptime(idx, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     for idx in i1\n",
    "# ]  # convert index of level 2 type to int and '' if NA\n",
    "# df_episodes_read_multiidx = df_episodes_read.copy()\n",
    "# multi_idx = pd.MultiIndex.from_arrays([i0, i1], names=('episodestart', 'timestamp'))\n",
    "#\n",
    "# multi_idx.names = ['episodestart', 'timestamp']\n",
    "\n",
    "df.columns = multi_col\n",
    "# df.index = multi_idx\n",
    "\n",
    "df = df.set_index([\"vehicle\", \"driver\", \"episodestart\", df.index])\n",
    "df.index.dtypes\n",
    "df.index\n",
    "# len(multi_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add rows to a partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\n",
    "    \"eos_complete_episodes\",\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    "    ignore_metadata_file=False,\n",
    "    infer_divisions=True,\n",
    ")\n",
    "ddf.index\n",
    "ddf.npartitions\n",
    "ddf.divisions\n",
    "ddf.dtypes\n",
    "\n",
    "# ddf['episodestart'] = ddf['episodestart'].astype('datetime64[ns]')  # error,  not allowed for dask dataframe\n",
    "# ddf.assign(episodestart=ddf['episodestart'].astype('datetime64[ns]'))\n",
    "ddf = ddf[\"episodestart\"].astype(\"datetime64[ns]\")\n",
    "ddf.dtypes\n",
    "# ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode5 = dfs_episode4.copy()\n",
    "dfs_episode5.index = dfs_episode4.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(9, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode5.index = dfs_episode4.index.set_levels(\n",
    "    [[trucks_by_id[\"MP74\"].vid], [drivers_by_id[\"zheng-longfei\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "# dfs_episode5 = dfs_episode5.swaplevel(0,1, axis=0).swaplevel(1,2,axis=0)\n",
    "dfs_episode5 = dfs_episode5.reset_index(level=[\"vehicle\", \"driver\", \"episodestart\"])\n",
    "\n",
    "dfs_episode5[\"vehicle\"] = dfs_episode5[\"vehicle\"].astype(\"category\")\n",
    "dfs_episode5[\"driver\"] = dfs_episode5[\"driver\"].astype(\"category\")\n",
    "# dfs_episode5['episodestart'] = dfs_episode5['episodestart'].astype('category')\n",
    "dfs_episode5.dtypes\n",
    "\n",
    "\n",
    "# encoding columns index\n",
    "dfs_episode5.columns = [\n",
    "    f\"{x[0]}_{x[1]}_{x[2]}\"\n",
    "    if (x[1] != \"\" and x[2] != \"\")\n",
    "    else f\"{x[0]}_{x[1]}_\"\n",
    "    if (x[1] != \"\" and x[2] == \"\")\n",
    "    else f\"{x[0]}__{x[2]}\"  # !!! dunder!!!\n",
    "    if (x[2] != \"\")\n",
    "    else f\"{x[0]}__\"\n",
    "    for x in dfs_episode5.columns.to_flat_index()\n",
    "]\n",
    "# df_episode_new.index = [\n",
    "#     f'{x[0].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}_{x[1].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}'\n",
    "#     if x[1] != ''\n",
    "#     else f'{x[0].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}'\n",
    "#     for x in dfs_episode5.index.to_flat_index()\n",
    "# ]\n",
    "# df_episode_new.dtypes\n",
    "dfs_episode5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode6 = dfs_episode4.copy()\n",
    "dfs_episode6.index = dfs_episode4.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(19, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode6.index = dfs_episode4.index.set_levels(\n",
    "    [[trucks_by_id[\"MP73\"].vid], [drivers_by_id[\"wang-cheng\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "# dfs_episode6 = dfs_episode5.swaplevel(0, 1, axis=0).swaplevel(1, 2, axis=0)\n",
    "dfs_episode6 = dfs_episode6.reset_index(level=[\"vehicle\", \"driver\", \"episodestart\"])\n",
    "\n",
    "dfs_episode6[\"vehicle\"] = dfs_episode6[\"vehicle\"].astype(\"category\")\n",
    "dfs_episode6[\"driver\"] = dfs_episode6[\"driver\"].astype(\"category\")\n",
    "# dfs_episode6['episodestart'] = dfs_episode6['episodestart'].astype('category')\n",
    "dfs_episode6.dtypes\n",
    "# encoding columns index\n",
    "dfs_episode6.columns = [\n",
    "    f\"{x[0]}_{x[1]}_{x[2]}\"\n",
    "    if (x[1] != \"\" and x[2] != \"\")\n",
    "    else f\"{x[0]}_{x[1]}_\"\n",
    "    if (x[1] != \"\" and x[2] == \"\")\n",
    "    else f\"{x[0]}__{x[2]}\"  # !!! dunder!!!\n",
    "    if (x[2] != \"\")\n",
    "    else f\"{x[0]}__\"\n",
    "    for x in dfs_episode6.columns.to_flat_index()\n",
    "]\n",
    "# dfs_episode6.index = [\n",
    "#     f'{x[0].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}_{x[1].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}'\n",
    "#     if x[1] != ''\n",
    "#     else f'{x[0].strftime(\"%Y-%m-%dT%H:%M:%S.%f\")}'\n",
    "#     for x in dfs_episode6.index.to_flat_index()\n",
    "# ]\n",
    "# df_episode_new.dtypes\n",
    "dfs_episode6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoding single dataframe of multiindex into dask single index dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_read = dd.read_parquet(\n",
    "    \"eos_complete_episodes\",\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    "    ignore_metadata_file=False,\n",
    "    infer_divisions=True,\n",
    ")\n",
    "# df_all = ddf_read.compute()\n",
    "# df_all\n",
    "# idx = pd.IndexSlice\n",
    "# col_epistart = ddf_read.loc[:, 'episodestart__'].astype('datetime64[ns]').compute()\n",
    "# col_epistart\n",
    "#\n",
    "# ddf_read.loc[:, 'episodestart__'] = ddf_read.loc[:, 'episodestart__'].astype(\n",
    "#     'datetime64[ns]'\n",
    "# )\n",
    "ddf_read[\"episodestart__\"] = ddf_read[\"episodestart__\"].astype(\"datetime64[ns]\")\n",
    "ddf_read.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf_episodes_new = dd.concat([dfs_episode5, dfs_episode6])\n",
    "# ddf_combine = dd.concat([ddf_read, ddf_episodes_new])\n",
    "ddf_combine = dd.concat([ddf_read, dfs_episode5, dfs_episode6])\n",
    "ddf_combine.compute()\n",
    "ddf_combine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf_list = []\n",
    "# for n in range(ddf_read.npartitions):\n",
    "#     ddf_list.append(ddf_read.partitions[n])\n",
    "#     # ddf_list[n].compute()\n",
    "# len(ddf_list)\n",
    "# type(ddf_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_list = [dfs_episode5, dfs_episode6]\n",
    "# df_attach = []\n",
    "# for df in df_new_list:\n",
    "#     bHit = False\n",
    "#     for i, ddf in enumerate(ddf_list):\n",
    "#         # if dfs_episode_new['vehicle']\n",
    "#         print(f\"{i}\")\n",
    "#         # df = ddf.compute()\n",
    "#         # ddf.columns\n",
    "#         # ddf.dtypes\n",
    "#         # type(ddf)\n",
    "#         vehicle = ddf['vehicle__'].compute()[0]\n",
    "#         driver = ddf['driver__'].compute()[0]\n",
    "#         # df_episode_new = df_episode_new.append(ddf)\n",
    "#         if df['vehicle__'][0] == vehicle and df['driver__'][0] == driver:\n",
    "#             bHit = True\n",
    "#             print(\n",
    "#                 f'hit {i}{\"st\" if i==1 else \"nd\" if i==2 else \"rd\" if i==3 else \"th\"} partition'\n",
    "#             )\n",
    "#             # ddf_list[i] = dd.concat([ddf, df], axis=0)\n",
    "#             df_attach.append(df)\n",
    "#             # append ddf to dfs_episode_new\n",
    "#\n",
    "#     if bHit == False:\n",
    "#         print('no hit')\n",
    "#         df_attach.append(df)\n",
    "#         # append ddf to dfs_episode_new\n",
    "#\n",
    "#\n",
    "# #     c_ep = df_episode_new['ep\n",
    "#     dfs_episode_new = dfs_episode_newappend(ddf)\n",
    "# print(f\"splicing dfs_episode_new {c_ep} with\n",
    "# df_attach.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_attach[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf_list.append(df_attach[0])\n",
    "# ddf_list[0].dtypes\n",
    "# ddf_all = dd.concat(ddf_list, axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf_all.compute()os.getcwd()\n",
    "custom_metadata = {\n",
    "    b\"eos\": b'{\"length\":[8, 800, 8],\"timezeone\":\"sh\",\"units\":[\"kph\",\"pct\",\"pct\"],\"data_propensity\":[50, 1, 4],\"Dataset Description\": \"MP vehicle from TBox\"}'\n",
    "}\n",
    "\n",
    "try:\n",
    "    with ProgressBar():\n",
    "        ddf_combine.to_parquet(\n",
    "            \"eos_combine_episodes\",\n",
    "            engine=\"pyarrow\",\n",
    "            compression=\"snappy\",\n",
    "            partition_on=[\"vehicle__\", \"driver__\", \"episodestart__\"],\n",
    "            write_metadata_file=True,\n",
    "            custom_metadata=custom_metadata,\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf_all.compute()\n",
    "ddf = dd.read_parquet(\n",
    "    \"eos_combine_episodes\",\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    "    ignore_metadata_file=False,\n",
    "    infer_divisions=True,\n",
    ")\n",
    "pq_meta = pq.read_metadata(\"eos_combine_episodes/_common_metadata\")\n",
    "# print(table_meta)\n",
    "# print(table_meta.metadata[b'eos'])\n",
    "custom_meta_info = pq_meta.metadata[b\"eos\"]\n",
    "custom_meta_info = json.loads(custom_meta_info)\n",
    "# custom_meta_info\n",
    "\n",
    "for key, val in custom_meta_info.items():\n",
    "    print(f\"{key}: {val}\")\n",
    "\n",
    "df = ddf.compute()\n",
    "\n",
    "multi_tpl = [tuple(col.split(\"_\")) for col in ddf.columns]\n",
    "multi_col = pd.MultiIndex.from_tuples(multi_tpl)\n",
    "i1 = multi_col.get_level_values(0)\n",
    "i1 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i1\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "i2 = multi_col.get_level_values(\n",
    "    1\n",
    ")  # must be null string instead of the default pd.NA or np.nan\n",
    "i2 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i2\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "i3 = multi_col.get_level_values(\n",
    "    2\n",
    ")  # must be null string instead of the default pd.NA or np.nan\n",
    "i3 = [\n",
    "    \"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else int(idx) for idx in i3\n",
    "]  # convert index of level 2 type to int and '' if NA\n",
    "\n",
    "multi_col = pd.MultiIndex.from_arrays([i1, i2, i3])\n",
    "multi_col.names = [\"tuple\", \"rows\", \"idx\"]\n",
    "df.columns = multi_col\n",
    "\n",
    "# multi_idx = [tuple(idx.split('_')) for idx in ddf.index]\n",
    "# multi_idx = pd.MultiIndex.from_tuples(multi_idx)\n",
    "# i0 = multi_idx.get_level_values(\n",
    "#     0\n",
    "# )  # must be null string instead of the default pd.NA or np.nan\n",
    "# i0 = [\n",
    "#     ''\n",
    "#     if str(idx) in (str(pd.NA), 'nan', '')\n",
    "#     else datetime.strptime(idx, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     for idx in i0\n",
    "# ]  # convert index of level 2 type to int and '' if NA\n",
    "# i1 = multi_idx.get_level_values(\n",
    "#     1\n",
    "# )  # must be null string instead of the default pd.NA or np.nan\n",
    "# i1 = [\n",
    "#     ''\n",
    "#     if str(idx) in (str(pd.NA), 'nan', '')\n",
    "#     else datetime.strptime(idx, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "#     for idx in i1\n",
    "# ]  # convert index of level 2 type to int and '' if NA\n",
    "# multi_idx = pd.MultiIndex.from_arrays([i0, i1], names=('episodestart', 'timestamp'))\n",
    "# df.index = multi_idx\n",
    "\n",
    "\n",
    "df = df.set_index([\"vehicle\", \"driver\", \"episodestart\", df.index])\n",
    "df\n",
    "df.columns\n",
    "df.index\n",
    "# len(multi_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Quadratuple from parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\n",
    "    \"eos_combine_episodes\",\n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\",\n",
    "    ignore_metadata_file=False,\n",
    "    infer_divisions=True,\n",
    ")\n",
    "df = ddf.compute()\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_list = []\n",
    "for n in range(ddf.npartitions):\n",
    "    ddf_list.append(ddf.partitions[n])\n",
    "len(ddf_list)\n",
    "type(ddf_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Quadratuple from parquet files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vehicle = \"VB7\"\n",
    "target_driver = \"wang-cheng\"\n",
    "partition = []\n",
    "for i, ddf in enumerate(ddf_list):\n",
    "    # if dfs_episode_new['vehicle']\n",
    "    print(f\"{i}\")\n",
    "    # df = ddf.compute()\n",
    "    # ddf.columns\n",
    "    # ddf.dtypes\n",
    "    vehicle = ddf[\"vehicle__\"].compute()[0]\n",
    "    driver = ddf[\"driver__\"].compute()[0]\n",
    "    # df_episode_new = df_episode_new.append(ddf)\n",
    "    if target_vehicle == vehicle and target_driver == driver:\n",
    "        bHit = True\n",
    "        print(\n",
    "            f'hit {i}{\"st\" if i==1 else \"nd\" if i==2 else \"rd\" if i==3 else \"th\"} partition'\n",
    "        )\n",
    "        # k = i\n",
    "        partition.append(i)\n",
    "\n",
    "        # ddf_list[i] = dd.concat([ddf, df], axis=0)\n",
    "        # append ddf to dfs_episode_new\n",
    "\n",
    "if bHit == False:\n",
    "    print(\"no hit\")\n",
    "    # ddf_list.append(df_episode_new)\n",
    "    # append ddf to dfs_episode_new\n",
    "\n",
    "partition\n",
    "ddf_target = dd.concat([ddf_list[i] for i in partition], axis=0)\n",
    "# ddf_target\n",
    "# # ddf_target.head()\n",
    "df_target = ddf_target.compute()\n",
    "df_target\n",
    "# # df_target\n",
    "\n",
    "# #     c_ep = df_episode_new['ep\n",
    "# #     dfs_episode_new = dfs_episode_newappend(ddf)\n",
    "# # print(f\"splicing dfs_episode_new {c_ep} with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_sample = ddf_target.sample(frac=0.2).compute()\n",
    "tuple_sample[\"episodestart__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_target.sample(frac=0.2).compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
