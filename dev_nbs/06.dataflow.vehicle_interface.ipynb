{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e85c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import concurrent.futures\n",
    "import logging\n",
    "import os\n",
    "import queue\n",
    "import time\n",
    "from pathlib import Path\n",
    "from threading import Event, current_thread\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e525191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from .consumer import Consumer  # type: ignore\n",
    "from .hetero_filter import HeteroFilter  # type: ignore\n",
    "from .pipeline import Pipeline  # type: ignore\n",
    "from .pipeline_dq import PipelineDQ  # type: ignore\n",
    "from .producer import Producer  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eos.data_io.config import Driver, Truck, CANMessenger\n",
    "from eos.data_io.eos_struct import RawType\n",
    "from eos.comm.tbox.utils.tbox_can_exceptions import TBoxCanException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb93923",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class VehicleInterface(\n",
    "    Producer[RawType, str],\n",
    "    Consumer[pd.DataFrame],\n",
    "    HeteroFilter[RawType, pd.DataFrame],\n",
    "):\n",
    "    \"\"\"\n",
    "    VehicleInterface is Producer(get vehicle status), Consumer(flasher) and Filter(generate observation data)\n",
    "    \"\"\"\n",
    "\n",
    "    truck: Truck\n",
    "    driver: Driver\n",
    "    can_server: CANMessenger\n",
    "    resume: bool = False\n",
    "    data_dir: Optional[Path] = None\n",
    "    flash_count: int = 0\n",
    "    episode_count: int = 0\n",
    "    vcu_calib_table_row_start: int = 0\n",
    "    torque_table_default: Optional[pd.DataFrame] = None\n",
    "    torque_table_live: Optional[pd.DataFrame] = None\n",
    "    epi_countdown_time: float = 3.0\n",
    "    logger: Optional[logging.Logger] = None\n",
    "    dict_logger: Optional[dict] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.logger = self.logger.getChild((self.__str__()))\n",
    "        self.dict_logger = self.dict_logger\n",
    "\n",
    "        if self.data_dir is None:\n",
    "            self.data_dir = Path(\".\")\n",
    "        self.init_vehicle()\n",
    "\n",
    "        # super().__post_init__()\n",
    "        self.logger.info(\"Vehicle interface initialized\")\n",
    "\n",
    "    def init_vehicle(self) -> None:\n",
    "        proj_root = (\n",
    "            self.data_dir.resolve().parent.parent.parent\n",
    "        )  # assuming data_dir is a stepchild of the project root/data, otherwise throw Exception\n",
    "\n",
    "        if self.resume:\n",
    "            files = sorted(self.data_dir.glob(\"last_table*.csv\"))\n",
    "            if not files:\n",
    "                self.logger.info(\n",
    "                    f\"{{'header': 'No last table found, start from default calibration table'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                latest_file = proj_root / \"eos/data_io/config\" / \"vb7_init_table.csv\"\n",
    "            else:\n",
    "                self.logger.info(\n",
    "                    f\"{{'header': 'Resume last table'}}\", extra=self.dict_logger\n",
    "                )\n",
    "                latest_file = max(files, key=os.path.getctime)\n",
    "\n",
    "        else:\n",
    "            self.logger.info(\n",
    "                f\"{{'header': 'Use default calibration table'}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            latest_file = proj_root / \"eos/data_io/config\" / \"vb7_init_table.csv\"\n",
    "\n",
    "        self.torque_table_default = pd.read_csv(latest_file, index_col=0)\n",
    "        self.torque_table_default.columns = self.torque_table_default.columns.astype(\n",
    "            np.float64\n",
    "        )\n",
    "\n",
    "        # pandas deep copy of the default table (while numpy shallow copy is sufficient)\n",
    "        self.torque_table_live = self.torque_table_default.copy(\n",
    "            deep=True\n",
    "        )  # make sure it's a deep copy, the live table should be modified by the flash thread\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'Start flash initial table'}}\", extra=self.dict_logger\n",
    "        )\n",
    "        self.flash_vehicle(self.torque_table_default)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def flash_vehicle(self, torque_table: pd.DataFrame) -> None:\n",
    "        pass\n",
    "\n",
    "    def hmi_control(\n",
    "        self,\n",
    "        hmi_pipeline: Pipeline[str],\n",
    "        observe_pipeline: Pipeline[pd.DataFrame],\n",
    "        start_event: Event,\n",
    "        stop_event: Event,\n",
    "        interrupt_event: Event,\n",
    "        countdown_event: Event,\n",
    "        exit_event: Event,\n",
    "        flash_event: Event,\n",
    "    ) -> None:\n",
    "        thread = current_thread()\n",
    "        thread.name = \"hmi_control\"\n",
    "        logger_hmi_control = self.logger.getChild(\"hmi_control\")\n",
    "        logger_hmi_control.propagate = True\n",
    "        logger_hmi_control.info(\n",
    "            f\"{{'header': 'hmi_control thread start!'}}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "        while exit_event.is_set() is False:\n",
    "            try:\n",
    "                status = hmi_pipeline.get(\n",
    "                    block=True, timeout=3.0\n",
    "                )  # default block = True\n",
    "\n",
    "            except TimeoutError:\n",
    "                logger_hmi_control.info(\n",
    "                    f\"{{'header': 'hmi pipeline timeout'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                continue\n",
    "            except queue.Empty:\n",
    "                # logger_hmi_control.info(\n",
    "                #     f\"{{'header': 'hmi pipeline empty'}}\",\n",
    "                # )\n",
    "                continue\n",
    "\n",
    "            if status == \"begin\":\n",
    "                observe_pipeline.clear()\n",
    "                start_event.set()\n",
    "                stop_event.clear()\n",
    "                interrupt_event.clear()\n",
    "                logger_hmi_control.info(\n",
    "                    f\"{{'header': 'Episode will start!!!'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "\n",
    "            elif status == \"end_valid\":\n",
    "                # set flag for countdown thread\n",
    "                countdown_event.set()\n",
    "\n",
    "                logger_hmi_control.info(\n",
    "                    f\"{{'header': 'Episode end starts countdown!'}}\"\n",
    "                )\n",
    "            elif status == \"end_invalid\":\n",
    "                start_event.clear()  # pause data collection\n",
    "                interrupt_event.set()\n",
    "\n",
    "                logger_hmi_control.info(\n",
    "                    f\"{{'header': 'Episode is interrupted!!!'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                observe_pipeline.clear()\n",
    "                self.episode_count += 1  # invalid round increments\n",
    "            elif status == \"exit\":\n",
    "                start_event.clear()\n",
    "                countdown_event.set()  # cancel countdown, let countdown thread exit\n",
    "\n",
    "                observe_pipeline.clear()\n",
    "                self.episode_count += 1\n",
    "                interrupt_event.set()\n",
    "                flash_event.set()  # set the flash event here for cruncher and kvaser/cloud filter thread\n",
    "                countdown_event.set()  # cancel countdown, let countdown thread exit\n",
    "                if not exit_event.is_set():\n",
    "                    exit_event.set()\n",
    "                break  # exit hmi control thread\n",
    "        # exit hmi control thread\n",
    "        logger_hmi_control.info(\n",
    "            f\"{{'header': 'HMI control dies!!!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def filter(\n",
    "        self,\n",
    "        in_pipeline: PipelineDQ[RawType],\n",
    "        out_pipeline: Pipeline[pd.DataFrame],\n",
    "        start_event: Optional[Event],\n",
    "        stop_event: Optional[Event],\n",
    "        interrupt_event: Optional[Event],  # input event\n",
    "        flash_event: Optional[Event],\n",
    "        exit_event: Optional[Event],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Produce data into the pipeline\n",
    "        main entry to the capture thread\n",
    "        sub-thread method\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def init_internal_pipelines(\n",
    "        self,\n",
    "    ) -> Tuple[PipelineDQ[RawType], Pipeline[str]]:\n",
    "        \"\"\"\n",
    "        initialize types of raw_pipeline and hmi_pipeline\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def ignite(\n",
    "        self,\n",
    "        observe_pipeline: Pipeline[pd.DataFrame],\n",
    "        flash_pipeline: Pipeline[pd.DataFrame],\n",
    "        start_event: Event,\n",
    "        stop_event: Event,\n",
    "        interrupt_event: Event,\n",
    "        flash_event: Event,\n",
    "        exit_event: Event,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ignite\n",
    "        creating the ThreadPool for handing the hmi, data capturing and data processing\n",
    "        main entry to the vehicle thread. will spawn three further threads for\n",
    "            - input processing, HMI control and output processing\n",
    "            - data into the pipeline\n",
    "            - handle the input pipeline\n",
    "            - guide observation data into the output pipeline\n",
    "            - start/stop/interrupt/countdown/exit event to control the state machine\n",
    "        main entry to the capture thread\n",
    "        \"\"\"\n",
    "\n",
    "        thread = current_thread()\n",
    "        thread.name = \"vehicle_interface_ignite\"\n",
    "        # internal pipelines, raw_pipelines are different for kvaser and cloud interface\n",
    "        raw_pipeline, hmi_pipeline = self.init_internal_pipelines()\n",
    "\n",
    "        # internal event\n",
    "        countdown_event = Event()\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'ignite Thread Pool starts!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=5, thread_name_prefix='Vehicle_Interface'\n",
    "        ) as executor:\n",
    "            executor.submit(\n",
    "                self.produce,\n",
    "                raw_pipeline,\n",
    "                hmi_pipeline,  # self.hmi_pipeline not required for cloud interface\n",
    "                exit_event,\n",
    "            )\n",
    "\n",
    "            executor.submit(\n",
    "                self.hmi_control,  # will delegate to concrete the hmi control method\n",
    "                hmi_pipeline,\n",
    "                observe_pipeline,\n",
    "                start_event,\n",
    "                stop_event,\n",
    "                interrupt_event,\n",
    "                countdown_event,\n",
    "                exit_event,\n",
    "                flash_event,\n",
    "            )\n",
    "\n",
    "            executor.submit(\n",
    "                self.countdown,  # countdown thread\n",
    "                observe_pipeline,\n",
    "                start_event,\n",
    "                countdown_event,\n",
    "                stop_event,\n",
    "                exit_event,\n",
    "            )\n",
    "\n",
    "            executor.submit(\n",
    "                self.filter,\n",
    "                raw_pipeline,\n",
    "                observe_pipeline,\n",
    "                start_event,\n",
    "                stop_event,  # not used\n",
    "                interrupt_event,  # not used\n",
    "                flash_event,  # flash_event,\n",
    "                exit_event,\n",
    "            )\n",
    "\n",
    "            executor.submit(\n",
    "                self.consume,  # flash thread\n",
    "                flash_pipeline,\n",
    "                start_event,\n",
    "                stop_event,\n",
    "                interrupt_event,\n",
    "                exit_event,\n",
    "                flash_event,\n",
    "            )\n",
    "\n",
    "        # exit the thread\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'ignite Thread Pool dies!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def produce(\n",
    "        self,\n",
    "        raw_pipeline: PipelineDQ[RawType],\n",
    "        hmi_pipeline: Optional[Pipeline[str]] = None,\n",
    "        exit_event: Optional[Event] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Produce data into the pipeline\n",
    "        main entry to the capture thread\n",
    "        will spawn three further threads for input processing, HMI control and output processing\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def countdown(\n",
    "        self,\n",
    "        observe_pipeline: Pipeline[pd.DataFrame],  # output pipeline\n",
    "        start_event: Event,  # output event\n",
    "        countdown_event: Event,  # input event\n",
    "        stop_event: Event,  # output event\n",
    "        exit_event: Event,  # input event\n",
    "    ):\n",
    "        thread = current_thread()\n",
    "        thread.name = \"countdown\"\n",
    "        logger_countdown = self.logger.getChild(\"countdown\")\n",
    "        logger_countdown.propagate = True\n",
    "        logger_countdown.info(\n",
    "            f\"{{'header': 'countdown thread start!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "        while not exit_event.is_set():\n",
    "            logger_countdown.info(\n",
    "                f\"{{'header': 'wait for countdown'}}\", extra=self.dict_logger\n",
    "            )\n",
    "            countdown_event.wait()\n",
    "            if exit_event.is_set():\n",
    "                continue\n",
    "\n",
    "            # if episode done is triggered, sleep for the extension time\n",
    "            time.sleep(self.epi_countdown_time)\n",
    "            # cancel wait as soon as waking up\n",
    "            logger_countdown.info(\n",
    "                f\"{{'header': 'finish countdown'}}\", extra=self.dict_logger\n",
    "            )\n",
    "\n",
    "            start_event.clear()\n",
    "            stop_event.set()  # set valid stop signal only after countdown\n",
    "            observe_pipeline.clear()\n",
    "            self.episode_count += 1  # valid round increments\n",
    "\n",
    "            logger_countdown.info(\n",
    "                f\"{{'header': 'Episode done! free remote_flash and remote_get!'}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            countdown_event.clear()\n",
    "            # raise Exception(\"reset capture to stop\")\n",
    "\n",
    "        # exit countdown thread\n",
    "        logger_countdown.info(\n",
    "            f\"{{'header': 'Coutndown dies!!!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "    def consume(\n",
    "        self,\n",
    "        flash_pipeline: Pipeline[pd.DataFrame],\n",
    "        start_event: Optional[Event] = None,\n",
    "        stop_event: Optional[Event] = None,\n",
    "        interrupt_event: Optional[Event] = None,\n",
    "        exit_event: Optional[Event] = None,\n",
    "        flash_event: Optional[Event] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Consume data from the pipeline\n",
    "        main entry to the flash thread\n",
    "        data in pipeline is a tuple of (torque_table, flash_start_row)\n",
    "        \"\"\"\n",
    "        thread = current_thread()\n",
    "        thread.name = \"flash\"\n",
    "        flash_count = 0\n",
    "\n",
    "        logger_flash = self.logger.getChild(\"flash\")\n",
    "        logger_flash.propagate = True\n",
    "\n",
    "        logger_flash.info(\n",
    "            f\"{{'header': 'flash thread starts!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "        while not exit_event.is_set():\n",
    "            if (\n",
    "                not start_event.is_set()\n",
    "                or interrupt_event.is_set()\n",
    "                or stop_event.is_set()\n",
    "            ):\n",
    "                continue\n",
    "            try:\n",
    "                logger_flash.info(\n",
    "                    f\"{{'header': 'Flashing thread try to get a table!'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "\n",
    "                table = flash_pipeline.get(\n",
    "                    block=True, timeout=3\n",
    "                )  # default block = True\n",
    "\n",
    "            except TimeoutError:\n",
    "                logger_flash.info(\n",
    "                    f\"{{'header': '{flash_count}' TableQueue timeout}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                continue\n",
    "            except queue.Empty:\n",
    "                # if idle_count % 1000 == 0:\n",
    "                #     logger_flash.info(\n",
    "                #         f\"{{'header': 'E{epi_cnt} step: {step_count}' TableQueue empty.}}\",\n",
    "                #         extra=self.dict_logger)))  # type: ignore\n",
    "                # idle_count += 1\n",
    "                continue\n",
    "            else:\n",
    "                # get change budget : % of initial table\n",
    "                # dynamically get default table row as table.index changes\n",
    "                table_default_reduced = self.torque_table_default.loc[table.index]\n",
    "                torque_table_reduced = (\n",
    "                    table * self.truck.torque_budget + table_default_reduced\n",
    "                )\n",
    "\n",
    "                torque_table_reduced.clip(\n",
    "                    lower=table_default_reduced - self.truck.torque_budget,  # type: ignore\n",
    "                    upper=table_default_reduced * self.truck.torque_upper_bound,  # type: ignore\n",
    "                    inplace=True,\n",
    "                )\n",
    "\n",
    "                # create updated complete pedal map, only update the first few rows\n",
    "                # torque_table_live keeps changing as the cache of the changing pedal map\n",
    "                self.torque_table_live.loc[  # type: ignore\n",
    "                    table.index\n",
    "                ] = torque_table_reduced  # totally fine as pandas slicing operation! mypy is mean.\n",
    "\n",
    "                logger_flash.info(\n",
    "                    f\"{{'header': 'flash starts'}}\", extra=self.dict_logger\n",
    "                )\n",
    "\n",
    "                try:  # flash the vehicle\n",
    "                    self.flash_vehicle(self.torque_table_live)\n",
    "                except TBoxCanException as exc:\n",
    "                    flash_event.set()  # set the flash event here for cruncher and kvaser/cloud filter thread\n",
    "                    if exc.err_code == 4:  # xcp time out\n",
    "                        logger_flash.info(\n",
    "                            f\"{{'header': 'Flash thread exception: {exc.codes[exc.err_code]}'}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        interrupt_event.set()\n",
    "                        continue\n",
    "                    else:\n",
    "                        logger_flash.error(\n",
    "                            f\"{{'header': 'Flash thread exception: {exc.codes[exc.err_code]}'}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        exit_event.set()\n",
    "                        raise exc\n",
    "\n",
    "                except Exception as exc:\n",
    "                    logger_flash.info(\n",
    "                        f\"{{'header': 'Flash thread exception: {exc}'}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    raise exc\n",
    "\n",
    "                flash_event.set()  # set the flash event here for cruncher and kvaser/cloud filter thread\n",
    "\n",
    "                flash_count += 1\n",
    "                logger_flash.info(\n",
    "                    f\"{{'header': 'flash ends', 'count': {flash_count} }}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                # watch(flash_count)\n",
    "\n",
    "        if not flash_event.is_set():  # if flash event is not set, normal exit\n",
    "            logger_flash.info(\n",
    "                f\"{{'header': 'flash_evnet is not set when exit occurred!!!!'}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            flash_event.set()  # set the flash event here for cruncher and kvaser/cloud filter thread\n",
    "        else:  # if flash event is set, probably abnormal exit, GracefulKiller exit\n",
    "            logger_flash.info(\n",
    "                f\"{{'header': 'flash_event is set'}}\", extra=self.dict_logger\n",
    "            )\n",
    "\n",
    "        logger_flash.info(\n",
    "            f\"{{'header': 'Save the last table!!!!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "        last_table_store_path = (\n",
    "            self.data_dir.joinpath(  # there's no slash in the end of the string\n",
    "                \"last_table_\"\n",
    "                + \"-\"\n",
    "                + self.truck.vid\n",
    "                + \"-\"\n",
    "                + self.driver.pid\n",
    "                + \"-\"\n",
    "                + pd.Timestamp.now(self.truck.site.tz).isoformat()\n",
    "                + \".csv\"\n",
    "            )\n",
    "        )\n",
    "        with open(last_table_store_path, \"wb\"):\n",
    "            self.torque_table_live.to_csv(last_table_store_path)\n",
    "\n",
    "        logger_flash.info(\n",
    "            f\"{{'header': 'flash thread dies!!!!'}}\", extra=self.dict_logger\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
