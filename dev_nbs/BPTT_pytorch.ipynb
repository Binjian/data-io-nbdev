{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ef5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBPTT:\n",
    "    def __init__(self, one_step_module, loss_module, k1, k2, optimizer):\n",
    "        self.one_step_module = one_step_module\n",
    "        self.loss_module = loss_module\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.retain_graph = k1 < k2\n",
    "        # You can also remove all the optimizer code here, and the\n",
    "        # train function will just accumulate all the gradients in\n",
    "        # one_step_module parameters\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train(self, input_sequence, init_state):\n",
    "        states = [(None, init_state)]\n",
    "        for j, (inp, target) in enumerate(input_sequence):\n",
    "            state = states[-1][1].detach()\n",
    "            state.requires_grad = True\n",
    "            output, new_state = self.one_step_module(inp, state)\n",
    "            states.append((state, new_state))\n",
    "\n",
    "            while len(states) > self.k2:\n",
    "                # Delete stuff that is too old\n",
    "                del states[0]\n",
    "\n",
    "            if (j + 1) % self.k1 == 0:\n",
    "                loss = self.loss_module(output, target)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # backprop last module (keep graph only if they ever overlap)\n",
    "                start = time.time()\n",
    "                loss.backward(retain_graph=self.retain_graph)\n",
    "                for i in range(self.k2 - 1):\n",
    "                    # if we get all the way back to the \"init_state\", stop\n",
    "                    if states[-i - 2][0] is None:\n",
    "                        break\n",
    "                    curr_grad = states[-i - 1][0].grad\n",
    "                    states[-i - 2][1].backward(\n",
    "                        curr_grad, retain_graph=self.retain_graph\n",
    "                    )\n",
    "                print(\"bw: {}\".format(time.time() - start))\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "layer_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMod, self).__init__()\n",
    "        self.lin = nn.Linear(2 * layer_size, 2 * layer_size)\n",
    "\n",
    "    def forward(self, inp, state):\n",
    "        global idx\n",
    "        full_out = self.lin(torch.cat([inp, state], 1))\n",
    "        # out, new_state = full_out.chunk(2, dim=1)\n",
    "        out = full_out.narrow(1, 0, layer_size)\n",
    "        new_state = full_out.narrow(1, layer_size, layer_size)\n",
    "\n",
    "        def get_pr(idx_val):\n",
    "            def pr(*args):\n",
    "                print(\"doing backward {}\".format(idx_val))\n",
    "\n",
    "            return pr\n",
    "\n",
    "        new_state.register_hook(get_pr(idx))\n",
    "        out.register_hook(get_pr(idx))\n",
    "        print(\"doing fw {}\".format(idx))\n",
    "        idx += 1\n",
    "        return out, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_module = MyMod()\n",
    "loss_module = nn.MSELoss()\n",
    "input_sequence = [(torch.rand(200, layer_size), torch.rand(200, layer_size))] * seq_len\n",
    "optimizer = torch.optim.SGD(one_step_module.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b703e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = TBPTT(one_step_module, loss_module, 5, 5, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(input_sequence, torch.zeros(200, layer_size))\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
