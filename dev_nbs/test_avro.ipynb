{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c26be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eos import proj_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(proj_root / \"data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastavro import writer, reader, parse_schema\n",
    "\n",
    "schema = {\n",
    "    \"doc\": \"A weather reading.\",\n",
    "    \"name\": \"Weather\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"station\", \"type\": \"string\"},\n",
    "        {\"name\": \"time\", \"type\": \"long\"},\n",
    "        {\"name\": \"temp\", \"type\": \"int\"},\n",
    "    ],\n",
    "}\n",
    "parsed_schema = parse_schema(schema)\n",
    "\n",
    "# 'records' can be an iterable (including generator)\n",
    "records = [\n",
    "    {\"station\": \"011990-99999\", \"temp\": 0, \"time\": 1433269388},\n",
    "    {\"station\": \"011990-99999\", \"temp\": 22, \"time\": 1433270389},\n",
    "    {\"station\": \"011990-99999\", \"temp\": -11, \"time\": 1433273379},\n",
    "    {\"station\": \"012650-99999\", \"temp\": 111, \"time\": 1433275478},\n",
    "]\n",
    "\n",
    "# Writing\n",
    "with open(\"weather.avro\", \"wb\") as out:\n",
    "    writer(out, parsed_schema, records)\n",
    "\n",
    "# Reading\n",
    "with open(\"weather.avro\", \"rb\") as fo:\n",
    "    for record in reader(fo):\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea55958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from functools import reduce\n",
    "\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ordered_set import OrderedSet\n",
    "from eos.data_io.config import drivers, trucks_by_id, drivers_by_id\n",
    "from datetime import datetime\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "ts = pd.to_datetime(datetime.now())\n",
    "\n",
    "ss = np.arange(12)\n",
    "a1 = ss[:4].tolist()\n",
    "a2 = ss[4:8].tolist()\n",
    "a3 = ss[8:].tolist()\n",
    "ss = [a1, a2, a3]\n",
    "\n",
    "ts_ind = ts + pd.to_timedelta(np.arange(0, 4 * 20, 20), \"ms\")\n",
    "ss = np.arange(12)\n",
    "a1 = ss[:4]\n",
    "a2 = ss[4:8]\n",
    "a3 = ss[8:]\n",
    "df_ss = pd.DataFrame(\n",
    "    {\"timestep\": ts_ind, \"velocity\": a1, \"thrust\": a2, \"brake\": a3}\n",
    ")  # .set_index('timestep')\n",
    "df_ss.columns.name = \"qtuple\"\n",
    "\n",
    "state = df_ss.stack().swaplevel(0, 1)\n",
    "state.name = \"state\"\n",
    "state.index.names = [\"rows\", \"idx\"]\n",
    "state.sort_index(inplace=True)\n",
    "\n",
    "a = len(ss) + np.arange(15)\n",
    "speed_ser = pd.Series(np.linspace(40, 60, 3), name=\"speed\")\n",
    "row_array = a.reshape(3, 5).transpose()\n",
    "rows_df = pd.DataFrame(row_array)\n",
    "rows_df.columns = [f\"r{i}\" for i in np.arange(3)]\n",
    "\n",
    "ts_ind = ts + pd.to_timedelta(np.arange(5 * 20, 8 * 20, 20), \"ms\")\n",
    "ts_ser = pd.Series(ts_ind, name=\"timestep\")\n",
    "throttle_ser = pd.Series(np.linspace(0, 1.0, 5), name=\"throttle\")\n",
    "# throttle_ser\n",
    "dfs = [rows_df, ts_ser, speed_ser, throttle_ser]\n",
    "action = (\n",
    "    reduce(\n",
    "        lambda left, right: pd.merge(\n",
    "            left, right, how=\"outer\", left_index=True, right_index=True\n",
    "        ),\n",
    "        dfs,\n",
    "    )\n",
    "    .stack()\n",
    "    .swaplevel(0, 1)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "action.name = \"action\"\n",
    "action.index.names = [\"rows\", \"idx\"]\n",
    "\n",
    "reward = (\n",
    "    pd.DataFrame({\"work\": len(ss) + len(a), \"timestep\": ts_ind[0]}, index=[0])\n",
    "    .stack()\n",
    "    .swaplevel(0, 1)\n",
    "    .sort_index()\n",
    ")\n",
    "reward.index.names = [\"rows\", \"idx\"]\n",
    "reward.name = \"reward\"\n",
    "ts_ind = ts + pd.to_timedelta(5, \"s\") + pd.to_timedelta(np.arange(0, 4 * 20, 20), \"ms\")\n",
    "ss = (\n",
    "    np.arange(12) + len(ss) + len(a) + len(reward) - 1\n",
    ")  # exclude the timestamp in reward\n",
    "a1 = ss[:4]\n",
    "a2 = ss[4:8]\n",
    "a3 = ss[8:]\n",
    "\n",
    "nstate = (\n",
    "    pd.DataFrame({\"timestep\": ts_ind, \"velocity\": a1, \"thrust\": a2, \"brake\": a3})\n",
    "    .stack()\n",
    "    .swaplevel(0, 1)\n",
    "    .sort_index()\n",
    ")\n",
    "nstate.name = \"nstate\"\n",
    "nstate.index.names = [\"rows\", \"idx\"]\n",
    "\n",
    "timestamp = pd.Series([ts], name=\"timestamp\")\n",
    "timestamp.index = pd.MultiIndex.from_product(\n",
    "    [timestamp.index, [0]], names=[\"rows\", \"idx\"]\n",
    ")\n",
    "\n",
    "timestamp_index = (timestamp.name, \"\", 0)\n",
    "state_index = [(state.name, *i) for i in state.index]\n",
    "reward_index = [(reward.name, *i) for i in reward.index]\n",
    "action_index = [(action.name, *i) for i in action.index]\n",
    "nstate_index = [(nstate.name, *i) for i in nstate.index]\n",
    "multiindex = pd.MultiIndex.from_tuples(\n",
    "    [timestamp_index, *state_index, *action_index, *reward_index, *nstate_index]\n",
    ")\n",
    "observation_list = [timestamp, state, action, reward, nstate]\n",
    "observation = pd.concat(observation_list)\n",
    "observation.index = multiindex\n",
    "\n",
    "observation0 = observation.copy()\n",
    "observation0.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(1, \"h\")\n",
    "observation1 = observation.copy()\n",
    "observation1.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(2, \"h\")\n",
    "observation2 = observation.copy()\n",
    "observation2.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(3, \"h\")\n",
    "observation3 = observation.copy()\n",
    "observation3.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(4, \"h\")\n",
    "observation4 = observation.copy()\n",
    "observation4.loc[\"timestamp\", \"\", 0] = ts + pd.Timedelta(5, \"h\")\n",
    "observation_list = [\n",
    "    observation0,\n",
    "    observation1,\n",
    "    observation2,\n",
    "    observation3,\n",
    "    observation4,\n",
    "]\n",
    "\n",
    "dfs_epi = pd.concat(observation_list, axis=1).transpose()\n",
    "dfs_epi.columns.names = [\"qtuple\", \"rows\", \"idx\"]\n",
    "\n",
    "dfs_episode = dfs_epi.copy()\n",
    "dfs_episode.set_index((\"timestamp\", \"\", 0), inplace=True)\n",
    "dfs_episode.sort_index(axis=1, inplace=True)\n",
    "dfs_episode.index.name = \"timestamp\"\n",
    "\n",
    "state_cols_float = [(\"state\", col) for col in [\"brake\", \"thrust\", \"velocity\"]]\n",
    "action_cols_float = [(\"action\", col) for col in [\"r0\", \"r1\", \"r2\", \"speed\", \"throttle\"]]\n",
    "reward_cols_float = [(\"reward\", \"work\")]\n",
    "nstate_cols_float = [(\"nstate\", col) for col in [\"brake\", \"thrust\", \"velocity\"]]\n",
    "for col in action_cols_float + state_cols_float + reward_cols_float + nstate_cols_float:\n",
    "    dfs_episode[col[0], col[1]] = dfs_episode[col[0], col[1]].astype(\n",
    "        \"float\"\n",
    "    )  # float16 not allowed in parquet\n",
    "dfs_episode = pd.concat(\n",
    "    [dfs_episode], keys=[drivers_by_id[\"wang-cheng\"].pid], names=[\"driver\"]\n",
    ")\n",
    "dfs_episode = pd.concat(\n",
    "    [dfs_episode], keys=[trucks_by_id[\"VB7\"].vid], names=[\"vehicle\"]\n",
    ")\n",
    "episodestart = ts - pd.Timedelta(1, \"h\")\n",
    "dfs_episode = pd.concat([dfs_episode], keys=[ts], names=[\"episodestart\"])\n",
    "dfs_episode = dfs_episode.swaplevel(1, 0, axis=0)\n",
    "dfs_episode = dfs_episode.swaplevel(1, 2, axis=0)\n",
    "dfs_episode.sort_index(inplace=True)\n",
    "dfs_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_new = pd.to_datetime((datetime.now()))\n",
    "episodestart = ts_new - pd.Timedelta(2, \"d\")\n",
    "\n",
    "dfs_episode0 = dfs_episode.copy()\n",
    "dfs_episode0.index = dfs_episode0.index.set_levels([episodestart], level=\"episodestart\")\n",
    "dfs_episode0.index = dfs_episode0.index.set_levels(\n",
    "    [[trucks_by_id[\"VB7\"].vid], [drivers_by_id[\"zheng-longfei\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "ts_index = dfs_episode0.index.unique(level=\"timestamp\")\n",
    "idx_num = len(ts_index)\n",
    "drop_num = np.random.randint(low=1, high=idx_num - 1)\n",
    "ts_index_to_drop = np.random.choice(ts_index, drop_num, replace=False)\n",
    "dfs_episode0 = dfs_episode0.drop(index=ts_index_to_drop, level=\"timestamp\")\n",
    "# srs_episode0 = dfs_episode0.stack(level=['qtuple', 'rows', 'idx'])\n",
    "\n",
    "dfs_episode1 = dfs_episode.copy()\n",
    "dfs_episode1.index = dfs_episode1.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(3, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode1.index = dfs_episode1.index.set_levels(\n",
    "    [[trucks_by_id[\"MP73\"].vid], [drivers_by_id[\"wang-cheng\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "ts_index = dfs_episode1.index.unique(level=\"timestamp\")\n",
    "idx_num = len(ts_index)\n",
    "drop_num = np.random.randint(low=1, high=idx_num - 1)\n",
    "ts_index_to_drop = np.random.choice(ts_index, drop_num, replace=False)\n",
    "dfs_episode1 = dfs_episode1.drop(index=ts_index_to_drop, level=\"timestamp\")\n",
    "# srs_episode1 = dfs_episode1.stack(level=['qtuple', 'rows', 'idx'])\n",
    "\n",
    "dfs_episode2 = dfs_episode.copy()\n",
    "dfs_episode2.index = dfs_episode2.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(4, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode2.index = dfs_episode2.index.set_levels(\n",
    "    [[trucks_by_id[\"VB7\"].vid], [drivers_by_id[\"wang-cheng\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "ts_index = dfs_episode2.index.unique(level=\"timestamp\")\n",
    "idx_num = len(ts_index)\n",
    "drop_num = np.random.randint(low=1, high=idx_num - 1)\n",
    "ts_index_to_drop = np.random.choice(ts_index, drop_num, replace=False)\n",
    "dfs_episode2 = dfs_episode2.drop(index=ts_index_to_drop, level=\"timestamp\")\n",
    "# srs_episode2 = dfs_episode2.stack(level=['qtuple', 'rows', 'idx'])\n",
    "\n",
    "dfs_episode3 = dfs_episode.copy()\n",
    "dfs_episode3.index = dfs_episode3.index.set_levels(\n",
    "    [episodestart - pd.Timedelta(5, \"d\")], level=\"episodestart\"\n",
    ")\n",
    "dfs_episode3.index = dfs_episode3.index.set_levels(\n",
    "    [[trucks_by_id[\"MP73\"].vid], [drivers_by_id[\"zheng-longfei\"].pid]],\n",
    "    level=[\"vehicle\", \"driver\"],\n",
    "    verify_integrity=False,\n",
    ")\n",
    "ts_index = dfs_episode3.index.unique(level=\"timestamp\")\n",
    "idx_num = len(ts_index)\n",
    "drop_num = np.random.randint(low=1, high=idx_num - 1)\n",
    "ts_index_to_drop = np.random.choice(ts_index, drop_num, replace=False)\n",
    "dfs_episode3 = dfs_episode3.drop(index=ts_index_to_drop, level=\"timestamp\")\n",
    "# srs_episode3 = dfs_episode3.stack(level=['qtuple', 'rows', 'idx'])\n",
    "from functools import reduce\n",
    "\n",
    "episodes = [dfs_episode, dfs_episode0, dfs_episode1, dfs_episode2, dfs_episode3]\n",
    "try:\n",
    "    dfs_episode_all = reduce(\n",
    "        lambda left, right,: pd.concat([left, right], axis=0), episodes\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# dfs_episode_all.sort_index(inplace=True)\n",
    "# dfs_episode_all = dfs_episode_all.swaplevel(1, 0, axis=0)\n",
    "# dfs_episode_all = dfs_episode_all.swaplevel(1, 2, axis=0)\n",
    "dfs_episode_all.sort_index(inplace=True)\n",
    "dfs_episode_all = dfs_episode_all[[\"state\", \"action\", \"reward\", \"nstate\"]]\n",
    "display(\"dfs_episode_all\")\n",
    "# dfs_episode_all.index\n",
    "# dfs_episode_all.columns#\n",
    "#\n",
    "dfs_episode_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e250b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_episode\n",
    "# episodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "indices = dfs_episode.index\n",
    "# ep_start = indices.get_level_values(level='episodestart')[0]\n",
    "indices_dict = [\n",
    "    {indices.names[i]: level for i, level in enumerate(levels)} for levels in indices\n",
    "]\n",
    "episode_meta = indices_dict[0].copy()\n",
    "episode_meta[\"episodestart\"] = episode_meta[\"episodestart\"].timestamp() * 1e6\n",
    "episode_meta[\"timestamp\"] = episode_meta[\"timestamp\"].timestamp() * 1e6\n",
    "try:\n",
    "    episode_meta.pop(\"timestamp\")\n",
    "except KeyError:\n",
    "    print(f\"Key 'timestamp' not found\")\n",
    "# episode_meta\n",
    "\n",
    "# episodes_indices\n",
    "episodes_indices_dict = [\n",
    "    [{indices.names[i]: level for i, level in enumerate(levels)} for levels in df.index]\n",
    "    for df in episodes\n",
    "]\n",
    "episodes_meta_dict = [indices[0].pop(\"timestamp\") for indices in episodes_indices_dict]\n",
    "\n",
    "\n",
    "# for i in episodes_meta_dict:\n",
    "#     i.pop('timestamp')\n",
    "episodes_meta_dict = [indices[0] for indices in episodes_indices_dict]\n",
    "\n",
    "for ep_mt in episodes_meta_dict:\n",
    "    ep_mt[\"episodestart\"] = ep_mt[\"episodestart\"].timestamp() * 1e6\n",
    "episodes_meta_dict\n",
    "# for i in episodes_indices_dict:\n",
    "#     i\n",
    "\n",
    "# episodes_meta = [\n",
    "#     [\n",
    "#         [\n",
    "#             {df.index.names[i]: level } for i, level in enumerate(levels)\n",
    "#         ] for levels in df.index\n",
    "#     ] for df in episodes]\n",
    "# episodes_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9add69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = indices_dict[0]\n",
    "# ind.pop('timestamp')\n",
    "ind[\"episodestart\"] = ind[\"episodestart\"].timestamp() * 1e6\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eos.data_io.eos_struct import ObservationMeta, StateSpecs, StateUnitCodes, ActionSpecs\n",
    "from eos.data_io.utils.eos_pandas import ep_nest, df_to_ep_nested_dict, avro_ep_encoding\n",
    "from pydantic import schema_json_of, schema_of\n",
    "\n",
    "observation_meta = ObservationMeta(\n",
    "    state_specs=StateSpecs(\n",
    "        state_unit_codes=StateUnitCodes(\n",
    "            velocity_unit_code=\"kph\",\n",
    "            thrust_unit_code=\"pct\",\n",
    "            brake_unit_code=\"pct\",\n",
    "        ),\n",
    "        unit_number=trucks_by_id[\"VB7\"].cloud_unit_number,  # 4\n",
    "        unit_duration=trucks_by_id[\"VB7\"].cloud_unit_duration,  # 1s\n",
    "        frequency=trucks_by_id[\"VB7\"].cloud_signal_frequency,  # 50 hz\n",
    "    ),\n",
    "    action_specs=ActionSpecs(\n",
    "        action_unit_code=\"nm\",\n",
    "        action_row_number=trucks_by_id[\"VB7\"].torque_table_row_num_flash,\n",
    "        action_column_number=len(trucks_by_id[\"VB7\"].pedal_scale),\n",
    "    ),\n",
    "    reward_specs={\n",
    "        \"reward_unit\": \"wh\",\n",
    "    },\n",
    "    site=trucks_by_id[\"VB7\"].site,\n",
    ")\n",
    "\n",
    "\n",
    "dict_nested = avro_ep_encoding(dfs_episode)\n",
    "dict_nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ep = {\n",
    "    \"episodestart\": episode_meta[\"episodestart\"],\n",
    "    \"meta\": {\"episode_meta\": episode_meta, \"observation_meta\": observation_meta.dict()},\n",
    "    \"sequence\": dict_nested,\n",
    "}\n",
    "dict_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_dict_nested = [avro_ep_encoding(ep) for ep in episodes]\n",
    "episodes_dict_nested[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nested_states = [[step[\"state\"] for step in ep] for ep in episodes_dict_nested]\n",
    "dict_nested_nstates = [[step[\"nstate\"] for step in ep] for ep in episodes_dict_nested]\n",
    "dict_nested_rewards = [[step[\"reward\"] for step in ep] for ep in episodes_dict_nested]\n",
    "dict_nested_actions = [[step[\"action\"] for step in ep] for ep in episodes_dict_nested]\n",
    "dict_nested_timestamps = [\n",
    "    [step[\"timestamp\"] for step in ep] for ep in episodes_dict_nested\n",
    "]\n",
    "\n",
    "arr_states = [\n",
    "    [{\"ts\": ts, \"state\": state_arr[i]} for i, ts in enumerate(ts_arr)]\n",
    "    for (ts_arr, state_arr) in zip(dict_nested_timestamps, dict_nested_states)\n",
    "]\n",
    "arr_states[0]\n",
    "# dict_nested_timestamps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastavro\n",
    "import json\n",
    "\n",
    "state_unit_fields_schema = [\n",
    "    {\"name\": \"velocity_unit_code\", \"type\": \"string\"},\n",
    "    {\"name\": \"thrust_unit_code\", \"type\": \"string\"},\n",
    "    {\"name\": \"brake_unit_code\", \"type\": \"string\"},\n",
    "]\n",
    "state_specs_fields_schema = [\n",
    "    {\n",
    "        \"name\": \"state_unit_codes\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"state_unit_codes_\",\n",
    "            \"fields\": state_unit_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\"name\": \"unit_number\", \"type\": \"int\"},\n",
    "    {\"name\": \"unit_duration\", \"type\": \"int\"},\n",
    "    {\"name\": \"frequency\", \"type\": \"int\"},\n",
    "]\n",
    "action_specs_fields_schema = [\n",
    "    {\"name\": \"action_unit_code\", \"type\": \"string\"},\n",
    "    {\"name\": \"action_row_number\", \"type\": \"int\"},\n",
    "    {\"name\": \"action_column_number\", \"type\": \"int\"},\n",
    "]\n",
    "reward_specs_fields_schema = [{\"name\": \"reward_unit\", \"type\": \"string\"}]\n",
    "\n",
    "observation_meta_fields_schema = [\n",
    "    {\n",
    "        \"name\": \"state_specs\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"state_sp\",\n",
    "            \"fields\": state_specs_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"action_specs\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"action_sp\",\n",
    "            \"fields\": action_specs_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"reward_specs\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"reward_sp\",\n",
    "            \"fields\": reward_specs_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\"name\": \"site\", \"type\": \"string\"},\n",
    "]\n",
    "episode_meta_fields_schema = [\n",
    "    {\"name\": \"vehicle\", \"type\": \"string\"},\n",
    "    {\"name\": \"driver\", \"type\": \"string\"},\n",
    "    {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "]\n",
    "observation_meta_fields_schema = [\n",
    "    {\n",
    "        \"name\": \"state_specs\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"state_specs_\",\n",
    "            \"fields\": state_specs_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"action_specs\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"action_specs_\",\n",
    "            \"fields\": action_specs_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"reward_specs\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"reward_specs_\",\n",
    "            \"fields\": reward_specs_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\"name\": \"site\", \"type\": \"string\"},\n",
    "]\n",
    "\n",
    "state_fields_schema = [\n",
    "    {\"name\": \"velocity\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    {\"name\": \"thrust\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    {\"name\": \"brake\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    {\n",
    "        \"name\": \"timestep\",\n",
    "        \"type\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "torque_table_row_names = [\"r0\", \"r1\", \"r2\"]\n",
    "action_fields_schema = [\n",
    "    {\"name\": r, \"type\": {\"type\": \"array\", \"items\": \"float\"}}\n",
    "    for r in torque_table_row_names\n",
    "]\n",
    "action_fields_schema += [\n",
    "    {\"name\": \"speed\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    {\"name\": \"throttle\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    {\n",
    "        \"name\": \"timestep\",\n",
    "        \"type\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "reward_fields_schema = [\n",
    "    {\"name\": \"work\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    {\n",
    "        \"name\": \"timestep\",\n",
    "        \"type\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "episode_array_fields_schema = [\n",
    "    {\n",
    "        \"type\": \"long\",\n",
    "        \"name\": \"timestamp\",\n",
    "        \"logicalType\": \"timestamp-micros\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"state\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"state_\",\n",
    "            \"fields\": state_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"action\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"action_\",\n",
    "            \"fields\": action_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"reward\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"reward_\",\n",
    "            \"fields\": reward_fields_schema,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"nstate\",\n",
    "        \"type\": {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"nstate_\",\n",
    "            \"fields\": state_fields_schema,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "schema_episode = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"episode\",\n",
    "    \"doc\": \"episode data with a timestamp, meta description and an array of episode steps\",\n",
    "    \"fields\": [\n",
    "        {\"type\": \"long\", \"name\": \"episodestart\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"meta\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"meta_\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"episode_meta\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"episode_meta_\",\n",
    "                            \"fields\": episode_meta_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"observation_meta\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"observation_meta_\",\n",
    "                            \"fields\": observation_meta_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"name\": \"step\",  # not used in constructing the episode observation array data\n",
    "                    \"type\": \"record\",\n",
    "                    \"fields\": episode_array_fields_schema,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "parsed_schema_episode = fastavro.schema.parse_schema(schema_episode)\n",
    "print(json.dumps(schema_episode, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from eos import proj_root\n",
    "\n",
    "os.chdir(proj_root / \"data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3b983",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import dask\n",
    "# import dask.bag as db\n",
    "# b_ep = db.from_sequence([dict_ep])  # turn one single record to a list, bag create only from sequence\n",
    "# rec = b_ep.take(1)\n",
    "# type(rec[0])\n",
    "# # b_ep.to_textfiles('*.json.gz')\n",
    "# b_ep.to_avro('bag_ep.*.avro', schema=schema_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bc505",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "# from fastavro import writer, reader, parse_schema\n",
    "#\n",
    "# with open('bag_ep3.avro', 'wb') as out:\n",
    "# \twriter(out, schema_episode, rec)\n",
    "#\n",
    "# with open('bag_ep3.avro', 'rb') as fo:\n",
    "# \tfor record in reader(fo):\n",
    "# \t\tprint(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ce538",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"doc\": \"A episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"station\", \"type\": \"string\"},\n",
    "        {\"name\": \"time\", \"type\": \"long\"},\n",
    "        {\"name\": \"velocity\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "        {\"name\": \"brake\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "    ],\n",
    "}\n",
    "\n",
    "parsed_schema = parse_schema(schema)\n",
    "\n",
    "\n",
    "# 'records' can be an iterable (including generator)\n",
    "records = [\n",
    "    {\n",
    "        \"station\": \"011990-99999\",\n",
    "        \"velocity\": [0, 1],\n",
    "        \"brake\": [0, 1],\n",
    "        \"time\": 1433269388,\n",
    "    },\n",
    "    {\n",
    "        \"station\": \"011990-99999\",\n",
    "        \"velocity\": [22, 1],\n",
    "        \"brake\": [0, 1],\n",
    "        \"time\": 1433270389,\n",
    "    },\n",
    "    {\n",
    "        \"station\": \"011990-99999\",\n",
    "        \"velocity\": [-11, 1],\n",
    "        \"brake\": [0, 1],\n",
    "        \"time\": 1433273379,\n",
    "    },\n",
    "    {\n",
    "        \"station\": \"012650-99999\",\n",
    "        \"velocity\": [111, 1],\n",
    "        \"brake\": [0, 1],\n",
    "        \"time\": 1433275478,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Writing\n",
    "with open(\"episode1.avro\", \"wb\") as out:\n",
    "    writer(out, parsed_schema, records)\n",
    "\n",
    "# Reading\n",
    "with open(\"episode1.avro\", \"rb\") as fo:\n",
    "    for record in reader(fo):\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict1 = [dict_ep[\"sequence\"][i][\"observation\"][\"state\"] for i in range(5)]\n",
    "state_dict1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f082a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'records' can be an iterable (including generator)\n",
    "# records0 = [\n",
    "#     {u'station': u'011990-99999', u'state': state_dict1[0], u'time': 1433269388},\n",
    "#     {u'station': u'011990-99999', u'state': state_dict1[1],  u'time': 1433270389},\n",
    "#     {u'station': u'011990-99999', u'state': state_dict1[2], u'time': 1433273379},\n",
    "#     {u'station': u'012650-99999', u'state': state_dict1[3], u'time': 1433275478},\n",
    "# ]\n",
    "# records0\n",
    "#\n",
    "# # 'records' can be an iterable (including generator)\n",
    "# records1 = [\n",
    "#     {u'station': u'011990-99999', u'state': {'velocity': state_dict1 [0]['velocity'],'thrust': state_dict1 [0]['thrust'],'brake': state_dict1 [0]['brake'],'timestep': state_dict1 [0]['timestep']}, u'time': 1433269388},\n",
    "#     {u'station': u'011990-99999', u'state': {'velocity': state_dict1 [1]['velocity'],'thrust': state_dict1 [1]['thrust'],'brake': state_dict1 [1]['brake'],'timestep': state_dict1 [1]['timestep'] },  u'time': 1433270389},\n",
    "#     {u'station': u'011990-99999', u'state': {'velocity': state_dict1 [2]['velocity'],'thrust': state_dict1 [2]['thrust'],'brake': state_dict1 [2]['brake'],'timestep': state_dict1 [2]['timestep'] },  u'time': 1433273379},\n",
    "#     {u'station': u'012650-99999', u'state': {'velocity': state_dict1 [3]['velocity'],'thrust': state_dict1 [3]['thrust'],'brake': state_dict1 [3]['brake'],'timestep': state_dict1 [3]['timestep'] },  u'time': 1433275478},\n",
    "# ]\n",
    "# # records1\n",
    "#\n",
    "# records2 = [\n",
    "#     {u'timestamp': dict_ep['episode'][0]['episodestep']['timestamp'], u'observation': {'state': state_dict1[0]}, u'time': 1433269388},\n",
    "#     {u'timestamp': dict_ep['episode'][1]['episodestep']['timestamp'], u'observation': {'state': state_dict1[1]},  u'time': 1433270389},\n",
    "#     {u'timestamp': dict_ep['episode'][2]['episodestep']['timestamp'], u'observation': {'state': state_dict1[2]},  u'time': 1433273379},\n",
    "#     {u'timestamp': dict_ep['episode'][3]['episodestep']['timestamp'], u'observation': {'state': state_dict1[3]},  u'time': 1433275478},\n",
    "# ]\n",
    "# # records2\n",
    "records3 = [\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][0][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"state\": state_dict1[0]},\n",
    "        \"time\": 1433269388,\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][1][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"state\": state_dict1[1]},\n",
    "        \"time\": 1433270389,\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][2][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"state\": state_dict1[2]},\n",
    "        \"time\": 1433273379,\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][3][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"state\": state_dict1[3]},\n",
    "        \"time\": 1433275478,\n",
    "    },\n",
    "]\n",
    "records3\n",
    "# dict_nested_state = [dict_ep['episode'][i]['episodestep']['observation']['state'] for i in range(4)]\n",
    "records4 = [\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[0][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": arr_states[0],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[1][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": arr_states[1],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[2][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": arr_states[2],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[3][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": arr_states[3],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[4][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": arr_states[4],\n",
    "    },\n",
    "]\n",
    "# records4[2]\n",
    "\n",
    "records5 = [\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[0][\"episodestart\"],\n",
    "        \"sequence\": dict_nested_timestamps[0],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[1][\"episodestart\"],\n",
    "        \"sequence\": dict_nested_timestamps[1],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[2][\"episodestart\"],\n",
    "        \"sequence\": dict_nested_timestamps[2],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[3][\"episodestart\"],\n",
    "        \"sequence\": dict_nested_timestamps[3],\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": episodes_indices_dict[4][\"episodestart\"],\n",
    "        \"sequence\": dict_nested_timestamps[4],\n",
    "    },\n",
    "]\n",
    "# records5[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "records7 = [\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][0][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"ts\": dict_nested[0][\"timestamp\"], \"state\": state_dict1[0]},\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][1][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"ts\": dict_nested[1][\"timestamp\"], \"state\": state_dict1[1]},\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][2][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"ts\": dict_nested[2][\"timestamp\"], \"state\": state_dict1[2]},\n",
    "    },\n",
    "    {\n",
    "        \"episodestart\": dict_ep[\"sequence\"][3][\"timestamp\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episode_meta,\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": {\"ts\": dict_nested[3][\"timestamp\"], \"state\": state_dict1[3]},\n",
    "    },\n",
    "]\n",
    "records7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "records8 = [\n",
    "    {\"episodestart\": dict_ep[\"sequence\"][0][\"timestamp\"], \"sequence\": arr_states[0]},\n",
    "    {\"episodestart\": dict_ep[\"sequence\"][1][\"timestamp\"], \"sequence\": arr_states[1]},\n",
    "    {\"episodestart\": dict_ep[\"sequence\"][2][\"timestamp\"], \"sequence\": arr_states[2]},\n",
    "    {\"episodestart\": dict_ep[\"sequence\"][3][\"timestamp\"], \"sequence\": arr_states[3]},\n",
    "    {\"episodestart\": dict_ep[\"sequence\"][4][\"timestamp\"], \"sequence\": arr_states[4]},\n",
    "]\n",
    "records8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"station\", \"type\": \"string\"},\n",
    "        {\"name\": \"time\", \"type\": \"long\"},\n",
    "        {\n",
    "            \"name\": \"state\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"state_\",\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"velocity\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "                    {\"name\": \"thrust\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "                    {\"name\": \"brake\", \"type\": {\"type\": \"array\", \"items\": \"float\"}},\n",
    "                    {\n",
    "                        \"name\": \"timestep\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"long\",\n",
    "                                \"logicalType\": \"timestamp-micros\",\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "parsed_schema = parse_schema(schema1)\n",
    "parsed_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600766b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbfa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing\n",
    "# with open('episode5.avro', 'wb') as out:\n",
    "#     writer(out, parsed_schema, records1)\n",
    "#\n",
    "# # Reading\n",
    "# with open('episode5.avro', 'rb') as fo:\n",
    "#     for record in reader(fo):\n",
    "#         print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema2 = {\n",
    "#     'doc': 'An episode reading.',\n",
    "#     'name': 'episode',\n",
    "#     'namespace': 'test',\n",
    "#     'type': 'record',\n",
    "#     'fields': [\n",
    "#         {'name': 'timestamp', 'type': 'long', 'logicalType': 'timestamp-micros'},\n",
    "#         {'name': 'observation', 'type':\n",
    "#             {\n",
    "#                 'type': 'record',\n",
    "#                 'name': 'observation_',\n",
    "#                 'fields': [\n",
    "#                     {\n",
    "#                         'name': 'state',\n",
    "#                         'type': {\n",
    "#                             'type': 'record',\n",
    "#                             'name': 'state_',\n",
    "#                             'fields': state_fields_schema\n",
    "#                         }\n",
    "#                     },\n",
    "#                 ]\n",
    "#             }\n",
    "#          },\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# schema3 = {\n",
    "#     'doc': 'An episode reading.',\n",
    "#     'name': 'episode',\n",
    "#     'namespace': 'test',\n",
    "#     'type': 'record',\n",
    "#     'fields': [\n",
    "#         {'name': 'timestamp', 'type': 'long', 'logicalType': 'timestamp-micros'},\n",
    "#         {'name': 'observation', 'type':\n",
    "#             {\n",
    "#                 'type': 'record',\n",
    "#                 'name': 'observation_',\n",
    "#                 'fields': [\n",
    "#                     {\n",
    "#                         'name': 'state',\n",
    "#                         'type': {\n",
    "#                             'type': 'record',\n",
    "#                             'name': 'state_',\n",
    "#                             'fields': state_fields_schema\n",
    "#                         }\n",
    "#                     },\n",
    "#                 ]\n",
    "#             }\n",
    "#          },\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "schema3 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"sequence\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"meta\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"meta_\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"episode_meta\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"episode_meta_\",\n",
    "                            \"fields\": episode_meta_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"observation_meta\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"observation_meta_\",\n",
    "                            \"fields\": observation_meta_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"sequence_\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"state\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"state_\",\n",
    "                            \"fields\": state_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# parsed_schema = parse_schema(schema3)\n",
    "# # parsed_schema\n",
    "# schema3\n",
    "\n",
    "schema4 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"meta\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"meta_\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"episode_meta\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"episode_meta_\",\n",
    "                            \"fields\": episode_meta_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"observation_meta\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"observation_meta_\",\n",
    "                            \"fields\": observation_meta_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": [\n",
    "                    {\n",
    "                        \"name\": \"step\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"step_\",\n",
    "                            \"fields\": [\n",
    "                                {\n",
    "                                    \"name\": \"ts\",\n",
    "                                    \"type\": {\n",
    "                                        \"type\": \"long\",\n",
    "                                        \"logicalType\": \"timestamp-micros\",\n",
    "                                    },\n",
    "                                }\n",
    "                            ],\n",
    "                        },\n",
    "                    }\n",
    "                    # {'name': 'observation',\n",
    "                    #     'type': {\n",
    "                    #         'type': 'record',\n",
    "                    #         'name': 'observation_',\n",
    "                    #         'fields': [\n",
    "                    #             {\n",
    "                    #                 'name': 'state',\n",
    "                    #                 'type': {\n",
    "                    #                     'type': 'record',\n",
    "                    #                     'name': 'state_',\n",
    "                    #                     'fields': state_fields_schema\n",
    "                    #                 },\n",
    "                    #             },\n",
    "                    #         ]\n",
    "                    #     }\n",
    "                    # },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "# parsed_schema = parse_schema(schema4)\n",
    "# parsed_schema\n",
    "# schema4\n",
    "schema5 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"sequence_\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"step\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"step_\",\n",
    "                            \"fields\": [\n",
    "                                {\n",
    "                                    \"name\": \"ts\",\n",
    "                                    \"type\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"items\": {\n",
    "                                            \"type\": \"long\",\n",
    "                                            \"logicalType\": \"timestamp-micros\",\n",
    "                                        },\n",
    "                                    },\n",
    "                                },\n",
    "                            ]\n",
    "                            # [{\n",
    "                            #     'name': 'ts',\n",
    "                            #     'type': {'type': 'long', 'logicalType': 'timestamp-micros'}\n",
    "                            # }]\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# parsed_schema\n",
    "\n",
    "schema6 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"sequence_\",\n",
    "                \"fields\": [\n",
    "                    {\n",
    "                        \"name\": \"ts\",\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema7 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"sequence_\",\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"ts\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "                    {\n",
    "                        \"name\": \"state\",\n",
    "                        \"type\": {\n",
    "                            \"type\": \"record\",\n",
    "                            \"name\": \"state_\",\n",
    "                            \"fields\": state_fields_schema,\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "parsed_schema = parse_schema(schema7)\n",
    "parsed_schema\n",
    "schema7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16014c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema8 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"name\": \"step\",  # not used in constructing the array data, only implicit name for schema namespace,\n",
    "                    \"type\": \"record\",\n",
    "                    \"fields\": [\n",
    "                        {\n",
    "                            \"name\": \"ts\",\n",
    "                            \"type\": \"long\",\n",
    "                            \"logicalType\": \"timestamp-micros\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"state\",\n",
    "                            \"type\": {\n",
    "                                \"type\": \"record\",\n",
    "                                \"name\": \"state_\",\n",
    "                                \"fields\": state_fields_schema,\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "parsed_schema = parse_schema(schema8)\n",
    "# parsed_schema\n",
    "schema8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275489ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema9 = {\n",
    "    \"doc\": \"An episode reading.\",\n",
    "    \"name\": \"episode\",\n",
    "    \"namespace\": \"test\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"episodestart\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"},\n",
    "        {\n",
    "            \"name\": \"sequence\",\n",
    "            \"type\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"name\": \"step\",  # not used in constructing the array data, only implicit name for schema namespace,\n",
    "                    \"type\": \"record\",\n",
    "                    \"fields\": [\n",
    "                        {\n",
    "                            \"name\": \"ts\",\n",
    "                            \"type\": \"long\",\n",
    "                            \"logicalType\": \"timestamp-micros\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"state\",\n",
    "                            \"type\": {\n",
    "                                \"type\": \"record\",\n",
    "                                \"name\": \"state_\",\n",
    "                                \"fields\": state_fields_schema,\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "parsed_schema = parse_schema(schema9)\n",
    "# parsed_schema\n",
    "schema9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda662c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records_episodes = [\n",
    "#     {u'episodestart': episodes_indices_dict[0]['episodestart'],\n",
    "#      u'meta': {'episode_meta': episode_meta, 'observation_meta': observation_meta.dict()},\n",
    "#      u'sequence': episodes_dict_nested[0]},\n",
    "#     {u'episodestart': episodes_indices_dict[1]['episodestart'],\n",
    "#      u'meta': {'episode_meta': episode_meta, 'observation_meta': observation_meta.dict()},\n",
    "#      u'sequence': episodes_dict_nested[1]},\n",
    "#     {u'episodestart': episodes_indices_dict[2]['episodestart'],\n",
    "#      u'meta': {'episode_meta': episode_meta, 'observation_meta': observation_meta.dict()},\n",
    "#      u'sequence': episodes_dict_nested[2]},\n",
    "#     {u'episodestart': episodes_indices_dict[3]['episodestart'],\n",
    "#      u'meta': {'episode_meta': episode_meta, 'observation_meta': observation_meta.dict()},\n",
    "#      u'sequence': episodes_dict_nested[3]},\n",
    "#     {u'episodestart': episodes_indices_dict[4]['episodestart'],\n",
    "#      u'meta': {'episode_meta': episode_meta, 'observation_meta': observation_meta.dict()},\n",
    "#      u'sequence': episodes_dict_nested[4]},\n",
    "# ]\n",
    "\n",
    "\n",
    "records_episodes = [\n",
    "    {\n",
    "        \"episodestart\": episodes_meta_dict[i][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episodes_meta_dict[i],\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": episodes_dict_nested[i],\n",
    "    }\n",
    "    for i in range(4)\n",
    "]\n",
    "\n",
    "records_episodes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing\n",
    "with open(\"./episodes2.avro\", \"wb\") as out:\n",
    "    writer(out, parsed_schema_episode, records_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading\n",
    "with open(\"./episodes2.avro\", \"rb\") as fo:\n",
    "    for record in reader(fo):\n",
    "        # print(record)\n",
    "        print(record[\"meta\"][\"episode_meta\"][\"vehicle\"])\n",
    "        print(record[\"meta\"][\"episode_meta\"][\"driver\"])\n",
    "        print(pd.to_datetime(record[\"episodestart\"], unit=\"us\"))\n",
    "        print(pd.to_datetime(record[\"sequence\"][0][\"timestamp\"], unit=\"us\"))\n",
    "        print(len(record[\"sequence\"]))\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4273a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"bags\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56671c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.bag as db\n",
    "from dask import delayed\n",
    "\n",
    "b = db.from_sequence([{\"name\": \"Alice\", \"value\": 100}, {\"name\": \"Bob\", \"value\": 200}])\n",
    "b.take(2, npartitions=2)\n",
    "schema = {\n",
    "    \"name\": \"People\",\n",
    "    \"doc\": \"Set of people's scores\",\n",
    "    \"type\": \"record\",\n",
    "    \"fields\": [{\"name\": \"name\", \"type\": \"string\"}, {\"name\": \"value\", \"type\": \"int\"}],\n",
    "}\n",
    "b.to_avro(\"my-data.*.avro\", schema)\n",
    "\n",
    "b_episodes = db.from_sequence(records_episodes)\n",
    "b_episodes.npartitions\n",
    "data = b_episodes.take(4, npartitions=4)\n",
    "len(data)\n",
    "b_episodes.to_avro(\"bag_episodes.*.avro\", schema=parsed_schema_episode)\n",
    "# dd_episodes = [delayed(db.from_sequence(ep))  for ep in records_episodes]\n",
    "# # b_episodes_data = b_episodes.compute()\n",
    "# b_episodes = db.from_delayed(dd_episodes)\n",
    "# b_episodes.take(2)\n",
    "# b_episodes.to_avro('bag_episodes.*.avro', schema=parsed_schema_episode)\n",
    "#\n",
    "# # rec = b_episodes.take(1)\n",
    "#\n",
    "# b_episodes.to_avro('bag_episodes.*.avro', schema=parsed_schema_episode)\n",
    "#\n",
    "\n",
    "# rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60545fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_episodes_read = db.read_avro(\"bag_episodes.*.avro\")\n",
    "rec = b_episodes_read.take(4, npartitions=4)\n",
    "len(rec)\n",
    "rec[0][\"meta\"][\"episode_meta\"][\"vehicle\"]\n",
    "rec[0][\"meta\"][\"episode_meta\"][\"driver\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ca98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_episode_to_add = [\n",
    "    {\n",
    "        \"episodestart\": episodes_meta_dict[4][\"episodestart\"],\n",
    "        \"meta\": {\n",
    "            \"episode_meta\": episodes_meta_dict[4],\n",
    "            \"observation_meta\": observation_meta.dict(),\n",
    "        },\n",
    "        \"sequence\": episodes_dict_nested[4],\n",
    "    }\n",
    "]\n",
    "# records_episode_to_add\n",
    "\n",
    "b_episodes_new = db.concat([b_episodes_read, db.from_sequence(records_episode_to_add)])\n",
    "b_episodes_new.npartitions\n",
    "b_episodes_new.to_avro(\"bag_episodes.*.avro\", schema=parsed_schema_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_episodes_read = db.read_avro(\"bag_episodes.*.avro\")\n",
    "b_episodes_read.npartitions\n",
    "b_episodes_read.take(5, npartitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f74016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
