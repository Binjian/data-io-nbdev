{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb2bde52d3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass\n",
    "#\n",
    "# @dataclass(kw_only=True)\n",
    "# class Parent:\n",
    "#     name: str\n",
    "#     age: int\n",
    "#     ugly: bool = False\n",
    "#\n",
    "# @dataclass(kw_only=True)\n",
    "# class Child(Parent):\n",
    "#     school: str\n",
    "#\n",
    "# ch = Child(name=\"Kevin\", age=17, school=\"42\")\n",
    "# print(ch.ugly)\n",
    "#\n",
    "# ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e6ad2a91fd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65ebe0e9e1a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from collections import UserDict\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class RemoteCanException(Exception):\n",
    "    \"\"\"Base class for all remote CAN exceptions.\"\"\"\n",
    "\n",
    "    err_code: Optional[int] = 1001  # default exception is unknown connection error\n",
    "    extra_msg: Optional[str] = None\n",
    "    codes: UserDict = UserDict(  # class attribute, if not given use the default\n",
    "        {\n",
    "            0: \"success\",\n",
    "            1: \"client_cannot_connect_to_server\",\n",
    "            2: \"ai_mode_shutdown\",\n",
    "            1000: \"network_connection_error\",\n",
    "            1001: \"network_unknown_error\",\n",
    "            1002: \"network_timeout\",\n",
    "            -1: \"tsp_internal_error\",\n",
    "            202: \"tsp_no_API_exist\",\n",
    "            206: \"tsp_parameter_wrong\",\n",
    "            301: \"tsp_out_of_time\",\n",
    "            302: \"tsp_command_execute_error\",\n",
    "            303: \"tsp_car_not_registered\",\n",
    "            304: \"tsp_car_offline\",\n",
    "            310: \"tsp_internal_exception_error\",\n",
    "            311: \"tsp_tbox_returned_error\",\n",
    "            3000: \"tsp_return_result_is_not_dictionary\",\n",
    "            3001: \"tsp_return_result_has_no_oss_link\",\n",
    "            2000: \"uds_version_failed\",\n",
    "            2001: \"ab_torque_switch_failed\",\n",
    "            2002: \"oss_data_not_enough\",\n",
    "            2003: \"torque_shape_error\",\n",
    "            2004: \"torque_range_error\",\n",
    "            2005: \"remote_can_unknown_format\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        print(\n",
    "            f\"{{'header': 'err_code': '{self.err_code}', \"\n",
    "            f\"'msg': '{self.codes[self.err_code]}', \"\n",
    "            f\"'extra_msg': '{self.extra_msg}'}}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471661a438d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise RemoteCanException(err_code=1000, extra_msg=\"test\")\n",
    "# raise RemoteCanException(err_code=1000)\n",
    "raise RemoteCanException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62c7754cc42804",
   "metadata": {},
   "outputs": [],
   "source": [
    "1000 in (1, 1000, 1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619ecba474be7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_product(seq1, seq2):\n",
    "#\n",
    "#     if not seq1 or not seq2:\n",
    "#         raise ValueError('Sequence arguments must be non-empty')\n",
    "#\n",
    "#     return [(x1, x2) for x1 in seq1 for x2 in seq2]\n",
    "#\n",
    "#\n",
    "# cross_product([1,2,3], seq2=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2d9e3ba297142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # descriptors.py\n",
    "# class Verbose_attribute():\n",
    "#     def __get__(self, obj, type=None) -> object:\n",
    "#         print(\"accessing the attribute to get the value\")\n",
    "#         return 42\n",
    "#     def __set__(self, obj, value) -> None:\n",
    "#         print(\"accessing the attribute to set the value\")\n",
    "#         raise AttributeError(\"Cannot change the value\")\n",
    "#\n",
    "# class Foo():\n",
    "#     attribute1 = Verbose_attribute()\n",
    "#\n",
    "# my_foo_object = Foo()\n",
    "# # print(my_foo_object.attribute1)\n",
    "# # x = my_foo_object.attribute1\n",
    "# # print(x)\n",
    "# print(Foo.attribute1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee496d673fc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parent:\n",
    "    def __init_subclass__(cls):\n",
    "        print(\"Subclass of Parent Created!\")\n",
    "        print(cls.__base__.__dict__)\n",
    "        print(cls.__name__)\n",
    "        print(cls.__dict__)\n",
    "\n",
    "\n",
    "class Child(Parent):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc71de81d0685c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "ddf = dd.from_pandas(pd.DataFrame([]), npartitions=1)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406c37280823fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.bag import Bag\n",
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ca247f3bc36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_train = 1200\n",
    "from numpy.random import choice\n",
    "\n",
    "X_train = np.zeros((1200, 20, 1))\n",
    "one_indexes = choice(a=N_train, size=N_train // 2, replace=False)\n",
    "X_train[one_indexes, 0, 0] = 1  # very long term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee391449c09d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(x_train, y_train, window_length):\n",
    "    windows = []\n",
    "    windows_y = []\n",
    "    for i, sequence in enumerate(x_train):\n",
    "        len_seq = len(sequence)\n",
    "        for window_start in range(0, len_seq - window_length + 1):\n",
    "            window_end = window_start + window_length\n",
    "            window = sequence[window_start:window_end]\n",
    "            windows.append(window)\n",
    "            windows_y.append(y_train[i])\n",
    "    return np.array(windows), np.array(windows_y)\n",
    "\n",
    "\n",
    "X = [[1, 0, 0, 0, 0]]\n",
    "Y = [1]\n",
    "window_length = 2\n",
    "\n",
    "prepare_sequences(X, Y, window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6619186facf1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_out, Y_out = prepare_sequences(X_train.tolist(), X_train[:, 0].tolist(), 10)\n",
    "\n",
    "X_train = X_out[:11000, :]\n",
    "X_test = X_out[11000:, :]\n",
    "y_train = Y_out[:11000]\n",
    "y_test = Y_out[11000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e347f0f580fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.layers import Input, Dense, LSTM\n",
    "# from tensorflow.python.keras.models import Sequential\n",
    "from keras import Input, Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "print(\"Building STATELESS model...\")\n",
    "max_len = 10\n",
    "batch_size = 64\n",
    "# model = Sequential()\n",
    "# # model.add(Input(shape=(max_len, 1)))\n",
    "# model.add(LSTM(10, input_shape=(max_len, 1), return_sequences=False, stateful=False))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=15,\n",
    "#             validation_data=(X_test, y_test), shuffle=False)\n",
    "# # score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(max_len, 1), return_sequences=False, stateful=False))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=False,\n",
    ")\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a821e2842d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(\n",
    "        10,\n",
    "        batch_input_shape=(batch_size, max_len, 1),\n",
    "        return_sequences=False,\n",
    "        stateful=True,\n",
    "    )\n",
    ")\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=False,\n",
    ")\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4b01e3bbec7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_train = 1200\n",
    "from numpy.random import choice\n",
    "\n",
    "X_in = np.zeros((1200, 10, 1))\n",
    "one_indexes = choice(a=N_train, size=N_train // 2, replace=False)\n",
    "X_in[one_indexes, 0, 0] = 1  # very long term memory.\n",
    "Y_in = np.expand_dims(X_in[:, 0, 0], axis=1)\n",
    "\n",
    "X_train = X_in[:1000, :].tolist()\n",
    "X_test = X_in[1000:, :].tolist()\n",
    "Y_train = Y_in[:1000].tolist()\n",
    "Y_test = Y_in[1000:].tolist()\n",
    "max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d608a845e6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Build STATEFUL model...\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, batch_input_shape=(1, 1, 1), return_sequences=False, stateful=True))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ccf07e1c76f1ea",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"Train...\")\n",
    "for epoch in range(15):\n",
    "    mean_tr_acc = []\n",
    "    mean_tr_loss = []\n",
    "    for i in range(len(X_train)):\n",
    "        Y_true = Y_train[i]\n",
    "        for j in range(max_len):\n",
    "            tr_loss, tr_acc = model.train_on_batch(\n",
    "                np.expand_dims(np.expand_dims(X_train[i][j], axis=1), axis=1),\n",
    "                np.array([Y_true]),\n",
    "            )\n",
    "            mean_tr_acc.append(tr_acc)\n",
    "            mean_tr_loss.append(tr_loss)\n",
    "        model.reset_states()\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                \"epoch {}, sample {}, tr_acc {}, tr_loss {}\".format(\n",
    "                    epoch, i, np.mean(mean_tr_acc), np.mean(mean_tr_loss)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"accuracy training = {}\".format(np.mean(mean_tr_acc)))\n",
    "    print(\"loss training = {}\".format(np.mean(mean_tr_loss)))\n",
    "    print(\"___________________________________\")\n",
    "\n",
    "    mean_te_acc = []\n",
    "    mean_te_loss = []\n",
    "    for i in range(len(X_test)):\n",
    "        for j in range(max_len):\n",
    "            te_loss, te_acc = model.test_on_batch(\n",
    "                np.expand_dims(np.expand_dims(X_test[i][j], axis=1), axis=1),\n",
    "                np.array([Y_test[i]]),\n",
    "            )\n",
    "            mean_te_acc.append(te_acc)\n",
    "            mean_te_loss.append(te_loss)\n",
    "        model.reset_states()\n",
    "\n",
    "        for j in range(max_len):\n",
    "            Y_pred = model.predict_on_batch(\n",
    "                np.expand_dims(np.expand_dims(X_test[i][j], axis=1), axis=1)\n",
    "            )\n",
    "        model.reset_states()\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                \"test, sample {}, tr_acc {}, tr_loss {}\".format(\n",
    "                    i, np.mean(mean_te_acc), np.mean(mean_te_loss)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"accuracy testing = {}\".format(np.mean(mean_te_acc)))\n",
    "    print(\"loss testing = {}\".format(np.mean(mean_te_loss)))\n",
    "    print(\"___________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a0750b1f49986",
   "metadata": {},
   "source": [
    "# pydantic with custom serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125849d7daeda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import ujson\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str = 'John Doe'\n",
    "    signup_ts: datetime = None\n",
    "\n",
    "    class Config:\n",
    "        json_loads = ujson.loads\n",
    "\n",
    "\n",
    "user = User.model_validate_json('{\"id\": 123,\"signup_ts\":1234567890,\"name\":\"John Doe\"}')\n",
    "print(user)\n",
    "#> id=123 signup_ts=datetime.datetime(2009, 2, 13, 23, 31, 30,\n",
    "#> tzinfo=datetime.timezone.utc) name='John Doe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14843502214ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import orjson\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def orjson_dumps(v, *, default):\n",
    "    # orjson.dumps returns bytes, to match standard json.dumps we need to decode\n",
    "    return orjson.dumps(v, default=default).decode()\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name:str = 'John Doe'\n",
    "    signup_ts: datetime = None\n",
    "\n",
    "    class Config:\n",
    "        json_loads = orjson.loads\n",
    "        json_dumps = orjson_dumps\n",
    "\n",
    "\n",
    "user = User.model_validate_json('{\"id\":123,\"signup_ts\":1234567890,\"name\":\"John Doe\"}')\n",
    "print(user.model_dump_json())\n",
    "#> {\"id\":123,\"signup_ts\":\"2009-02-13T23:31:30+00:00\",\"name\":\"John Doe\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd883ffb365060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoneinfo import ZoneInfo\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from eos.data_io.eos_struct.eos_location import locations_by_abbr\n",
    "\n",
    "from pydantic_core import SchemaSerializer\n",
    "\n",
    "class OrJsonSerializer(SchemaSerializer):\n",
    "\n",
    "    def to_json(self, *args, **kwargs):\n",
    "        return orjson.dumps(...)  # implementation not complete, need to understand args/kwargs\n",
    "\n",
    "    def to_python(self, *args, **kwargs): # real signature unknown\n",
    "        return orjson.loads(...)  # implementation not complete, need to understand args/kwargs\n",
    "\n",
    "\n",
    "class EosLocation(BaseModel):\n",
    "    \n",
    "    __pydantic_serializer__ = OrJsonSerializer\n",
    "\n",
    "    abbr: str\n",
    "    name: str\n",
    "    cname: str\n",
    "    tz: ZoneInfo\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3d36522a68d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = EosLocation.model_validate_json('{\"abbr\":\"CHN\",\"name\":\"China\",\"cname\":\"中国\",\"tz\":\"Asia/Shanghai\"}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
