{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tspace\n",
    "\n",
    "> Time sequence data pipleline framework </br>for deep reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from tspace.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "tspace is an data pipleline framework for deep reinforcement learning  with IO interface, processing and configuration. The current code base depicts an automotive implementation. The main features are:\n",
    "\n",
    "- working both training and inferrence mode, supporting\n",
    "  - coordinated [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) and ML pipelines,\n",
    "  - online and offline training,\n",
    "  - local and distributed training;\n",
    "- multiple models of\n",
    "  - reinforcement learning models with DDPG and \n",
    "  - time sequence processing with recurrent models;\n",
    "- data pipelines compatible to both ETL and ML dataflow with\n",
    "  - support of multiple data sources (local CAN or remote cloud object storage),\n",
    "  - stateful time sequence processing with sequential model and\n",
    "  - support of both NoSQL database, local and cloud data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "draft = '''\n",
    "Markdown\n",
    "\n",
    "tspace is an data pipleline framework for deep reinforcement learning  with IO interface, processing and configuration. The main features are:\n",
    "\n",
    "- Working in training and inferrence mode\n",
    "  - logging and monitoring with cutelog or TUI interface\n",
    "  - cascaded threading pool for well-structured Scheduling of [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) and ML pipelines\n",
    "  - Customized Exception handling\n",
    "  - Graceful shutdown\n",
    "  - online and offline training\n",
    "  - local and distributed training\n",
    "- Support for multiple models\n",
    "  - reinforcement learning models with DDPG \n",
    "  - time sequence models with LSTM and Transformer\n",
    "- Data pipeline compatible to both ETL and ML dataflow \n",
    "  - Support for multiple data sources (local CAN or remote cloud object storage)\n",
    "  - Support both NoSQL database and local or cloud data storage through Dask with Parquet and Avro interface\n",
    "  - Full Pandas DataFrame support with raw json codecs\n",
    "  - Configuration system for vehicles, drivers, data sites, neural network hyperparameters, database, HMI types, etc\n",
    "  - Timezone aware time sequence data processing\n",
    "  - Data object meta-info processing and storage linked to configuration system\n",
    "  - Stateful time sequence processing with sequential model\n",
    "  - Type hint for data processing and configuration\n",
    "  - Pydantic integration\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/tspace_overview.svg\" alt=\"Overview of tspace architecture\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram shows the basic architure of tspace. The main components are:\n",
    "\n",
    "- **`Avatar`**: orchestrates the whole ETL and ML workflow \n",
    "  - It configure KvaserCAN, RemoteCAN, Cruncher, Agent, Model, Database, Pipeline.\n",
    "  - It also manages the scheduling of the workflow threads.\n",
    "  - It select the either **KvaserCAN** or **RemoteCAN** as the vehicle interface for reading the observation and applying the action.\n",
    "- **KvaserCAN** is implemented with `Kvaser` which provides \n",
    "  - a local interface for reading the observation (CAN messages of vehicle states) via Kvaser using `udp_context` to get CAN messages as json data from a local udp server. Then it encodes the raw json data into a [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) for forwarding through the data pipeline to `Cruncher`.\n",
    "  - It provides a local interface for applying the action (flashing parameters) onto the vehicle ECU (VCU). Before sending the action, it decodes the action from the [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) into packed string buffer and then sends it to the ECU by calling `send_float_array` from `VehicleInterface.consume`.\n",
    "  - The control messages for training HMI go through the same UDP port. They are used to modify the threading events to control the episodic training process with `VehicleInterface.hmi_control`. \n",
    "- **RemoteCAN** provides a remote interface to the vehicle via the object storage system on the cloud sent by the onboard TBox. It's implemented with `Cloud`: \n",
    "  - It reads the observation (CAN messages of vehicle states) from the cloud object storage system through `RemoteCanClient.get_signals`. It then encodes the raw json data into a [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) and forward it to `Cruncher` through the data pipeline.\n",
    "  - It sends the action (flashing parameters) to the vehicle ECU (VCU) in the shared `VehicleInterface.consume` by calling `RemoteCanClient.send_torque_map`, which decodes the action from the [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) into raw json string.\n",
    "  - It selects the training HMI to get the vehicle and driver information as configuration with `Cloud.hmi_capture_from_udp` for local udp server, with `Cloud.hmi_capture_from_rmq` for remote RocketMQ server, with `Cloud.hmi_capture_from_dummy` for pure inference mode without training or updating models. It shares the same control logic `VehicleInterface.hmi_control` with **KvaserCAN**.\n",
    "- **Cruncher**:\n",
    "  - The `Cruncher.filter` reveives the observation through the data pipeline from **KvaserCAN** or **RemoteCAN**. It pre-processes the input data into the quadruple with a timestamp $(timestamp, state, action, reward, state')$ and give it to the reinforcement agent `DPG` for inferring an optimal action determined by its current policy. After getting the prediction of the agent, it encodes the prediction result into an action object and forwards it to `VehicleInterface.consume` to be flashed onto VCU. \n",
    "  - It collects the critic, actor loss, the total reward for each episode, the running reward and the action at the end of the episode. It also saves the model checkpoint and the training log to the database.  \n",
    "- **Agent** provides a wrapper for the reinforcement learning model with `DPG`:\n",
    "  - It initializes the actor and critic networks with the `Actor` and `Critic` classes. It also initializes the target actor and target critic networks with the `Actor` and `Critic` classes. \n",
    "  - It trains the actor and critic networks with the `train` method. It also updates the target actor and target critic networks with the `update_target` method. \n",
    "  - It predicts the action with the `predict` method. It also predicts the target action with the `predict_target` method.\n",
    "- **Model**:\n",
    "- **Database**:\n",
    "- **Pipeline**:\n",
    "- **Config**:\n",
    "- **Sched** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "1. Add time sequence embedding database support with LanceDB for TimeGPT\n",
    "2. Batch mode for large scale inference and training with Unit of Work pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install tspace\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev \n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
