{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c3f1388493a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a6e485a6ca7d5",
   "metadata": {},
   "source": [
    "# Cloud\n",
    "\n",
    "> Cloud class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ca855026ba37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataflow.cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c53ad89e20d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import concurrent.futures\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from threading import Event, Lock, current_thread\n",
    "from typing import Callable, Optional, Tuple, cast\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rocketmq.client import Message, Producer  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd5845269ec498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from data_io_nbdev.dataflow.pipeline.queue import Pipeline  # type: ignore\n",
    "from data_io_nbdev.dataflow.pipeline.deque import PipelineDQ  # type: ignore\n",
    "from data_io_nbdev.dataflow.vehicle_interface import VehicleInterface  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49144c66a2d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from data_io_nbdev.conn.clearable_pull_consumer import ClearablePullConsumer\n",
    "\n",
    "from data_io_nbdev.conn.remote_can_client import RemoteCanClient, RemoteCanException\n",
    "from data_io_nbdev.config.messengers import CANMessenger, TripMessenger\n",
    "from data_io_nbdev.config.vehicles import TruckInCloud\n",
    "from data_io_nbdev.conn.udp import udp_context\n",
    "from data_io_nbdev.data.external.numpy_utils import (\n",
    "    ragged_nparray_list_interp,\n",
    "    timestamps_from_can_strings,\n",
    ")\n",
    "from data_io_nbdev.data.core import RawType, RCANType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81395ea9d4504a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Cloud(VehicleInterface):\n",
    "    \"\"\"\n",
    "    Kvaser is local vehicle interface with Producer(get vehicle status) and Consumer(flasher)\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "        truck: TruckInCloud\n",
    "            truck type is TruckInCloud\n",
    "        can_server: CANMessenger\n",
    "            can_server type is CANMessenger\n",
    "        trip_server: Optional[TripMessenger] = None\n",
    "            trip_server type is TripMessenger\n",
    "        ui: str = \"UDP\"\n",
    "            ui must be cloud, local or mobile, not {self.ui}\n",
    "        web_srv = (\"rocket_intra\",)\n",
    "            web_srv is a tuple of str\n",
    "        epi_countdown_time: float = 3.0\n",
    "            epi_countdown_time is a float\n",
    "        remotecan: Optional[RemoteCanClient] = None\n",
    "            RemoteCanClient type is RemoteCanClient\n",
    "        rmq_consumer: Optional[ClearablePullConsumer] = None\n",
    "            ClearablePullConsumer type is ClearablePullConsumer\n",
    "        rmq_message_ready: Optional[Message] = None\n",
    "            Message type is Message\n",
    "        rmq_producer: Optional[Producer] = None\n",
    "            Producer type is Producer\n",
    "        remoteClient_lock: Optional[Lock] = None\n",
    "            Lock type is Lock\n",
    "    \"\"\"\n",
    "\n",
    "    truck: TruckInCloud\n",
    "    can_server: CANMessenger\n",
    "    trip_server: Optional[TripMessenger] = None\n",
    "    ui: str = \"UDP\"\n",
    "    web_srv = (\"rocket_intra\",)\n",
    "    epi_countdown_time: float = 3.0\n",
    "    remotecan: Optional[RemoteCanClient] = None\n",
    "    rmq_consumer: Optional[ClearablePullConsumer] = None\n",
    "    rmq_message_ready: Optional[Message] = None\n",
    "    rmq_producer: Optional[Producer] = None\n",
    "    remoteClient_lock: Optional[Lock] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"init cloud interface and set ui type\"\"\"\n",
    "        super().__post_init__()\n",
    "        self.init_cloud()\n",
    "        assert type(self.truck is TruckInCloud), \"truck type is not TruckInCloud\"\n",
    "        assert self.ui in [\n",
    "            \"cloud\",\n",
    "            \"local\",\n",
    "            \"mobile\",\n",
    "        ], f\"ui must be cloud, local or mobile, not {self.ui}\"\n",
    "\n",
    "        self.logger.info(\"Cloud interface initialized\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"cloud\"\n",
    "\n",
    "    def init_cloud(self) -> None:\n",
    "        \"\"\"initialize cloud interface, set proxy and remote can client and the lock\"\"\"\n",
    "        os.environ[\"http_proxy\"] = \"\"\n",
    "        self.remotecan = RemoteCanClient(\n",
    "            host=self.can_server.host,\n",
    "            port=self.can_server.port,\n",
    "            truck=self.truck,\n",
    "            logger=self.logger,\n",
    "            dict_logger=self.dict_logger,\n",
    "        )\n",
    "\n",
    "        self.remoteClient_lock = Lock()\n",
    "\n",
    "    def init_internal_pipelines(\n",
    "        self,\n",
    "    ) -> Tuple[\n",
    "        PipelineDQ[RawType], Pipeline[str]\n",
    "    ]:  # PipelineDQ[dict[str, Union[str, dict[str, list[Union[str, list[str]]]]]]],\n",
    "        \"\"\"initialize internal pipeline static type for cloud interface\"\"\"\n",
    "        raw_pipeline = PipelineDQ[\n",
    "            RawType\n",
    "        ](  # [dict[str, dict[str, list[Union[str, list[str]]]]]]\n",
    "            maxlen=1\n",
    "        )\n",
    "        hmi_pipeline = Pipeline[str](maxsize=1)\n",
    "        return raw_pipeline, hmi_pipeline\n",
    "\n",
    "    def flash_vehicle(self, torque_table: pd.DataFrame) -> None:\n",
    "        \"\"\"flash torque table to the VCU\"\"\"\n",
    "        thread = current_thread()\n",
    "        thread.name = \"cloud_flash\"\n",
    "        with self.remoteClient_lock:\n",
    "            try:\n",
    "                self.remotecan.send_torque_map(pedal_map=torque_table, swap=True)  # 14\n",
    "            except RemoteCanException as exc:\n",
    "                self.logger.error(\n",
    "                    f\"{{'header': 'remotecan send_torque_map failed: {exc}'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                if exc.err_code in (1, 1000, 1002):\n",
    "                    self.cloud_ping()\n",
    "                    # self.cloud_telnet_test()\n",
    "                else:\n",
    "                    raise exc\n",
    "            except Exception as exc:\n",
    "                self.logger.error(\n",
    "                    f\"{{'header': 'remote get_signals failed: {exc}'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                raise exc\n",
    "\n",
    "        self.logger.info(\n",
    "            \"{'header': 'Done flash initial table'}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    def hmi_select(\n",
    "        self,\n",
    "    ) -> Callable[[Pipeline[str], Optional[Event]], None]:\n",
    "        \"\"\"\n",
    "        select HMI interface according to ui type.\n",
    "\n",
    "        Produce data into the pipeline main entry to the capture thread\n",
    "        sub-thread method\n",
    "        Callable input parameters example:\n",
    "            hmi_pipeline: Pipeline[str],\n",
    "\n",
    "        Return:\n",
    "            Callback for the HMI thread with type\n",
    "                Callable[[Pipeline[str], Optional[Event]], None]\n",
    "        \"\"\"\n",
    "        if self.ui == \"UDP\":\n",
    "            return self.hmi_capture_from_udp  # Callable[ [Pipeline[str], Event], None ]\n",
    "        elif self.ui == \"RMQ\":\n",
    "            return self.hmi_capture_from_rmq  # Callable[ [Pipeline[str], Event], None ]\n",
    "        elif self.ui == \"dummy\":\n",
    "            return (\n",
    "                self.hmi_capture_from_dummy\n",
    "            )  # Callable[ [Pipeline[str], Event], None ]\n",
    "        else:\n",
    "            raise ValueError(f\"ui must be UDP, RMQ or dummy, not {self.ui}\")\n",
    "\n",
    "    def produce(\n",
    "        self,\n",
    "        raw_pipeline: PipelineDQ[\n",
    "            RawType\n",
    "        ],  # PipelineDQ[dict[str, dict[str, list[Union[str, list[str]]]]]],\n",
    "        hmi_pipeline: Optional[Pipeline[str]] = None,\n",
    "        exit_event: Optional[Event] = None,\n",
    "    ):\n",
    "        \"\"\"Create secondary threading pool for HMI thread and data capture thread\"\"\"\n",
    "        self.logger.info(\n",
    "            \"{'header': 'cloud produce Thread Pool starts!'}\", extra=self.dict_logger\n",
    "        )\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=2,\n",
    "            thread_name_prefix=\"cloud\",\n",
    "        ) as executor:\n",
    "            executor.submit(\n",
    "                self.hmi_select(),  # will delegate to concrete the hmi control method\n",
    "                hmi_pipeline,\n",
    "                exit_event,\n",
    "            )\n",
    "\n",
    "            executor.submit(\n",
    "                self.data_capture_from_remotecan,\n",
    "                raw_pipeline,\n",
    "                exit_event,\n",
    "            )\n",
    "\n",
    "        self.logger.info(\n",
    "            \"{'header': 'cloud produce Thread Pool dies!'}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "    def data_capture_from_remotecan(\n",
    "        self,\n",
    "        raw_pipeline: PipelineDQ[\n",
    "            RawType\n",
    "        ],  # PipelineDQ[dict[str, dict[str, list[Union[str, list[str]]]]]],\n",
    "        exit_event: Optional[Event] = None,\n",
    "    ):\n",
    "        \"\"\"Callback for the data capture thread\"\"\"\n",
    "        logger_remote_get = self.logger.getChild(\"remotecan_capture\")\n",
    "        logger_remote_get.propagate = True\n",
    "\n",
    "        logger_remote_get.info(\n",
    "            \"cloud data_capture starts!\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        while not exit_event.is_set():\n",
    "            logger_remote_get.info(\n",
    "                \"wait for remote get trigger\", extra=self.dict_logger\n",
    "            )\n",
    "\n",
    "            # if episode is done, sleep for the extension time\n",
    "            # cancel wait as soon as waking up\n",
    "            timeout = self.truck.tbox_unit_number + 7\n",
    "            logger_remote_get.info(\n",
    "                f\"Wake up to fetch remote data, duration={self.truck.tbox_unit_number}s timeout={timeout}s\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            with self.remoteClient_lock:\n",
    "                try:\n",
    "                    remotecan_data: RCANType = self.remotecan.get_signals(\n",
    "                        duration=self.truck.tbox_unit_number, timeout=timeout\n",
    "                    )  # timeout is 1 second longer than duration\n",
    "                except RemoteCanException as exc:\n",
    "                    logger_remote_get.error(\n",
    "                        f\"{{'header': 'remote get_signals failed and retry', \"\n",
    "                        f\"'ret_code': '{exc.err_code}', \"\n",
    "                        f\"'ret_str': '{exc.codes[exc.err_code]}', \"\n",
    "                        f\"'extra_str': '{exc.extra_msg}'}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    # if the exception is connection related, ping the server to get further information.\n",
    "                    if exc.err_code in (1, 1000, 1002):\n",
    "                        self.cloud_ping()\n",
    "                        # self.cloud_telnet_test()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise exc\n",
    "                except Exception as exc:\n",
    "                    logger_remote_get.error(\n",
    "                        f\"{{'header': 'remote get_signals failed: {exc}'}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    raise exc\n",
    "\n",
    "            raw_pipeline.put_data(remotecan_data)  # deque is non-blocking\n",
    "\n",
    "        logger_remote_get.info(\"cloud data_capture dies!!!!!\", extra=self.dict_logger)\n",
    "\n",
    "    def cloud_ping(self):\n",
    "        \"\"\"utility function for ping test\"\"\"\n",
    "\n",
    "        response = os.system(\"ping -c 1 \" + self.can_server.host)\n",
    "        if response == 0:\n",
    "            self.logger.info(\n",
    "                f\"{{'header': 'host is up', \" f\"'host': '{self.can_server.host}'}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "        else:\n",
    "            self.logger.info(\n",
    "                f\"{{'header': 'host is down', \"\n",
    "                f\"'host': '{self.can_server.host}', \"\n",
    "                f\"'response': '{response}'}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "        # response_ping = \"\"\n",
    "        # try:\n",
    "        # response_ping = subprocess.check_output(\n",
    "        #     \"ping -c 1 \" + self.can_server.host, shell=True\n",
    "        # )\n",
    "        # except subprocess.CalledProcessError as e:\n",
    "        #     self.logger.info(\n",
    "        #         f\"{self.can_server.host} is down, responds: {response_ping}\"\n",
    "        #         f\"return code: {e.return_code}, output: {e.output}!\",\n",
    "        #         extra=self.dict_logger,\n",
    "        #     )\n",
    "        # self.logger.info(\n",
    "        #     f\"{self.can_server.host} is up, responds: {response}!\",\n",
    "        #     extra=self.dict_logger,\n",
    "        # )\n",
    "\n",
    "    def cloud_telnet_test(self):\n",
    "        \"\"\"Utility function for telnet test\"\"\"\n",
    "        try:\n",
    "            response_telnet = subprocess.check_output(\n",
    "                f\"timeout 1 telnet {self.can_server.host} {self.can_server.port}\",\n",
    "                shell=True,\n",
    "            )\n",
    "            self.logger.info(\n",
    "                f\"Telnet {self.can_server.host} responds: {response_telnet}!\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.logger.info(\n",
    "                f\"telnet {self.can_server.host} return code: {e.returncode}, output: {e.output}!\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "        except subprocess.TimeoutExpired as e:\n",
    "            self.logger.info(\n",
    "                f\"telnet {self.can_server.host} timeout\"\n",
    "                f\"cmd: {e.cmd}, output: {e.output}, timeout: {e.timeout}!\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "    def hmi_capture_from_udp(\n",
    "        self,\n",
    "        hmi_pipeline: Pipeline[str],\n",
    "        exit_event: Optional[Event] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Callback function for getting HMI message from local UDP\"\"\"\n",
    "        logger_hmi_capture_udp = self.logger.getChild(\"hmi_capture_udp\")\n",
    "        logger_hmi_capture_udp.propagate = True\n",
    "\n",
    "        logger_hmi_capture_udp.info(\n",
    "            \"{'header': 'cloud hmi_capture udp thread starts!'}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        with udp_context(self.can_server.host, self.can_server.port) as s:\n",
    "            can_data, addr = s.recvfrom(2048)\n",
    "            # self.logger.info('Data received!!!', extra=self.dict_logger)\n",
    "            while True:\n",
    "                try:\n",
    "                    pop_data = json.loads(can_data)\n",
    "                except TypeError:\n",
    "                    raise TypeError(\"udp sending wrong data type!\")\n",
    "\n",
    "                for key, value in pop_data.items():\n",
    "                    if key == \"status\":  # state machine chores\n",
    "                        assert isinstance(\n",
    "                            value, str\n",
    "                        ), \"udp sending wrong data type of status!\"\n",
    "                        hmi_pipeline.put_data(value)\n",
    "                    elif key == \"data\":\n",
    "                        # TODO this data may be stored for future benchmarking of cloud data quality\n",
    "                        logger_hmi_capture_udp.info(\n",
    "                            \"{'header': 'udp data message ignored for now!'}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                    else:\n",
    "                        logger_hmi_capture_udp.warning(\n",
    "                            f\"{{'header': 'udp sending message with key: {key}; value: {value}'}}\"\n",
    "                        )\n",
    "\n",
    "                        break\n",
    "                if key == \"status\" and value == \"exit\":  # exit thread and program\n",
    "                    # exit_event.set()  # exit_event will be set from hmi_control()\n",
    "                    if not exit_event.is_set():\n",
    "                        exit_event.set()\n",
    "                    break\n",
    "\n",
    "        logger_hmi_capture_udp.info(\n",
    "            \"{'header': 'cloud hmi_capture udp thread dies!'}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    def hmi_capture_from_rmq(\n",
    "        self,\n",
    "        hmi_pipeline: Pipeline[str],\n",
    "        exit_event: Optional[Event] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get the hmi message from RocketMQ\n",
    "        \"\"\"\n",
    "        logger_rmq = self.logger.getChild(\"hmi_capture_rmq\")\n",
    "        logger_rmq.propagate = True\n",
    "\n",
    "        logger_rmq.info(\n",
    "            \"{'header': 'cloud hmi_capture_rmq thread starts!'}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        # Create RocketMQ consumer\n",
    "        rmq_consumer = ClearablePullConsumer(\"CID_EPI_ROCKET\")\n",
    "        rmq_consumer.set_namesrv_addr(\n",
    "            self.trip_server.host + \":\" + self.trip_server.port\n",
    "        )\n",
    "\n",
    "        # Create RocketMQ producer\n",
    "        rmq_message_ready = Message(\"update_ready_state\")\n",
    "        rmq_message_ready.set_keys(\"what is keys mean\")\n",
    "        rmq_message_ready.set_tags(\"tags ------\")\n",
    "        rmq_message_ready.set_body(\n",
    "            json.dumps({\"vin\": self.truck.vid, \"is_ready\": True})\n",
    "        )\n",
    "        # self.rmq_message_ready.set_keys('trip_server')\n",
    "        # self.rmq_message_ready.set_tags('tags')\n",
    "        rmq_producer = Producer(\"PID-EPI_ROCKET\")\n",
    "        assert rmq_producer is not None, \"rmq_producer is None\"\n",
    "        rmq_producer.set_namesrv_addr(\n",
    "            self.trip_server.host + \":\" + self.trip_server.port\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            rmq_consumer.start()\n",
    "            rmq_producer.start()\n",
    "            logger_rmq.info(\n",
    "                f\"Start RocketMQ client on {self.trip_server.host}!\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "            msg_topic = self.driver.pid + \"_\" + self.truck.vin\n",
    "\n",
    "            broker_msgs = rmq_consumer.pull(msg_topic)\n",
    "            logger_rmq.info(\n",
    "                f\"Before clearing history: Pull {len(list(broker_msgs))} history messages of {msg_topic}!\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            rmq_consumer.clear_history(msg_topic)\n",
    "            broker_msgs = rmq_consumer.pull(msg_topic)\n",
    "            logger_rmq.info(\n",
    "                f\"After clearing history: Pull {len(list(broker_msgs))} history messages of {msg_topic}!\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            all(broker_msgs)  # exhaust history messages\n",
    "\n",
    "        except Exception as e:\n",
    "            logger_rmq.error(\n",
    "                f\"send_sync failed: {e}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            raise e\n",
    "        try:\n",
    "            # send ready signal to trip server\n",
    "            ret = rmq_producer.send_sync(rmq_message_ready)\n",
    "            logger_rmq.info(\n",
    "                f\"Sending ready signal to trip server:\"\n",
    "                f\"status={ret.status};\"\n",
    "                f\"msg-id={ret.msg_id};\"\n",
    "                f\"offset={ret.offset}.\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "            logger_rmq.info(\n",
    "                \"RocketMQ client Initialization Done!\", extra=self.dict_logger\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger_rmq.error(\n",
    "                f\"Fatal Failure!: {e}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            raise e\n",
    "\n",
    "        msg_body = {}\n",
    "        while True:  # th_exit is local; program_exit is global\n",
    "            msgs = rmq_consumer.pull(msg_topic)\n",
    "            for msg in msgs:\n",
    "                try:\n",
    "                    msg_body = json.loads(msg.body)\n",
    "                except TypeError:\n",
    "                    raise TypeError(\"rocketmq server sending wrong data type!\")\n",
    "                logger_rmq.info(f\"Get message {msg_body}!\", extra=self.dict_logger)\n",
    "                if msg_body[\"vin\"] != self.truck.vin:\n",
    "                    continue\n",
    "\n",
    "                if msg_body[\"code\"] == 5:  # \"config/start testing\"\n",
    "                    logger_rmq.info(\n",
    "                        f\"Restart/Reconfigure message VIN: {msg_body['vin']}; driver {msg_body['name']}!\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "\n",
    "                    # send ready signal to trip server\n",
    "                    ret = self.rmq_producer.send_sync(self.rmq_message_ready)\n",
    "                    logger_rmq.info(\n",
    "                        f\"Sending ready signal to trip server:\"\n",
    "                        f\"status={ret.status};\"\n",
    "                        f\"msg-id={ret.msg_id};\"\n",
    "                        f\"offset={ret.offset}.\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    # hmi_pipeline.put_data(\"begin\")\n",
    "\n",
    "                elif msg_body[\"code\"] == 1:  # start episode\n",
    "                    logger_rmq.info(\n",
    "                        \"%s\", \"Episode will start!!!\", extra=self.dict_logger\n",
    "                    )\n",
    "                    hmi_pipeline.put_data(\"begin\")\n",
    "\n",
    "                elif msg_body[\"code\"] == 2:  # valid stop\n",
    "                    # DONE for valid end wait for another 2 queue objects (3 seconds) to get the last reward!\n",
    "                    # cannot sleep the thread since data capturing in the same thread, use signal alarm instead\n",
    "\n",
    "                    logger_rmq.info(\"End Valid!!!!!!\", extra=self.dict_logger)\n",
    "                    hmi_pipeline.put_data(\"end_valid\")\n",
    "                elif msg_body[\"code\"] == 3:  # invalid stop\n",
    "                    logger_rmq.info(\"Episode is interrupted!!!\", extra=self.dict_logger)\n",
    "                    hmi_pipeline.put_data(\"end_invalid\")\n",
    "\n",
    "                elif msg_body[\"code\"] == 4:  # \"exit\"\n",
    "                    logger_rmq.info(\n",
    "                        \"Program exit!!!! free remote_flash and remote_get!\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    hmi_pipeline.put_data(\"exit\")\n",
    "                    if not exit_event.is_set():\n",
    "                        exit_event.set()\n",
    "                    # exit_event.set()  # exit_event will be set from hmi_control()\n",
    "                    break\n",
    "                else:\n",
    "                    logger_rmq.warning(\n",
    "                        f\"Unknown message {msg_body}!\", extra=self.dict_logger\n",
    "                    )\n",
    "            try:\n",
    "                if msg_body[\"code\"] == 4:  # \"exit\"\n",
    "                    break\n",
    "            except KeyError:\n",
    "                raise KeyError(f\"msg_body {msg_body} of RMQ has no defined code!\")\n",
    "\n",
    "        rmq_consumer.shutdown()\n",
    "        rmq_producer.shutdown()\n",
    "        logger_rmq.info(\"hmi_capture_from_rmq dies!!!\", extra=self.dict_logger)\n",
    "\n",
    "    def hmi_capture_from_dummy(\n",
    "        self,\n",
    "        hmi_pipeline: Pipeline[str],\n",
    "        exit_event: Event,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get the hmi status from dummy state management and remote can module\n",
    "\n",
    "        The only way to change the state with dummy mode is through Graceful Killer (Ctrl +C), which is triggered by GracefulKiller in the Cruncher thread and received in hmi_control\n",
    "        \"\"\"\n",
    "        logger_hmi_dummy = self.logger.getChild(\"hmi_capture_dummy\")\n",
    "        logger_hmi_dummy.propagate = True\n",
    "\n",
    "        logger_hmi_dummy.info(\n",
    "            \"{'header': 'cloud hmi_capture_dummy thread starts!'}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        hmi_pipeline.put_data(\n",
    "            \"begin\"\n",
    "        )  # start once and wait for exit from the GracefulKiller\n",
    "        while not exit_event.is_set():\n",
    "            time.sleep(1.0)\n",
    "\n",
    "        hmi_pipeline.put_data(\"exit\")\n",
    "        # exit_event.set()  # exit_event will be set from hmi_control()\n",
    "        # exit hmi control thread\n",
    "        logger_hmi_dummy.info(\n",
    "            \"{'header': 'cloud hmi_capture_dummy thread dies!'}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    def filter(\n",
    "        self,\n",
    "        in_pipeline: PipelineDQ[RawType],  # input pipelineDQ[raw data],\n",
    "        out_pipeline: Pipeline[pd.DataFrame],  # output pipeline[DataFrame]\n",
    "        start_event: Optional[Event],  # input event start\n",
    "        stop_event: Optional[Event],  # not used for cloud\n",
    "        interrupt_event: Optional[Event],  # not used for cloud\n",
    "        flash_event: Optional[\n",
    "            Event\n",
    "        ],  # required, in cloud only capture after flashing succeeds\n",
    "        exit_event: Optional[Event],  # input event exit\n",
    "    ) -> None:\n",
    "        \"\"\"Callback function for the data filter thread, encapsulating the data into pandas DataFrame\"\"\"\n",
    "        thread = current_thread()\n",
    "        thread.name = \"cloud_filter\"\n",
    "        logger_filter = self.logger.getChild(\"data_out\")\n",
    "        logger_filter.propagate = True\n",
    "\n",
    "        logger_filter.info(\n",
    "            \"cloud data filter thread starts!\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        while not exit_event.is_set():\n",
    "            try:\n",
    "                remotecan_data: RCANType = cast(\n",
    "                    RCANType, in_pipeline.get_data()\n",
    "                )  # deque is non-blocking, cast is to sooth mypy\n",
    "\n",
    "            except IndexError:  # if deque is empty, IndexError will be raised\n",
    "                continue\n",
    "            assert isinstance(remotecan_data, dict), \"remotecan_data is not a dict!\"\n",
    "\n",
    "            # as long as flashing is on going, always waiting for flash\n",
    "            if start_event.is_set():\n",
    "                try:\n",
    "                    signal_freq = self.truck.tbox_signal_frequency\n",
    "                    gear_freq = self.truck.tbox_gear_frequency\n",
    "                    unit_duration = self.truck.tbox_unit_duration\n",
    "                    unit_ob_num = unit_duration * signal_freq\n",
    "                    unit_gear_num = unit_duration * gear_freq\n",
    "                    unit_num = self.truck.tbox_unit_number\n",
    "                    for key, value in remotecan_data.items():\n",
    "                        if key == \"result\":\n",
    "                            logger_filter.info(\n",
    "                                \"convert observation state to array.\",\n",
    "                                extra=self.dict_logger,\n",
    "                            )\n",
    "                            # timestamp processing\n",
    "                            timestamps_arr = timestamps_from_can_strings(\n",
    "                                cast(list[str], value[\"timestamps\"]),\n",
    "                                signal_freq,\n",
    "                                unit_num,\n",
    "                                unit_duration,\n",
    "                            )\n",
    "\n",
    "                            current_arr = ragged_nparray_list_interp(\n",
    "                                cast(list[list[str]], value[\"list_current_1s\"]),\n",
    "                                ob_num=unit_ob_num,\n",
    "                            )\n",
    "                            voltage_arr = ragged_nparray_list_interp(\n",
    "                                cast(list[list[str]], value[\"list_voltage_1s\"]),\n",
    "                                ob_num=unit_ob_num,\n",
    "                            )\n",
    "                            thrust_arr = ragged_nparray_list_interp(\n",
    "                                cast(list[list[str]], value[\"list_pedal_1s\"]),\n",
    "                                ob_num=unit_ob_num,\n",
    "                            )\n",
    "                            brake_arr = ragged_nparray_list_interp(\n",
    "                                cast(list[list[str]], value[\"list_brake_pressure_1s\"]),\n",
    "                                ob_num=unit_ob_num,\n",
    "                            )\n",
    "                            velocity_arr = ragged_nparray_list_interp(\n",
    "                                cast(list[list[str]], value[\"list_speed_1s\"]),\n",
    "                                ob_num=unit_ob_num,\n",
    "                            )\n",
    "                            gears_arr = ragged_nparray_list_interp(\n",
    "                                cast(list[list[str]], value[\"list_gears\"]),\n",
    "                                ob_num=unit_gear_num,\n",
    "                            )\n",
    "                            # up-sample gears from 2Hz to 50Hz\n",
    "                            gears_arr = np.repeat(\n",
    "                                gears_arr,\n",
    "                                (signal_freq // gear_freq),\n",
    "                                axis=1,\n",
    "                            )\n",
    "\n",
    "                            motion_power = np.c_[\n",
    "                                timestamps_arr.reshape(-1, 1),\n",
    "                                velocity_arr.reshape(-1, 1),\n",
    "                                thrust_arr.reshape(-1, 1),\n",
    "                                brake_arr.reshape(-1, 1),\n",
    "                                gears_arr.reshape(-1, 1),\n",
    "                                current_arr.reshape(-1, 1),\n",
    "                                voltage_arr.reshape(-1, 1),\n",
    "                            ]  # 1 + 3 + 1 + 2  : im 7\n",
    "\n",
    "                            # 0~20km/h; 7~30km/h; 10~40km/h; 20~50km/h; ...\n",
    "                            # average concept\n",
    "                            # 10; 18; 25; 35; 45; 55; 65; 75; 85; 95; 105\n",
    "                            #   13; 18; 22; 27; 32; 37; 42; 47; 52; 57; 62;\n",
    "                            # here upper bound rule adopted\n",
    "                            vel_max = np.amax(velocity_arr)\n",
    "                            if vel_max < 20:\n",
    "                                self.vcu_calib_table_row_start = 0\n",
    "                            elif vel_max < 30:\n",
    "                                self.vcu_calib_table_row_start = 1\n",
    "                            elif vel_max < 120:\n",
    "                                self.vcu_calib_table_row_start = (\n",
    "                                    math.floor((vel_max - 30) / 10) + 2\n",
    "                                )\n",
    "                            else:\n",
    "                                logger_filter.warning(\n",
    "                                    \"cycle higher than 120km/h!\",\n",
    "                                    extra=self.dict_logger,\n",
    "                                )\n",
    "                                self.vcu_calib_table_row_start = 16\n",
    "\n",
    "                            logger_filter.info(\n",
    "                                f\"Cycle velocity: Aver{np.mean(velocity_arr):.2f},\"\n",
    "                                f\"Min{np.amin(velocity_arr):.2f},\"\n",
    "                                f\"Max{np.amax(velocity_arr):.2f},\"\n",
    "                                f\"StartIndex{self.vcu_calib_table_row_start}!\",\n",
    "                                extra=self.dict_logger,\n",
    "                            )\n",
    "\n",
    "                            df_motion_power = pd.DataFrame(\n",
    "                                motion_power,\n",
    "                                columns=[\n",
    "                                    \"timestep\",\n",
    "                                    \"velocity\",\n",
    "                                    \"thrust\",\n",
    "                                    \"brake\",\n",
    "                                    \"current\",\n",
    "                                    \"voltage\",\n",
    "                                ],\n",
    "                            )\n",
    "                            # df_motion_power.set_index('timestamp', inplace=True)\n",
    "                            df_motion_power.columns.name = \"qtuple\"\n",
    "                            out_pipeline.put_data(df_motion_power)\n",
    "                            flash_event.wait()  # wait for cruncher to consume and flash to finish\n",
    "                            flash_event.clear()  # reset flash_event as the first waiter\n",
    "\n",
    "                            logger_filter.info(\n",
    "                                \"evt_remote_flash wakes up, reset inner lock, restart remote_get!!!\",\n",
    "                                extra=self.dict_logger,\n",
    "                            )\n",
    "                        else:\n",
    "                            logger_filter.info(\n",
    "                                f\"show status: {key}:{value}\",\n",
    "                                extra=self.dict_logger,\n",
    "                            )\n",
    "                except Exception as exc:\n",
    "                    logger_filter.error(\n",
    "                        f\"Observation Corrupt! Status exception {exc}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "\n",
    "        logger_filter.info(\"cloud data filter dies!!!!!\", extra=self.dict_logger)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6823530748f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65be53142bb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.init_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9714e5d18d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.init_internal_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2642afc7cdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.flash_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2944e3afdf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.hmi_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bd55fefbd5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.produce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b1ba09e257c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.data_capture_from_remotecan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52986350c293818",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.cloud_ping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef4c8b34af13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.cloud_telnet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06882aa43572a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.hmi_capture_from_udp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da000e37126a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.hmi_capture_from_rmq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c8978b336fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.hmi_capture_from_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d366aa43327add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cloud.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be642972b0d481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev \n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
