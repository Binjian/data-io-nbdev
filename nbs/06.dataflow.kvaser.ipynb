{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.119880117Z",
     "start_time": "2023-12-19T13:10:34.104822845Z"
    }
   },
   "id": "6a0983f94822eb03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kvaser\n",
    "\n",
    "> Kvaser class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c482188e184b243d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#| default_exp dataflow.kvaser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.161983861Z",
     "start_time": "2023-12-19T13:10:34.119941531Z"
    }
   },
   "id": "a50765c6a0ea76ef"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "from threading import Event, current_thread\n",
    "from typing import Optional, Tuple, cast\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.357977624Z",
     "start_time": "2023-12-19T13:10:34.161078036Z"
    }
   },
   "id": "58bf20fb565d2363"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#| export\n",
    "from data_io_nbdev.dataflow.consumer import Consumer  # type: ignore\n",
    "from data_io_nbdev.dataflow.pipeline.queue import Pipeline  # type: ignore\n",
    "from data_io_nbdev.dataflow.pipeline.deque import PipelineDQ  # type: ignore\n",
    "from data_io_nbdev.dataflow.producer import Producer  # type: ignore\n",
    "from data_io_nbdev.dataflow.vehicle_interface import VehicleInterface  # type: ignore"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.462302556Z",
     "start_time": "2023-12-19T13:10:34.359951626Z"
    }
   },
   "id": "1fb81fc346957ad"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from data_io_nbdev.conn.tbox import TBoxCanException, kvaser_send_float_array\n",
    "from data_io_nbdev.conn.udp import udp_context\n",
    "from data_io_nbdev.data.core import MotionPower, RawType, KvaserType\n",
    "from data_io_nbdev.config.messengers import CANMessenger, can_servers_by_name\n",
    "from data_io_nbdev.config.vehicles import TruckInField"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.563471781Z",
     "start_time": "2023-12-19T13:10:34.463233448Z"
    }
   },
   "id": "41d65086bad94b5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Kvaser(VehicleInterface):\n",
    "    \"\"\"\n",
    "    Kvaser is local vehicle interface with Producer(get vehicle status) and Consumer(flasher)\n",
    "    \n",
    "    Attributes:\n",
    "        \n",
    "        truck: TruckInField\n",
    "            truck object\n",
    "        can_server: CANMessenger\n",
    "            can server object\n",
    "    \"\"\"\n",
    "    truck: TruckInField\n",
    "    can_server: CANMessenger = can_servers_by_name[\"can_udp_svc\"]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.logger.info(\"Kvaser initialized\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"kvaser\"\n",
    "\n",
    "    def flash_vehicle(self, \n",
    "                    torque_table: pd.DataFrame  # the torque table to be flashed\n",
    "                    ) -> None:\n",
    "        \"\"\"flash the torque table to the vehicle via kvaser\"\"\"\n",
    "        \n",
    "        try:\n",
    "            kvaser_send_float_array(torque_table, sw_diff=True)\n",
    "        except TBoxCanException as exc:\n",
    "            raise exc\n",
    "        except Exception as exc:\n",
    "            raise exc\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'Done with flashing table'}}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    def init_internal_pipelines(\n",
    "        self,\n",
    "    ) -> Tuple[\n",
    "        PipelineDQ[RawType], Pipeline[str]\n",
    "    ]:  # Tuple[PipelineDQ[dict[str,Union[str,list[str]]]], Pipeline[str]]\n",
    "        \"\"\"initialize the internal pipelines for kvaser\"\"\"\n",
    "        raw_pipeline = PipelineDQ[RawType](maxlen=1)\n",
    "        hmi_pipeline = Pipeline[str](maxsize=1)\n",
    "        return raw_pipeline, hmi_pipeline\n",
    "\n",
    "    def produce(\n",
    "        self,\n",
    "        raw_pipeline: PipelineDQ[RawType],  # PipelineDQ[dict[str, str]],\n",
    "        hmi_pipeline: Optional[Pipeline[str]] = None,  # HMI pipeline\n",
    "        exit_event: Optional[Event] = None,  # input event exit\n",
    "    ):\n",
    "        \"\"\"produce data from kvaser and put into the pipeline\"\"\"\n",
    "        thread = current_thread()\n",
    "        thread.name = \"kvaser_capture\"\n",
    "        logger_kvaser_get = self.logger.getChild(\"kvaser_capture\")\n",
    "        logger_kvaser_get.propagate = True\n",
    "        logger_kvaser_get.info(\n",
    "            f\"{{'header': 'kvaser capture thread start!'}}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "        with udp_context(self.can_server.host, self.can_server.port) as s:\n",
    "            # self.logger.info('Data received!!!', extra=self.dict_logger)\n",
    "            while not exit_event.is_set():\n",
    "                try:\n",
    "                    can_data, addr = s.recvfrom(2048)\n",
    "                    pop_data = json.loads(can_data)\n",
    "                except TypeError:\n",
    "                    raise TypeError(\"udp sending wrong data type!\")\n",
    "                except Exception as exc:\n",
    "                    logger_kvaser_get.error(\n",
    "                        f\"{{'header': 'udp reception error', \" \n",
    "                        f\"'exception': '{exc}'}}\"\n",
    "                    )\n",
    "                    raise exc\n",
    "                for key, value in pop_data.items():\n",
    "                    if key == \"status\":  # state machine chores\n",
    "                        assert (\n",
    "                            type(value) is str\n",
    "                        ), \"udp sending wrong data type of status!\"\n",
    "                        hmi_pipeline.put_data(value)\n",
    "                    elif key == \"data\":\n",
    "                        assert (\n",
    "                            type(value) is dict\n",
    "                        ), \"udp sending wrong data type of data!\"\n",
    "                        raw_pipeline.put_data(value)\n",
    "                    else:\n",
    "                        logger_kvaser_get.warning(\n",
    "                            f\"{{'header': 'udp sending message with key: {key}; value: {value}'}}\"\n",
    "                        )\n",
    "\n",
    "                        break\n",
    "                if (\n",
    "                    key == \"status\" and value == \"exit\"\n",
    "                ):  # exit thread and program, if earlier than the exit event\n",
    "                    break\n",
    "\n",
    "            # exit the thread\n",
    "            logger_kvaser_get.info(\n",
    "                f\"{{'header': 'kvaser_capture dies!!!'}}\", extra=self.dict_logger\n",
    "            )\n",
    "\n",
    "    def filter(\n",
    "        self,\n",
    "        in_pipeline: PipelineDQ[RawType],  # input PipelineDQ[dict[str, str]],\n",
    "        out_pipeline: Pipeline[pd.DataFrame],  # output Pipeline[pd.DataFrame],\n",
    "        start_event: Optional[Event],  # input event start\n",
    "        stop_event: Optional[Event],  # input event stop\n",
    "        interrupt_event: Optional[Event],  # input event interrupt\n",
    "        flash_event: Optional[\n",
    "            Event\n",
    "        ],  # input & output event, maybe unnecessary for kvaser\n",
    "        exit_event: Optional[Event],  # input event exit\n",
    "    ) -> None:\n",
    "        \"\"\"filter data from kvaser input pipeline and put into the output pipeline\"\"\"\n",
    "        thread = current_thread()\n",
    "        thread.name = \"kvaser_filter\"\n",
    "        logger_kvaser_out = self.logger.getChild(\"data_transform\")\n",
    "        logger_kvaser_out.propagate = True\n",
    "        motion_power_t: list[MotionPower] = []\n",
    "        logger_kvaser_out.info(\"{{'header': 'kvaser data transform thread start'}}\", extra=self.dict_logger)\n",
    "\n",
    "        while not exit_event.is_set():\n",
    "            #  always get data from the pipeline if available, forwarding outward depends on the HMI status\n",
    "            try:\n",
    "                data: KvaserType = cast(\n",
    "                    KvaserType, in_pipeline.get_data()\n",
    "                )  # non-blocking, get the most recent data, cast is to sooth mypy\n",
    "\n",
    "            except IndexError:\n",
    "                continue  # empty deque\n",
    "\n",
    "            # logger_kvaser_out.info(\"{{'header': 'kvaser get data'}}\", extra=self.dict_logger)\n",
    "\n",
    "            if start_event.is_set():  # starts episode\n",
    "                try:\n",
    "                    timestep = pd.Timestamp.now(tz=self.truck.site.tz)\n",
    "                    velocity = float(data[\"velocity\"])\n",
    "                    pedal = float(data[\"pedal\"])\n",
    "                    brake = float(data[\"brake_pressure\"])\n",
    "                    current = float(data[\"A\"])\n",
    "                    voltage = float(data[\"V\"])\n",
    "\n",
    "                    motion_power = MotionPower(\n",
    "                        timestep,\n",
    "                        velocity,\n",
    "                        pedal,\n",
    "                        brake,\n",
    "                        current,\n",
    "                        voltage,\n",
    "                    )\n",
    "                    # 3 +2 : im 5\n",
    "\n",
    "                    motion_power_t.append(\n",
    "                        motion_power\n",
    "                    )  # obs_reward [timestep, speed, pedal, brake, current, voltage]\n",
    "\n",
    "                    if len(motion_power_t) == self.truck.observation_length:\n",
    "                        df_motion_power = pd.DataFrame(\n",
    "                            motion_power_t,\n",
    "                            columns=[\n",
    "                                \"timestep\",\n",
    "                                \"velocity\",\n",
    "                                \"thrust\",\n",
    "                                \"brake\",\n",
    "                                \"current\",\n",
    "                                \"voltage\",\n",
    "                            ],\n",
    "                        )\n",
    "                        # df_motion_power.set_index('timestamp', inplace=True)\n",
    "                        df_motion_power.columns.name = \"qtuple\"\n",
    "\n",
    "                        out_pipeline.put_data(df_motion_power)\n",
    "                        logger_kvaser_out.info(\n",
    "                            f\"{{'header': 'convert one dataframe and wait.'}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        flash_event.wait()  # wait for cruncher to consume and flashing to finish\n",
    "                        flash_event.clear()  # clear the flash event here as the first waiter\n",
    "                        logger_kvaser_out.info(\n",
    "                            f\"{{'header': 'wake up after flashing'}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        # for kvaser the parameter is configured for waiting,\n",
    "                        # maybe the event is not necessary, for cloud interface the flash event is necessary\n",
    "                        observe_queue_size = out_pipeline.qsize()\n",
    "                        if observe_queue_size != 0:\n",
    "                            raise ValueError(\n",
    "                                f\"observe pipeline queue size: {observe_queue_size}, \"\n",
    "                                f\"must be zero, if cruncher has consumed\"\n",
    "                            )\n",
    "                        motion_power_t = []\n",
    "                except Exception as exc:\n",
    "                    logger_kvaser_out.info(\n",
    "                        f\"{{'header': 'kvaser get signal error',\"\n",
    "                        f\"'exception': '{exc}'}}\",\n",
    "                        # f\"Valid episode, Reset data capturing to stop after 3 seconds!\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    break\n",
    "            elif interrupt_event.is_set() or stop_event.is_set():  # interrupt episode\n",
    "                motion_power_t = []  # clean up list of motion power states\n",
    "\n",
    "        # exit the thread\n",
    "        logger_kvaser_out.info(\n",
    "            f\"{{'header': 'data_transform dies!!!'}}\", extra=self.dict_logger\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.605298934Z",
     "start_time": "2023-12-19T13:10:34.563925811Z"
    }
   },
   "id": "5e0f8e118b136d0d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.745295281Z",
     "start_time": "2023-12-19T13:10:34.605172069Z"
    }
   },
   "id": "a162c4e1abb9ce0c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "---\n\n### Kvaser.filter\n\n>      Kvaser.filter (in_pipeline:data_io_nbdev.dataflow.pipeline.deque.Pipeline\n>                     DQ[typing.Union[dict[str,str],dict[str,dict[str,list[typin\n>                     g.Union[str,list[list[str]]]]]]]], out_pipeline:data_io_nb\n>                     dev.dataflow.pipeline.queue.Pipeline[pandas.core.frame.Dat\n>                     aFrame], start_event:Optional[threading.Event],\n>                     stop_event:Optional[threading.Event],\n>                     interrupt_event:Optional[threading.Event],\n>                     flash_event:Optional[threading.Event],\n>                     exit_event:Optional[threading.Event])\n\nfilter data from kvaser input pipeline and put into the output pipeline\n\n|    | **Type** | **Details** |\n| -- | -------- | ----------- |\n| in_pipeline | PipelineDQ | input PipelineDQ[dict[str, str]], |\n| out_pipeline | Pipeline | output Pipeline[pd.DataFrame], |\n| start_event | Optional | input event start |\n| stop_event | Optional | input event stop |\n| interrupt_event | Optional | input event interrupt |\n| flash_event | Optional |  |\n| exit_event | Optional | input event exit |\n| **Returns** | **None** |  |",
      "text/markdown": "---\n\n### Kvaser.filter\n\n>      Kvaser.filter (in_pipeline:data_io_nbdev.dataflow.pipeline.deque.Pipeline\n>                     DQ[typing.Union[dict[str,str],dict[str,dict[str,list[typin\n>                     g.Union[str,list[list[str]]]]]]]], out_pipeline:data_io_nb\n>                     dev.dataflow.pipeline.queue.Pipeline[pandas.core.frame.Dat\n>                     aFrame], start_event:Optional[threading.Event],\n>                     stop_event:Optional[threading.Event],\n>                     interrupt_event:Optional[threading.Event],\n>                     flash_event:Optional[threading.Event],\n>                     exit_event:Optional[threading.Event])\n\nfilter data from kvaser input pipeline and put into the output pipeline\n\n|    | **Type** | **Details** |\n| -- | -------- | ----------- |\n| in_pipeline | PipelineDQ | input PipelineDQ[dict[str, str]], |\n| out_pipeline | Pipeline | output Pipeline[pd.DataFrame], |\n| start_event | Optional | input event start |\n| stop_event | Optional | input event stop |\n| interrupt_event | Optional | input event interrupt |\n| flash_event | Optional |  |\n| exit_event | Optional | input event exit |\n| **Returns** | **None** |  |"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Kvaser.flash_vehicle)\n",
    "show_doc(Kvaser.init_internal_pipelines)\n",
    "show_doc(Kvaser.produce)\n",
    "show_doc(Kvaser.filter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:34.833563972Z",
     "start_time": "2023-12-19T13:10:34.747733761Z"
    }
   },
   "id": "a5bb807037ded83"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T13:10:36.786742874Z",
     "start_time": "2023-12-19T13:10:34.833197614Z"
    }
   },
   "id": "369b1769b46f83e8"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
