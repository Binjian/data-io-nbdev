{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ba9082d74d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38130d4ed75344",
   "metadata": {},
   "source": [
    "# Pandas utilities\n",
    "\n",
    "> utilites for auxiliary pandas DataFrame processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b79acf6cb8376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.external.pandas_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f58841f0510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from typing import Dict, List, Optional, Tuple, Union, cast\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eed8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 10:04:16.051749: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-14 10:04:16.085577: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 10:04:16.085618: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 10:04:16.085647: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 10:04:16.092064: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-14 10:04:16.092796: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5a14a8cba841d",
   "metadata": {},
   "source": [
    "## Dataframe for state, action, reward, next_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assemble_state_ser(\n",
    "    state_columns: pd.DataFrame,  # state_columns: Dataframe with columns ['timestep', 'velocity', 'thrust', 'brake']\n",
    "        tz: ZoneInfo  # timezone for the timestamp\n",
    ") -> Tuple[pd.Series, int]:  # state: Series with index ['rows', 'idx'], table_row_start: int\n",
    "    \"\"\"\n",
    "    assemble state df from state_columns dataframe order is vital for the model\n",
    "    \n",
    "    inputs:\n",
    "    \n",
    "        state_columns: pd.DataFrame\n",
    "    \n",
    "    \"timestep, velocity, thrust, brake\"\n",
    "    contiguous storage in each measurement\n",
    "    due to sort_index, output:\n",
    "    [col0: brake, col1: thrust, col2: timestep, col3: velocity]\n",
    "    \n",
    "    return:\n",
    "    \n",
    "        state: pd.Series\n",
    "        table_row_start: int\n",
    "    \"\"\"\n",
    "\n",
    "    # state_columns['timestep'] = pd.to_datetime(datetime.now().timestamp(), unit='us').tz_localize(tz)\n",
    "    state: pd.Series = cast(\n",
    "        pd.Series,\n",
    "        (state_columns.stack().swaplevel(0, 1)),\n",
    "    )\n",
    "    state.name = \"state\"\n",
    "    state.index.names = [\"rows\", \"idx\"]\n",
    "    state.sort_index(\n",
    "        inplace=True\n",
    "    )  # sort by rows and idx (brake, thrust, timestep, velocity)\n",
    "    # str_as_type = f\"datetime64[us,{tz.key}]\"  # type: ignore\n",
    "    # state['timestep'].astype(str_as_type, copy=False)\n",
    "\n",
    "    vel_stats = state[\"velocity\"].astype(\"float\").describe()\n",
    "\n",
    "    # 0~20km/h; 7~30km/h; 10~40km/h; 20~50km/h; ...\n",
    "    # average concept\n",
    "    # 10; 18; 25; 35; 45; 55; 65; 75; 85; 95; 105\n",
    "    #   13; 18; 22; 27; 32; 37; 42; 47; 52; 57; 62;\n",
    "    # here upper bound rule adopted\n",
    "    if vel_stats[\"max\"] < 20:\n",
    "        table_row_start = 0\n",
    "    elif vel_stats[\"max\"] < 30:\n",
    "        table_row_start = 1\n",
    "    elif vel_stats[\"max\"] < 120:\n",
    "        table_row_start = math.floor((vel_stats[\"max\"] - 30) / 10) + 2\n",
    "    else:\n",
    "        table_row_start = 16  # cycle higher than 120km/h!\n",
    "    # get the row of the table\n",
    "\n",
    "    return state, table_row_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38859bc049df0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "---\n\n[source](https://github.com/Binjian/data-io-nbdev/tree/main/blob/main/data_io_nbdev/data/external/pandas_utils.py#L23){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n\n### assemble_state_ser\n\n>      assemble_state_ser (state_columns:pandas.core.frame.DataFrame,\n>                          tz:zoneinfo.ZoneInfo)\n\nassemble state df from state_columns dataframe order is vital for the model\n\ninputs:\n\n    state_columns: pd.DataFrame\n\n\"timestep, velocity, thrust, brake\"\ncontiguous storage in each measurement\ndue to sort_index, output:\n[col0: brake, col1: thrust, col2: timestep, col3: velocity]\n\nreturn:\n\n    state: pd.Series\n    table_row_start: int\n\n|    | **Type** | **Details** |\n| -- | -------- | ----------- |\n| state_columns | DataFrame | state_columns: Dataframe with columns ['timestep', 'velocity', 'thrust', 'brake'] |\n| tz | ZoneInfo | timezone for the timestamp |\n| **Returns** | **Tuple** |  |",
      "text/plain": "---\n\n[source](https://github.com/Binjian/data-io-nbdev/tree/main/blob/main/data_io_nbdev/data/external/pandas_utils.py#L23){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n\n### assemble_state_ser\n\n>      assemble_state_ser (state_columns:pandas.core.frame.DataFrame,\n>                          tz:zoneinfo.ZoneInfo)\n\nassemble state df from state_columns dataframe order is vital for the model\n\ninputs:\n\n    state_columns: pd.DataFrame\n\n\"timestep, velocity, thrust, brake\"\ncontiguous storage in each measurement\ndue to sort_index, output:\n[col0: brake, col1: thrust, col2: timestep, col3: velocity]\n\nreturn:\n\n    state: pd.Series\n    table_row_start: int\n\n|    | **Type** | **Details** |\n| -- | -------- | ----------- |\n| state_columns | DataFrame | state_columns: Dataframe with columns ['timestep', 'velocity', 'thrust', 'brake'] |\n| tz | ZoneInfo | timezone for the timestamp |\n| **Returns** | **Tuple** |  |"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(assemble_state_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5e526835d7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| hide\n",
    "from data_io_nbdev.utils import generate_eos_df, generate_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c04c99938da6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>rows</th>\n      <th colspan=\"4\" halign=\"left\">brake</th>\n      <th colspan=\"4\" halign=\"left\">thrust</th>\n      <th colspan=\"4\" halign=\"left\">timestep</th>\n      <th colspan=\"4\" halign=\"left\">velocity</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>idx</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n    <tr>\n      <th>vehicle</th>\n      <th>driver</th>\n      <th>episodestart</th>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">VB7</th>\n      <th rowspan=\"5\" valign=\"top\">wang-cheng</th>\n      <th rowspan=\"5\" valign=\"top\">2023-12-14 10:04:17.821022</th>\n      <th>2023-12-14 11:04:17.793151</th>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>2023-12-14 10:04:17.793469</td>\n      <td>2023-12-14 10:04:17.813469</td>\n      <td>2023-12-14 10:04:17.833469</td>\n      <td>2023-12-14 10:04:17.853469</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2023-12-14 12:04:17.793151</th>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>2023-12-14 10:04:17.793469</td>\n      <td>2023-12-14 10:04:17.813469</td>\n      <td>2023-12-14 10:04:17.833469</td>\n      <td>2023-12-14 10:04:17.853469</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2023-12-14 13:04:17.793151</th>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>2023-12-14 10:04:17.793469</td>\n      <td>2023-12-14 10:04:17.813469</td>\n      <td>2023-12-14 10:04:17.833469</td>\n      <td>2023-12-14 10:04:17.853469</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2023-12-14 14:04:17.793151</th>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>2023-12-14 10:04:17.793469</td>\n      <td>2023-12-14 10:04:17.813469</td>\n      <td>2023-12-14 10:04:17.833469</td>\n      <td>2023-12-14 10:04:17.853469</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2023-12-14 15:04:17.793151</th>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>2023-12-14 10:04:17.793469</td>\n      <td>2023-12-14 10:04:17.813469</td>\n      <td>2023-12-14 10:04:17.833469</td>\n      <td>2023-12-14 10:04:17.853469</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "rows                                                                     brake  \\\nidx                                                                          0   \nvehicle driver     episodestart               timestamp                          \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151   8.0   \n                                              2023-12-14 12:04:17.793151   8.0   \n                                              2023-12-14 13:04:17.793151   8.0   \n                                              2023-12-14 14:04:17.793151   8.0   \n                                              2023-12-14 15:04:17.793151   8.0   \n\nrows                                                                           \\\nidx                                                                         1   \nvehicle driver     episodestart               timestamp                         \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  9.0   \n                                              2023-12-14 12:04:17.793151  9.0   \n                                              2023-12-14 13:04:17.793151  9.0   \n                                              2023-12-14 14:04:17.793151  9.0   \n                                              2023-12-14 15:04:17.793151  9.0   \n\nrows                                                                            \\\nidx                                                                          2   \nvehicle driver     episodestart               timestamp                          \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  10.0   \n                                              2023-12-14 12:04:17.793151  10.0   \n                                              2023-12-14 13:04:17.793151  10.0   \n                                              2023-12-14 14:04:17.793151  10.0   \n                                              2023-12-14 15:04:17.793151  10.0   \n\nrows                                                                            \\\nidx                                                                          3   \nvehicle driver     episodestart               timestamp                          \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  11.0   \n                                              2023-12-14 12:04:17.793151  11.0   \n                                              2023-12-14 13:04:17.793151  11.0   \n                                              2023-12-14 14:04:17.793151  11.0   \n                                              2023-12-14 15:04:17.793151  11.0   \n\nrows                                                                     thrust  \\\nidx                                                                           0   \nvehicle driver     episodestart               timestamp                           \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151    4.0   \n                                              2023-12-14 12:04:17.793151    4.0   \n                                              2023-12-14 13:04:17.793151    4.0   \n                                              2023-12-14 14:04:17.793151    4.0   \n                                              2023-12-14 15:04:17.793151    4.0   \n\nrows                                                                           \\\nidx                                                                         1   \nvehicle driver     episodestart               timestamp                         \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  5.0   \n                                              2023-12-14 12:04:17.793151  5.0   \n                                              2023-12-14 13:04:17.793151  5.0   \n                                              2023-12-14 14:04:17.793151  5.0   \n                                              2023-12-14 15:04:17.793151  5.0   \n\nrows                                                                           \\\nidx                                                                         2   \nvehicle driver     episodestart               timestamp                         \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  6.0   \n                                              2023-12-14 12:04:17.793151  6.0   \n                                              2023-12-14 13:04:17.793151  6.0   \n                                              2023-12-14 14:04:17.793151  6.0   \n                                              2023-12-14 15:04:17.793151  6.0   \n\nrows                                                                           \\\nidx                                                                         3   \nvehicle driver     episodestart               timestamp                         \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  7.0   \n                                              2023-12-14 12:04:17.793151  7.0   \n                                              2023-12-14 13:04:17.793151  7.0   \n                                              2023-12-14 14:04:17.793151  7.0   \n                                              2023-12-14 15:04:17.793151  7.0   \n\nrows                                                                                        timestep  \\\nidx                                                                                                0   \nvehicle driver     episodestart               timestamp                                                \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  2023-12-14 10:04:17.793469   \n                                              2023-12-14 12:04:17.793151  2023-12-14 10:04:17.793469   \n                                              2023-12-14 13:04:17.793151  2023-12-14 10:04:17.793469   \n                                              2023-12-14 14:04:17.793151  2023-12-14 10:04:17.793469   \n                                              2023-12-14 15:04:17.793151  2023-12-14 10:04:17.793469   \n\nrows                                                                                                  \\\nidx                                                                                                1   \nvehicle driver     episodestart               timestamp                                                \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  2023-12-14 10:04:17.813469   \n                                              2023-12-14 12:04:17.793151  2023-12-14 10:04:17.813469   \n                                              2023-12-14 13:04:17.793151  2023-12-14 10:04:17.813469   \n                                              2023-12-14 14:04:17.793151  2023-12-14 10:04:17.813469   \n                                              2023-12-14 15:04:17.793151  2023-12-14 10:04:17.813469   \n\nrows                                                                                                  \\\nidx                                                                                                2   \nvehicle driver     episodestart               timestamp                                                \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  2023-12-14 10:04:17.833469   \n                                              2023-12-14 12:04:17.793151  2023-12-14 10:04:17.833469   \n                                              2023-12-14 13:04:17.793151  2023-12-14 10:04:17.833469   \n                                              2023-12-14 14:04:17.793151  2023-12-14 10:04:17.833469   \n                                              2023-12-14 15:04:17.793151  2023-12-14 10:04:17.833469   \n\nrows                                                                                                  \\\nidx                                                                                                3   \nvehicle driver     episodestart               timestamp                                                \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  2023-12-14 10:04:17.853469   \n                                              2023-12-14 12:04:17.793151  2023-12-14 10:04:17.853469   \n                                              2023-12-14 13:04:17.793151  2023-12-14 10:04:17.853469   \n                                              2023-12-14 14:04:17.793151  2023-12-14 10:04:17.853469   \n                                              2023-12-14 15:04:17.793151  2023-12-14 10:04:17.853469   \n\nrows                                                                     velocity  \\\nidx                                                                             0   \nvehicle driver     episodestart               timestamp                             \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151      0.0   \n                                              2023-12-14 12:04:17.793151      0.0   \n                                              2023-12-14 13:04:17.793151      0.0   \n                                              2023-12-14 14:04:17.793151      0.0   \n                                              2023-12-14 15:04:17.793151      0.0   \n\nrows                                                                           \\\nidx                                                                         1   \nvehicle driver     episodestart               timestamp                         \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  1.0   \n                                              2023-12-14 12:04:17.793151  1.0   \n                                              2023-12-14 13:04:17.793151  1.0   \n                                              2023-12-14 14:04:17.793151  1.0   \n                                              2023-12-14 15:04:17.793151  1.0   \n\nrows                                                                           \\\nidx                                                                         2   \nvehicle driver     episodestart               timestamp                         \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  2.0   \n                                              2023-12-14 12:04:17.793151  2.0   \n                                              2023-12-14 13:04:17.793151  2.0   \n                                              2023-12-14 14:04:17.793151  2.0   \n                                              2023-12-14 15:04:17.793151  2.0   \n\nrows                                                                           \nidx                                                                         3  \nvehicle driver     episodestart               timestamp                        \nVB7     wang-cheng 2023-12-14 10:04:17.821022 2023-12-14 11:04:17.793151  3.0  \n                                              2023-12-14 12:04:17.793151  3.0  \n                                              2023-12-14 13:04:17.793151  3.0  \n                                              2023-12-14 14:04:17.793151  3.0  \n                                              2023-12-14 15:04:17.793151  3.0  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "df = generate_eos_df()\n",
    "df[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473448cf0698d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestep</th>\n      <th>velocity</th>\n      <th>thrust</th>\n      <th>brake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-12-14T10:04:17.793469000</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-12-14T10:04:17.813469000</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-12-14T10:04:17.833469000</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-12-14T10:04:17.853469000</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        timestep velocity thrust brake\n0  2023-12-14T10:04:17.793469000      0.0    4.0   8.0\n1  2023-12-14T10:04:17.813469000      1.0    5.0   9.0\n2  2023-12-14T10:04:17.833469000      2.0    6.0  10.0\n3  2023-12-14T10:04:17.853469000      3.0    7.0  11.0"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "state = df['state'][[\"timestep\", \"velocity\", \"thrust\", \"brake\"]].iloc[0]\n",
    "# state = df['state'][\"timestep\"]\n",
    "# state[\"timestep\"].values\n",
    "state = pd.DataFrame(\n",
    "    [state[\"timestep\"].values, state[\"velocity\"].values, state[\"thrust\"].values, state[\"brake\"].values]).T\n",
    "state.columns = [\"timestep\", \"velocity\", \"thrust\", \"brake\"]\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea670600d116dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "rows      idx\nbrake     0                                8.0\n          1                                9.0\n          2                               10.0\n          3                               11.0\nthrust    0                                4.0\n          1                                5.0\n          2                                6.0\n          3                                7.0\ntimestep  0      2023-12-14T10:04:17.793469000\n          1      2023-12-14T10:04:17.813469000\n          2      2023-12-14T10:04:17.833469000\n          3      2023-12-14T10:04:17.853469000\nvelocity  0                                0.0\n          1                                1.0\n          2                                2.0\n          3                                3.0\nName: state, dtype: object"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "state_ser = state.stack().swaplevel(0, 1)\n",
    "state_ser.name = \"state\"\n",
    "state_ser.index.names = [\"rows\", \"idx\"]\n",
    "state_ser.sort_index(inplace=True)\n",
    "state_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1adc5d02bf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tz = ZoneInfo(\"Asia/Shanghai\")\n",
    "# state = df['state'].stack\n",
    "ser_state, row_start = assemble_state_ser(state, tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266489f5beb75eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "rows      idx\nbrake     0                                8.0\n          1                                9.0\n          2                               10.0\n          3                               11.0\nthrust    0                                4.0\n          1                                5.0\n          2                                6.0\n          3                                7.0\ntimestep  0      2023-12-14T10:04:17.793469000\n          1      2023-12-14T10:04:17.813469000\n          2      2023-12-14T10:04:17.833469000\n          3      2023-12-14T10:04:17.853469000\nvelocity  0                                0.0\n          1                                1.0\n          2                                2.0\n          3                                3.0\nName: state, dtype: object"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output: true\n",
    "assemble_state_ser(state, tz)[0]  # just showd the Dataframe, ignore row_start (its's 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac750cb897f35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert assemble_state_ser(state, tz)[1] == 0  # row_start should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eac8455ba36abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(assemble_state_ser(state, tz)[0], pd.Series) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed3e33de79fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf20a314185ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(isinstance(assemble_state_ser(state, tz)[0], pd.Series), True)  # use fastcore testing utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assemble_reward_ser(\n",
    "    power_columns: pd.DataFrame, obs_sampling_rate: int, ts\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    assemble reward df from motion_power df\n",
    "    order is vital for the model:\n",
    "    contiguous storage in each row, due to sort_index, output:\n",
    "    power_columns: ['current', 'voltage']\n",
    "    [timestep, work]\n",
    "    \"\"\"\n",
    "\n",
    "    ui_sum = power_columns.prod(axis=1).sum()\n",
    "    wh = (\n",
    "        ui_sum / 3600.0 / obs_sampling_rate\n",
    "    )  # rate 0.05 for kvaser, 0.02 remote # negative wh\n",
    "    work = wh * (-1.0)\n",
    "    reward: pd.Series = cast(\n",
    "        pd.Series,\n",
    "        (\n",
    "            pd.DataFrame({\"work\": work, \"timestep\": ts}, index=[0])\n",
    "            .stack()\n",
    "            .swaplevel(0, 1)\n",
    "            .sort_index()  # columns oder (timestep, work)\n",
    "        ),\n",
    "    )\n",
    "    reward.name = \"reward\"\n",
    "    reward.index.names = [\"rows\", \"idx\"]\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c594c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assemble_flash_table(\n",
    "    torque_map_line: np.ndarray,\n",
    "    table_start: int,\n",
    "    torque_table_row_num_flash: int,\n",
    "    torque_table_col_num: int,\n",
    "    speed_scale: tuple,\n",
    "    pedal_scale: tuple,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    generate flash table df from torque_map_line\n",
    "    order is vital for the model:\n",
    "    contiguous storage in each row, due to sort_index, output:\n",
    "    \"r0, r1, r2, r3, ..., speed, throttle(map),timestep\"\n",
    "    \"\"\"\n",
    "    # assemble_action_df\n",
    "\n",
    "    speed_ser = pd.Series(\n",
    "        speed_scale[table_start : table_start + torque_table_row_num_flash],\n",
    "        name=\"speed\",\n",
    "    )\n",
    "    throttle_ser = pd.Series(pedal_scale, name=\"throttle\")\n",
    "    torque_table = np.reshape(\n",
    "        torque_map_line,\n",
    "        [torque_table_row_num_flash, torque_table_col_num],\n",
    "    )\n",
    "    df_torque_table = pd.DataFrame(torque_table)  # not transpose!\n",
    "    df_torque_table.index = speed_ser\n",
    "    df_torque_table.columns = throttle_ser\n",
    "\n",
    "    return df_torque_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc157348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assemble_action_ser(\n",
    "    torque_map_line: np.ndarray,\n",
    "    torque_table_row_names: list[str],\n",
    "    table_start: int,\n",
    "    flash_start_ts: pd.Timestamp,\n",
    "    flash_end_ts: pd.Timestamp,\n",
    "    torque_table_row_num_flash: int,\n",
    "    torque_table_col_num: int,\n",
    "    speed_scale: tuple,\n",
    "    pedal_scale: tuple,\n",
    "    tz: ZoneInfo,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    generate action df from torque_map_line\n",
    "    order is vital for the model:\n",
    "    contiguous storage in each row, due to sort_index, output:\n",
    "    \"r0, r1, r2, r3, ..., speed, throttle(map),timestep\"\n",
    "    \"\"\"\n",
    "    # assemble_action_df\n",
    "    row_num = torque_table_row_num_flash\n",
    "\n",
    "    speed_ser = pd.Series(\n",
    "        speed_scale[table_start : table_start + torque_table_row_num_flash],\n",
    "        name=\"speed\",\n",
    "    )\n",
    "    throttle_ser = pd.Series(pedal_scale, name=\"throttle\")\n",
    "    torque_map = np.reshape(\n",
    "        torque_map_line,\n",
    "        [torque_table_row_num_flash, torque_table_col_num],\n",
    "    )\n",
    "    df_torque_map = pd.DataFrame(torque_map).transpose()  # row to columns\n",
    "    df_torque_map.columns = pd.Index(torque_table_row_names)  # index: [r0, r1, ...]\n",
    "    # df_torque_map.index = throttle_ser  # torque map index: if using [throttle], the index dtypes will become float!\n",
    "\n",
    "    span_each_row = (flash_end_ts - flash_start_ts) / row_num\n",
    "    flash_timestamps_ser = pd.Series(\n",
    "        [\n",
    "            pd.to_datetime(flash_start_ts + step * span_each_row, unit=\"us\").tz_convert(\n",
    "                tz\n",
    "            )\n",
    "            for step in np.linspace(1, row_num, row_num)\n",
    "        ],\n",
    "        name=\"timestep\",\n",
    "    )\n",
    "\n",
    "    dfs: list[Union[pd.DataFrame, pd.Series]] = [\n",
    "        df_torque_map,\n",
    "        flash_timestamps_ser,\n",
    "        speed_ser,\n",
    "        throttle_ser,\n",
    "    ]\n",
    "    action_df: pd.DataFrame = cast(\n",
    "        pd.DataFrame,\n",
    "        reduce(\n",
    "            lambda left, right: pd.merge(\n",
    "                left,\n",
    "                right,\n",
    "                how=\"outer\",\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "            ),\n",
    "            dfs,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    action = cast(\n",
    "        pd.Series, (action_df.stack().swaplevel(0, 1).sort_index())\n",
    "    )  # columns order (r0, r1, ..., speed, throttle, timestep)\n",
    "    action.name = \"action\"\n",
    "    action.index.names = [\"rows\", \"idx\"]\n",
    "    # action.column.names = []\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77fe250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nest(d: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a flat dictionary with tuple key to a nested dictionary through to the leaves\n",
    "    arrays will be converted to dictionaries with the index as the key\n",
    "    no conversion of pd.Timestamp\n",
    "    only for use in mongo records\n",
    "    \"\"\"\n",
    "    result: Dict = {}\n",
    "    for key, value in d.items():\n",
    "        target = result\n",
    "        for k in key[:-1]:\n",
    "            target = target.setdefault(k, {})\n",
    "        target[str(key[-1])] = value  # for mongo only string keys are allowed.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ffebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def df_to_nested_dict(df_multi_indexed_col: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a dataframe with multi-indexed columns to a nested dictionary\n",
    "    \"\"\"\n",
    "    d = df_multi_indexed_col.to_dict(\n",
    "        \"index\"\n",
    "    )  # for multi-indexed dataframe, the index in the first level of the dictionary is still a tuple!\n",
    "    return {k: nest(v) for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ee7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def eos_df_to_nested_dict(episode: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Convert an eos dataframe with multi-indexed columns to a nested dictionary\n",
    "    Remove all the levels of the multi-indexed columns except for 'timestamp'\n",
    "    Keep only the timestamp as the single key for the nested dictionary\n",
    "    \"\"\"\n",
    "    dict_nested = df_to_nested_dict(\n",
    "        episode\n",
    "    )  # for multi-indexed dataframe, the index in the first level of the dictionary is still a tuple!\n",
    "    indices_dict = [\n",
    "        {episode.index.names[i]: level for i, level in enumerate(levels)}\n",
    "        for levels in episode.index\n",
    "    ]  # all elements in the array should have the same vehicle, driver, episodestart\n",
    "    single_key_dict = {\n",
    "        idx[\"timestamp\"]: dict_nested[key]\n",
    "        for idx, key in zip(indices_dict, dict_nested)\n",
    "    }\n",
    "\n",
    "    return single_key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ep_nest(d: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Convert a flat dictionary with tuple key to a nested dictionary with arrays at the leaves\n",
    "    convert pd.Timestamp to millisecond long integer\n",
    "    Timestamp with zoneinfo will be converted to UTC and then to millisecond long integer\n",
    "    \"\"\"\n",
    "    result: Dict = {}\n",
    "    for key, value in d.items():\n",
    "        target = result\n",
    "        for k in key[:-2]:\n",
    "            target = target.setdefault(k, {})\n",
    "        if key[-2] not in target:\n",
    "            target[key[-2]] = []\n",
    "\n",
    "        if isinstance(value, pd.Timestamp):\n",
    "            value = value.timestamp() * 1e6  # convert to microsecond long integer,\n",
    "        target[key[-2]].append(value)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f17eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def df_to_ep_nested_dict(df_multi_indexed_col: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a dataframe with multi-indexed columns to a nested dictionary\n",
    "    \"\"\"\n",
    "    d = df_multi_indexed_col.to_dict(\n",
    "        \"index\"\n",
    "    )  # for multi-indexed dataframe, the index in the first level of the dictionary is still a tuple!\n",
    "    return {k: ep_nest(v) for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def avro_ep_encoding(episode: pd.DataFrame) -> list[Dict]:\n",
    "    \"\"\"\n",
    "    avro encoding,\n",
    "    parsing requires a schema defined in \"data_io/pool/episode_avro_schema.py\"\n",
    "\n",
    "    Convert an eos dataframe with multi-indexed columns to a nested dictionary\n",
    "    Remove all the levels of the multi-indexed columns except for 'timestamp'\n",
    "    Keep only the timestamp as the single key for the nested dictionary\n",
    "    ! Convert Timestamp to millisecond long integer!! for compliance to the  avro storage format\n",
    "    ! Timestamp with ZoneInfo will be converted to UTC and then to millisecond long integer\n",
    "    as flat as possible\n",
    "    PEP20: flat is better than nested!\n",
    "    \"\"\"\n",
    "    dict_nested = df_to_ep_nested_dict(\n",
    "        episode\n",
    "    )  # for multi-indexed dataframe, the index in the first level of the dictionary is still a tuple!\n",
    "    indices_dict = [\n",
    "        {episode.index.names[i]: level for i, level in enumerate(levels)}\n",
    "        for levels in episode.index\n",
    "    ]  # all elements in the array should have the same vehicle, driver, episodestart\n",
    "    array_of_dict = [\n",
    "        {\n",
    "            \"timestamp\": idx[\n",
    "                \"timestamp\"\n",
    "            ].timestamp()  # Timestamp with ZoneInfo will be converted to UTC\n",
    "            * 1e6,  # convert to microsecond long integer\n",
    "            **dict_nested[\n",
    "                key\n",
    "            ],  # merge the nested dict with the timestamp, as flat as possible\n",
    "        }\n",
    "        for (idx, key) in zip(indices_dict, dict_nested)\n",
    "    ]\n",
    "\n",
    "    return array_of_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93025395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def avro_ep_decoding(episodes: list[Dict], tz_info: Optional[ZoneInfo]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    avro decoding,\n",
    "\n",
    "    Convert a list of nested dictionaries to DataFrame with multi-indexed columns and index\n",
    "    ! Convert microsecond long integer to Timestamp!\n",
    "    (avro storage format stores timestamp as long integer in keys but\n",
    "    seem to have DateTime with timezone in the values.)\n",
    "\n",
    "    Apache Avro store datetime/timestamp as timezone unaware (default as UTC)\n",
    "    Therefore, we need tz info either in the metadata or elsewhere to designate the timezone\n",
    "\n",
    "    sort the column order\n",
    "    \"\"\"\n",
    "\n",
    "    batch = []\n",
    "    for ep in episodes:\n",
    "        dict_observations = [\n",
    "            {\n",
    "                (\n",
    "                    ep[\"meta\"][\"episode_meta\"][\"vehicle\"],\n",
    "                    ep[\"meta\"][\"episode_meta\"][\"driver\"],\n",
    "                    pd.to_datetime(\n",
    "                        ep[\"meta\"][\"episode_meta\"][\"episodestart\"], unit=\"us\", utc=True\n",
    "                    ).tz_convert(tz_info),\n",
    "                    pd.to_datetime(step[\"timestamp\"], unit=\"us\", utc=True).tz_convert(\n",
    "                        tz_info\n",
    "                    ),\n",
    "                    qtuple,\n",
    "                    rows,\n",
    "                    idx,\n",
    "                ): item\n",
    "                if rows != \"timestep\"\n",
    "                else pd.to_datetime(item, utc=True).tz_convert(tz_info)\n",
    "                for qtuple, obs in step.items()\n",
    "                if qtuple\n",
    "                != \"timestamp\"  # \"timestamp\" is not a real valid qtuple, although it is in this level\n",
    "                for rows, value in obs.items()  # but mixed in during avro encoding for storing\n",
    "                for idx, item in enumerate(value)\n",
    "            }\n",
    "            for step in ep[\"sequence\"]\n",
    "        ]\n",
    "\n",
    "        dict_ep = {k: v for d in dict_observations for k, v in d.items()}\n",
    "\n",
    "        ser_decoded = pd.Series(dict_ep)\n",
    "        ser_decoded.index.names = [\n",
    "            \"vehicle\",\n",
    "            \"driver\",\n",
    "            \"episodestart\",\n",
    "            \"timestamp\",\n",
    "            \"qtuple\",\n",
    "            \"rows\",\n",
    "            \"idx\",\n",
    "        ]\n",
    "        df_decoded = ser_decoded.unstack(level=[\"qtuple\", \"rows\", \"idx\"])  # type: ignore\n",
    "        df_decoded.sort_index(inplace=True, axis=1)  # sort the column order\n",
    "        batch.append(df_decoded)\n",
    "\n",
    "    index_names = batch[0].index.names\n",
    "    df_episodes = pd.concat(\n",
    "        batch, keys=range(len(batch)), names=[\"batch\"] + index_names\n",
    "    )\n",
    "\n",
    "    return df_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b574ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decode_mongo_records(\n",
    "    df: pd.DataFrame,\n",
    "    torque_table_row_names: list[str],\n",
    ") -> tuple[\n",
    "    list[pd.DataFrame], list[pd.DataFrame], list[pd.DataFrame], list[pd.DataFrame]\n",
    "]:\n",
    "    \"\"\"\n",
    "    decoding the batch RECORD observations from mongodb nested dicts to pandas dataframe\n",
    "    (EPISODE doesn't need decoding, it is already a dataframe)\n",
    "    TODO need to check whether sort_index is necessary\n",
    "    \"\"\"\n",
    "\n",
    "    dict_observations_list = (\n",
    "        [  # list of observations as dict with tuple key suitable as MultiIndex\n",
    "            {\n",
    "                (\n",
    "                    meta[\"episodestart\"],\n",
    "                    meta[\"vehicle\"],\n",
    "                    meta[\"driver\"],\n",
    "                    meta[\"timestamp\"],\n",
    "                    qtuple,\n",
    "                    rows,\n",
    "                    idx,\n",
    "                ): value\n",
    "                for qtuple, obs1 in obs.items()\n",
    "                for rows, obs2 in obs1.items()\n",
    "                for idx, value in obs2.items()\n",
    "            }\n",
    "            for meta, obs in zip(df[\"meta\"], df[\"observation\"])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_actions = []\n",
    "    df_states = []\n",
    "    df_nstates = []\n",
    "    ser_rewards = []\n",
    "    idx = pd.IndexSlice\n",
    "    for dict_observations in dict_observations_list:  # decode each measurement from\n",
    "        ser_decoded = pd.Series(dict_observations)\n",
    "        ser_decoded.index.names = [\n",
    "            \"episodestart\",\n",
    "            \"vehicle\",\n",
    "            \"driver\",\n",
    "            \"timestamp\",\n",
    "            \"qtuple\",\n",
    "            \"rows\",\n",
    "            \"idx\",\n",
    "        ]\n",
    "\n",
    "        # decode state\n",
    "        ser_state = ser_decoded.loc[\n",
    "            idx[:, :, :, :, \"state\", [\"brake\", \"thrust\", \"velocity\", \"timestep\"]]\n",
    "        ]\n",
    "        df_state = ser_state.unstack(level=[0, 1, 2, 3, 4, 5])  # type: ignore\n",
    "        multiindex = df_state.columns\n",
    "        df_state.set_index(multiindex[-1], inplace=True)  # last index has timestep\n",
    "        df_states.append(df_state)\n",
    "\n",
    "        # decode action\n",
    "        ser_action = ser_decoded.loc[\n",
    "            idx[:, :, :, :, \"action\", [*torque_table_row_names, \"throttle\"]]\n",
    "        ]\n",
    "        df_action = ser_action.unstack(level=[0, 1, 2, 3, 4, 5])  # type: ignore\n",
    "        multiindex = df_action.columns\n",
    "        df_action.set_index(multiindex[-1], inplace=True)  # last index has throttle\n",
    "\n",
    "        action_timestep = ser_decoded.loc[idx[:, :, :, :, \"action\", \"timestep\"]]\n",
    "        action_speed = ser_decoded.loc[idx[:, :, :, :, \"action\", \"speed\"]]\n",
    "        action_multi_col = [\n",
    "            (*column, speed, timestep)  # swap speed and timestep\n",
    "            for column, timestep, speed in zip(df_action.columns, action_timestep, action_speed)  # type: ignore\n",
    "        ]\n",
    "        df_action.columns = pd.MultiIndex.from_tuples(\n",
    "            action_multi_col,\n",
    "            names=[\n",
    "                \"episodestart\",\n",
    "                \"vehicle\",\n",
    "                \"driver\",\n",
    "                \"timestamp\",\n",
    "                \"qtuple\",\n",
    "                \"rows\",\n",
    "                \"speed\",\n",
    "                \"timestep\",\n",
    "            ],\n",
    "        )\n",
    "        df_actions.append(df_action)\n",
    "\n",
    "        # decode reward\n",
    "        ser_reward = ser_decoded.loc[idx[:, :, :, :, \"reward\", [\"work\", \"timestep\"]]]\n",
    "        df_reward = ser_reward.unstack([0, 1, 2, 3, 4, 5])  # type: ignore\n",
    "        multiindex = df_reward.columns\n",
    "        df_reward.set_index(multiindex[-1], inplace=True)  # last index has timestep\n",
    "        # df_reward\n",
    "        ser_rewards.append(df_reward)\n",
    "\n",
    "        # decode nstate\n",
    "        ser_nstate = ser_decoded.loc[\n",
    "            idx[:, :, :, :, \"nstate\", [\"brake\", \"thrust\", \"velocity\", \"timestep\"]]\n",
    "        ]\n",
    "        df_nstate = ser_nstate.unstack([0, 1, 2, 3, 4, 5])  # type: ignore\n",
    "        multiindex = df_nstate.columns\n",
    "        df_nstate.set_index(multiindex[-1], inplace=True)\n",
    "        df_nstates.append(df_nstate)\n",
    "\n",
    "    return df_states, df_actions, ser_rewards, df_nstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decode_mongo_episodes(\n",
    "    df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    decoding the batch RECORD observations from mongodb nested dicts to pandas dataframe\n",
    "    (EPISODE doesn't need decoding, it is already a dataframe)\n",
    "    TODO need to check whether sort_index is necessary\"\"\"\n",
    "    dict_observations = [\n",
    "        {\n",
    "            (\n",
    "                meta[\"vehicle\"],\n",
    "                meta[\"driver\"],\n",
    "                meta[\"episodestart\"],\n",
    "                timestamp,\n",
    "                qtuple,\n",
    "                rows,\n",
    "                idx,\n",
    "            ): value\n",
    "            for timestamp, obs1 in obs.items()\n",
    "            for qtuple, obs2 in obs1.items()  # (state, action, reward, next_state)\n",
    "            for rows, obs3 in obs2.items()  # (velocity, thrust, brake), (r0, r1, r2, ...),\n",
    "            for idx, value in obs3.items()  # (0, 1, 2, ...)\n",
    "        }\n",
    "        for meta, obs in zip(df[\"meta\"], df[\"observation\"])\n",
    "    ]\n",
    "\n",
    "    batch = []\n",
    "    for dict_obs in dict_observations:\n",
    "        ser_decoded = pd.Series(dict_obs)\n",
    "        ser_decoded.index.names = [\n",
    "            \"vehicle\",\n",
    "            \"driver\",\n",
    "            \"episodestart\",\n",
    "            \"timestamp\",\n",
    "            \"qtuple\",\n",
    "            \"rows\",\n",
    "            \"idx\",\n",
    "        ]\n",
    "        df_decoded = ser_decoded.unstack(level=[\"qtuple\", \"rows\", \"idx\"])  # type: ignore\n",
    "        df_decoded.sort_index(inplace=True, axis=1)\n",
    "        batch.append(df_decoded)  # qtuple, rows, index\n",
    "\n",
    "    # batch.sort_index(inplace=True, axis=0)\n",
    "    # must not sort_index, otherwise the order of the columns will be changed, if there were duplicated episodes\n",
    "    index_names = batch[0].index.names\n",
    "    df_episodes = pd.concat(\n",
    "        batch, keys=range(len(batch)), names=[\"batch\"] + index_names\n",
    "    )\n",
    "    return df_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode_dataframe_from_parquet(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    decode the dataframe from parquet with flat column indices to MultiIndexed DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    multi_tpl = [tuple(col.split(\"_\")) for col in df.columns]\n",
    "    multi_col = pd.MultiIndex.from_tuples(multi_tpl)\n",
    "    i1 = multi_col.get_level_values(0)\n",
    "    i1 = pd.Index(\n",
    "        [\"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i1]\n",
    "    )  # convert index of level 2 type to int and '' if NA\n",
    "    i2 = multi_col.get_level_values(\n",
    "        1\n",
    "    )  # must be null string instead of the default pd.NA or np.nan\n",
    "    i2 = pd.Index(\n",
    "        [\"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else idx for idx in i2]\n",
    "    )  # convert index of level 2 type to int and '' if NA\n",
    "    i3 = multi_col.get_level_values(\n",
    "        2\n",
    "    )  # must be null string instead of the default pd.NA or np.nan\n",
    "    i3 = pd.Index(\n",
    "        [\"\" if str(idx) in (str(pd.NA), \"nan\", \"\") else int(idx) for idx in i3]\n",
    "    )  # convert index of level 2 type to int and '' if NA\n",
    "\n",
    "    multi_col = pd.MultiIndex.from_arrays([i1, i2, i3])\n",
    "    multi_col.names = [\"qtuple\", \"rows\", \"idx\"]\n",
    "    df.columns = multi_col\n",
    "\n",
    "    df = df.set_index([\"vehicle\", \"driver\", \"episodestart\", df.index])  # type: ignore\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6114f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decode_episode_batch_to_padded_arrays(\n",
    "    episodes: pd.DataFrame,\n",
    "    torque_table_row_names: list[str],\n",
    "    padding_value: float = -10000.0,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    decode the dataframes to 3D numpy arrays [B, T, F] for states, actions, rewards, next_states\n",
    "    episodes with variable lengths will turn into ragged arrays with the same raggedness, thus the same maximum length\n",
    "    after padding the arrays will have the same shape and padding pattern.\n",
    "\n",
    "    episodes are not sorted and its internal index keeps the index order of the original episodes, not interleaved!\n",
    "    idx_len_list: list of lengths of each episode in the batch, use explicit segmentation to avoid the bug,\n",
    "    when the batch has duplicated episodes\n",
    "    \"\"\"\n",
    "\n",
    "    # episodestart_index = episodes.index.unique(level='episode_start')\n",
    "    # episodes.sort_index(inplace=False, axis=0).sort_index(inplace=True, axis=1)\n",
    "    # array of rewards for minibatch\n",
    "    # for ep in batch:\n",
    "    #     ep.sort_index(inplace=True, axis=1)\n",
    "    idx = pd.IndexSlice\n",
    "    rewards_list = [\n",
    "        episodes.loc[idx[i, :, :, :, :], idx[\"reward\", \"work\"]].values.tolist()  # type: ignore\n",
    "        for i in episodes.index.get_level_values(0)\n",
    "    ]  # type: ignore\n",
    "    r_n_t = tf.keras.utils.pad_sequences(\n",
    "        rewards_list, padding=\"post\", dtype=np.float32, value=padding_value\n",
    "    )\n",
    "\n",
    "    # array of states for minibatch\n",
    "    states_list = [\n",
    "        episodes.loc[idx[i, :, :, :, :], idx[\"state\", [\"velocity\", \"thrust\", \"brake\"]]].values.tolist()  # type: ignore\n",
    "        for i in episodes.index.get_level_values(0)\n",
    "    ]  # type: ignore\n",
    "    s_n_t = tf.keras.utils.pad_sequences(\n",
    "        states_list, padding=\"post\", dtype=np.float32, value=padding_value\n",
    "    )\n",
    "\n",
    "    # array of actions for minibatch\n",
    "    actions_list = [\n",
    "        episodes.loc[idx[i, :, :, :, :], idx[\"action\", torque_table_row_names]].values.tolist()  # type: ignore\n",
    "        for i in episodes.index.get_level_values(0)\n",
    "    ]  # type: ignore\n",
    "    a_n_t = tf.keras.utils.pad_sequences(\n",
    "        actions_list, padding=\"post\", dtype=np.float32, value=padding_value\n",
    "    )\n",
    "\n",
    "    # array of next_states for minibatch\n",
    "    nstates_list = [\n",
    "        episodes.loc[idx[i, :, :, :, :], idx[\"nstate\", [\"velocity\", \"thrust\", \"brake\"]]].values.tolist()  # type: ignore\n",
    "        for i in episodes.index.get_level_values(0)\n",
    "    ]  # type: ignore\n",
    "    ns_n_t = tf.keras.utils.pad_sequences(\n",
    "        nstates_list, padding=\"post\", dtype=np.float32, value=padding_value\n",
    "    )\n",
    "\n",
    "    return s_n_t, a_n_t, r_n_t, ns_n_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa72a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def encode_episode_dataframe_from_series(\n",
    "    observations: List[pd.Series],\n",
    "    torque_table_row_names: List[str],\n",
    "    episode_start_dt: datetime,\n",
    "    driver_str: str,\n",
    "    truck_str: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    encode the list of observations as a dataframe with multi-indexed columns\n",
    "    \"\"\"\n",
    "    episode = pd.concat(\n",
    "        observations, axis=1\n",
    "    ).transpose()  # concat along columns and transpose to DataFrame, columns not sorted as (s,a,r,s')\n",
    "    episode.columns.names = [\"tuple\", \"rows\", \"idx\"]\n",
    "    episode.set_index((\"timestamp\", \"\", 0), append=False, inplace=True)\n",
    "    episode.index.name = \"timestamp\"\n",
    "    episode.sort_index(axis=1, inplace=True)\n",
    "\n",
    "    # convert columns types to float where necessary\n",
    "    state_cols_float = [(\"state\", col) for col in [\"brake\", \"thrust\", \"velocity\"]]\n",
    "    action_cols_float = [\n",
    "        (\"action\", col) for col in [*torque_table_row_names, \"speed\", \"throttle\"]\n",
    "    ]\n",
    "    reward_cols_float = [(\"reward\", \"work\")]\n",
    "    nstate_cols_float = [(\"nstate\", col) for col in [\"brake\", \"thrust\", \"velocity\"]]\n",
    "    for col in (\n",
    "        action_cols_float + state_cols_float + reward_cols_float + nstate_cols_float\n",
    "    ):\n",
    "        episode[col[0], col[1]] = episode[col[0], col[1]].astype(\n",
    "            \"float\"\n",
    "        )  # float16 not allowed in parquet\n",
    "\n",
    "    # Create MultiIndex ('vehicle', 'driver', 'episodestart', 'timestamp')\n",
    "    ## Append index for the episode, in the order 'vehicle', 'driver', 'episodestart'\n",
    "    episode = pd.concat(\n",
    "        [episode],\n",
    "        keys=[episode_start_dt],\n",
    "        names=[\"episodestart\"],\n",
    "    )\n",
    "\n",
    "    episode = pd.concat([episode], keys=[driver_str], names=[\"driver\"])\n",
    "    episode = pd.concat([episode], keys=[truck_str], names=[\"vehicle\"])\n",
    "    episode.sort_index(inplace=True)  # sorting in the time order of timestamps\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recover_episodestart_tzinfo_from_timestamp(\n",
    "    ts: pd.Timestamp, tzinfo: ZoneInfo\n",
    ") -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    recover the timezone information from the parquet folder name string\n",
    "    \"\"\"\n",
    "\n",
    "    ts = ts.tz_localize(\"UTC\").tz_convert(tzinfo)\n",
    "\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb43a1e1c00ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
