{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594f72614ab511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b163581e9a74",
   "metadata": {},
   "source": [
    "# Mongo\n",
    "\n",
    "> MongoBuffer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911c2d62d3854d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp storage.buffer.mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f6eee4cfc007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from zoneinfo import ZoneInfo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bson.codec_options import CodecOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa8c539db9230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tspace.config.db import DBConfig, db_config_servers_by_name\n",
    "from tspace.config.drivers import Driver\n",
    "from tspace.config.vehicles import Truck\n",
    "from tspace.storage.pool.mongo import MongoPool\n",
    "from tspace.data.location import locations_by_abbr\n",
    "from tspace.data.core import (\n",
    "    ObservationMeta,\n",
    "    ObservationMetaCloud,\n",
    "    ObservationMetaECU,\n",
    "    PoolQuery,\n",
    "    veos_lifetime_end_date,\n",
    "    veos_lifetime_start_date,\n",
    ")\n",
    "from tspace.data.external.pandas_utils import (\n",
    "    decode_episode_batch_to_padded_arrays,\n",
    "    decode_mongo_episodes,\n",
    "    decode_mongo_records,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61dc9b1bf64d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tspace.storage.buffer.buffer import Buffer  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dafabfaedb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass(kw_only=True)\n",
    "class MongoBuffer(Buffer[pd.DataFrame]):\n",
    "    \"\"\"\n",
    "    A Buffer connected with a MongoDB database pool\n",
    "\n",
    "    Args:\n",
    "\n",
    "        batch_size: number of documents for batch sampling\n",
    "        driver: driver of the vehicle\n",
    "        truck: subject vehicle\n",
    "        meta: metadata of the observation\n",
    "        db_config: config for mongodb (str) or DBConfig (dict)\n",
    "        the key leads to a config with db_name and collection name with a switch for record or episode:\n",
    "            - string for db server name\n",
    "            - or string of the format \"usr:password@host:port\"\n",
    "                for mongo_cluster:\n",
    "                    Host=\"10.10.0.4\",  # url for the database server\n",
    "                    port=\"23000\",  # port for the database server\n",
    "                    user_name=\"admin\",  # username for the database server\n",
    "                    password=\"ty02ydhVqDj3QFjT\",  # password for the database server\n",
    "                    ==> mongo_key = \"admin:ty02ydhVqDj3QFjT@10.10.0.4:23000\"\n",
    "        torque_table_row_names: list of torque table row names, e.g. ['r0, r1, ..., r9']\n",
    "        query: query for the pool\n",
    "        pool: pool of the database, a `MongoPool` instance\n",
    "        logger: logger for the buffer\n",
    "        dict_logger: dict logger for the buffer\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size: int  # 0\n",
    "    driver: Driver  # field(default_factory=Driver)\n",
    "    truck: Truck  # field(default_factory=Truck)\n",
    "    meta: ObservationMeta  # field(default_factory=ObservationMeta)\n",
    "    db_config: DBConfig  # db_config_default\n",
    "    torque_table_row_names: list[str]  # field(default_factory=list)\n",
    "    query: Optional[PoolQuery] = None  # field(default_factory=PoolQuery)\n",
    "    pool: Optional[MongoPool] = None  # field(default_factory=MongoPool)\n",
    "    logger: Optional[logging] = None\n",
    "    dict_logger: Optional[dict] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"set logger and load pool\"\"\"\n",
    "        self.logger = self.logger.getChild(\"main\").getChild(\"mongo buffer\")\n",
    "        self.logger.propagate = True\n",
    "        if not self.torque_table_row_names:\n",
    "            self.torque_table_row_names = self.meta.get_torque_table_row_names()\n",
    "        super().__post_init__()\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"load pool from database\"\"\"\n",
    "        if self.db_config.type == \"RECORD\":\n",
    "            self.query = PoolQuery(\n",
    "                vehicle=self.truck.vid,\n",
    "                driver=self.driver.pid,\n",
    "                episodestart_start=veos_lifetime_start_date,\n",
    "                episodestart_end=veos_lifetime_end_date,\n",
    "                timestamp_start=veos_lifetime_start_date,\n",
    "                timestamp_end=veos_lifetime_end_date,\n",
    "            )\n",
    "        else:  # type is 'EPISODE'\n",
    "            self.query = PoolQuery(\n",
    "                vehicle=self.truck.vid,\n",
    "                driver=self.driver.pid,\n",
    "                episodestart_start=veos_lifetime_start_date,\n",
    "                episodestart_end=veos_lifetime_end_date,\n",
    "                seq_len_from=0,\n",
    "                seq_len_to=int(1e9),\n",
    "            )\n",
    "\n",
    "        # MongoPool stores both record and episode data, just need to specify the query and sample\n",
    "        self.pool = MongoPool(\n",
    "            db_config=self.db_config,\n",
    "            query=self.query,\n",
    "            meta=self.meta,\n",
    "            codec_option=CodecOptions(tz_aware=True),\n",
    "            logger=self.logger,\n",
    "            dict_logger=self.dict_logger,\n",
    "        )\n",
    "\n",
    "        if self.pool.cnt != 0:\n",
    "            # check plot with input vehicle and driver\n",
    "            batch_1 = self.pool.sample(size=1, query=self.query)\n",
    "            if type(self.meta) is ObservationMetaCloud:\n",
    "                meta_in_db = ObservationMetaCloud(\n",
    "                    state_specs=batch_1[\"meta\"].iloc[0][\"state_specs\"],\n",
    "                    action_specs=batch_1[\"meta\"].iloc[0][\"action_specs\"],\n",
    "                    reward_specs=batch_1[\"meta\"].iloc[0][\"reward_specs\"],\n",
    "                    site=locations_by_abbr[batch_1[\"meta\"].iloc[0][\"site\"][\"abbr\"]],\n",
    "                )\n",
    "            elif type(self.meta) is ObservationMetaECU:\n",
    "                meta_in_db = ObservationMetaECU(\n",
    "                    state_specs=batch_1[\"meta\"].iloc[0][\"state_specs\"],\n",
    "                    action_specs=batch_1[\"meta\"].iloc[0][\"action_specs\"],\n",
    "                    reward_specs=batch_1[\"meta\"].iloc[0][\"reward_specs\"],\n",
    "                    site=locations_by_abbr[batch_1[\"meta\"].iloc[0][\"site\"][\"abbr\"]],\n",
    "                )\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    f\"meta type {type(self.meta)} not implemented\"\n",
    "                )\n",
    "            assert self.meta.have_same_meta(\n",
    "                meta_in_db\n",
    "            ), f\"meta in db is {batch_1[0].meta}, but meta in config is {self.meta}\"\n",
    "        else:\n",
    "            self.logger.warning(\n",
    "                f\"Buffer is empty, create new database, buffer_count: {self.pool.cnt}, \"\n",
    "                f\"db_config: {self.db_config}, query: {self.query}, \"\n",
    "                f\"meta: {self.meta}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "        (\n",
    "            num_states,\n",
    "            num_actions,\n",
    "        ) = self.meta.get_number_of_states_actions()  # the realtime number\n",
    "        self.logger.info(\n",
    "            f\"Connected to MongoDB {self.db_config.database_name}, \"\n",
    "            f\"collection {self.db_config.collection_name}, \"\n",
    "            f\"record number {self.pool.cnt}, \"\n",
    "            f\"num_states: {num_states}, num_actions: {num_actions}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    def decode_batch_records(\n",
    "        self, df: pd.DataFrame\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Sample a batch of records from the pool.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            df: dataframe of sampled from the record collection of the pool\n",
    "\n",
    "        Return:\n",
    "\n",
    "            A quadruple of numpy arrays (states, actions, rewards, next_states)\n",
    "        \"\"\"\n",
    "\n",
    "        df_states, df_actions, ser_rewards, df_nstates = decode_mongo_records(\n",
    "            df, self.torque_table_row_names\n",
    "        )\n",
    "\n",
    "        idx = pd.IndexSlice\n",
    "        npa_states = np.stack(\n",
    "            [\n",
    "                df_state.loc[\n",
    "                    :,  # type: ignore\n",
    "                    idx[\n",
    "                        :, :, :, :, \"state\", [\"velocity\", \"thrust\", \"brake\"]\n",
    "                    ],  # same order as inference !!!\n",
    "                ].values.T.flatten()  # transpose values array to match inference!!!\n",
    "                for df_state in df_states\n",
    "            ]\n",
    "        ).astype(np.float32)\n",
    "        npa_actions = np.stack(\n",
    "            [\n",
    "                df_action.loc[\n",
    "                    :, idx[:, :, :, :, \"action\", self.torque_table_row_names]  # type: ignore\n",
    "                ].values.T.flatten()\n",
    "                for df_action in df_actions\n",
    "            ]\n",
    "        ).astype(np.float32)\n",
    "        npa_rewards = np.stack(\n",
    "            [ser_reward.values.T.flatten() for ser_reward in ser_rewards]\n",
    "        )\n",
    "        npa_nstates = np.stack(\n",
    "            [\n",
    "                df_nstate.loc[\n",
    "                    :, idx[:, :, :, :, \"nstate\", [\"velocity\", \"thrust\", \"brake\"]]  # type: ignore\n",
    "                ].values.T.flatten()\n",
    "                for df_nstate in df_nstates\n",
    "            ]\n",
    "        ).astype(np.float32)\n",
    "        return npa_states, npa_actions, npa_rewards, npa_nstates\n",
    "\n",
    "    def sample(self) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Sampling a batch of records or episodes from the pool.\n",
    "\n",
    "        Decoding the batch observations from mongodb nested dicts to pandas dataframe\n",
    "        flatten is used to adapt to model interface\n",
    "\n",
    "        Return:\n",
    "\n",
    "            A quadruple of numpy arrays (states, actions, rewards, next_states)\n",
    "        \"\"\"\n",
    "        df = self.pool.sample(size=self.batch_size, query=self.query)\n",
    "\n",
    "        if self.db_config.type == \"RECORD\":\n",
    "            states, actions, rewards, nstates = self.decode_batch_records(df)\n",
    "        else:  # if pool collection type is EPISODE\n",
    "            df_episodes = decode_mongo_episodes(df)\n",
    "\n",
    "            df_episodes_stripped = df_episodes[[\"state\", \"action\", \"reward\", \"nstate\"]]\n",
    "            (\n",
    "                states,\n",
    "                actions,\n",
    "                rewards,\n",
    "                nstates,\n",
    "            ) = decode_episode_batch_to_padded_arrays(\n",
    "                df_episodes_stripped, self.torque_table_row_names\n",
    "            )\n",
    "\n",
    "        return states, actions, rewards, nstates\n",
    "\n",
    "    def find(self, idx):\n",
    "        \"\"\"\n",
    "        find a record by index\n",
    "        \"\"\"\n",
    "        return self.pool.find(idx)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"close the pool and the database\"\"\"\n",
    "        self.pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee24646cdafdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c041c76aec6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MongoBuffer.__post_init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e0ffca9b4a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MongoBuffer.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f102ce78da92a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MongoBuffer.find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2188b03099c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MongoBuffer.close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a322f5e85937081",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MongoBuffer.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6cc6a9c1d87029",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MongoBuffer.decode_batch_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0b832b421de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
