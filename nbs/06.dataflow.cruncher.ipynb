{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c51af1896dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28053b2e393b129b",
   "metadata": {},
   "source": [
    "# Cruncher \n",
    "\n",
    "> Cruncher class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac5a9cda665df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataflow.cruncher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9404ab92ed6f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import queue\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from threading import Event, current_thread\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3d26571c23de6",
   "metadata": {},
   "source": [
    "from tensorflow.summary import SummaryWriter, create_file_write, scalar  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e7fcc2c85ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from data_io_nbdev.dataflow.filter.homo import HomoFilter  # type: ignore\n",
    "from data_io_nbdev.dataflow.pipeline.queue import Pipeline  # type: ignore\n",
    "from data_io_nbdev.dataflow.producer import Producer  # type: ignore\n",
    "from data_io_nbdev.config.drivers import Driver\n",
    "from data_io_nbdev.config.vehicles import Truck\n",
    "from data_io_nbdev.data.external.pandas_utils import (\n",
    "    assemble_action_ser,\n",
    "    assemble_flash_table,\n",
    "    assemble_reward_ser,\n",
    "    assemble_state_ser\n",
    ")\n",
    "from data_io_nbdev.system.plot import plot_3d_figure, plot_to_image\n",
    "from eos.agent import DPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694770de22183d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Cruncher(HomoFilter[pd.DataFrame]):\n",
    "    \"\"\"\n",
    "    Cruncher is the processing unit of the data flow.\n",
    "    \n",
    "    It consumes data (pd.DataFrame) from the observe pipeline and produces data (pd.DataFrame) into the flash pipeline.\n",
    "    \n",
    "    Attributes:\n",
    "        \n",
    "        - agent: abstract base class DPG, available DDPG, RDPG\n",
    "        - truck: Truck object\n",
    "        - driver: Driver object\n",
    "        - resume: bool, whether to resume training\n",
    "        - infer_mode: bool, whether only inferring or with training and inferring \n",
    "        - data_dir: Path, the local path to save all generated data\n",
    "        - train_summary_writer: SummaryWriter, Tensorflow training writer\n",
    "        - logger: Logger\n",
    "        - dict_logger: logger format specs\n",
    "    \"\"\"\n",
    "\n",
    "    agent: DPG\n",
    "    truck: Truck\n",
    "    driver: Driver\n",
    "    resume: bool = False\n",
    "    infer_mode: bool = False\n",
    "    data_dir: Optional[Path] = None\n",
    "    train_summary_writer: Optional[tf.summary.SummaryWriter] = None  # type: ignore\n",
    "    logger: Optional[logging.Logger] = None\n",
    "    dict_logger: Optional[dict] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Set logger, Tensorflow data path and running mode\"\"\"\n",
    "        # self.logger = logger.getChild(\"eos\").getChild((self.__str__()))\n",
    "        self.logger = self.logger.getChild(self.__str__())\n",
    "        if not self.data_dir:\n",
    "            self.data_dir = Path(\".\")\n",
    "\n",
    "        tfb_path = self.data_dir.joinpath(\n",
    "            \"tf-logs-\"\n",
    "            + str(self.agent)\n",
    "            + self.truck.vid\n",
    "            + \"/gradient_tape/\"\n",
    "            + pd.Timestamp.now(tz=self.truck.site.tz).isoformat()\n",
    "            + \"/train\"\n",
    "        )\n",
    "        self.train_summary_writer = tf.summary.create_file_writer(  # type: ignore\n",
    "            str(tfb_path)\n",
    "        )\n",
    "\n",
    "        if self.resume:\n",
    "            self.logger.info(\n",
    "                f\"{{'header': 'Resume last training'}}\", extra=self.dict_logger\n",
    "            )\n",
    "        else:\n",
    "            self.logger.info(\n",
    "                f\"{{'header': 'Start from scratch'}}\", extra=self.dict_logger\n",
    "            )\n",
    "        super().__post_init__()\n",
    "        self.logger.info(\"Cruncher initialized\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"cruncher\"\n",
    "\n",
    "    def filter(\n",
    "        self,\n",
    "        in_pipeline: Pipeline[pd.DataFrame],  # input pipeline\n",
    "        out_pipeline: Pipeline[pd.DataFrame],  # output pipeline\n",
    "        start_event: Optional[Event],  # input event start\n",
    "        stop_event: Optional[Event],  # input event stop\n",
    "        interrupt_event: Optional[Event],  # input event interrupt\n",
    "        flash_event: Optional[Event],  # input event flash\n",
    "        exit_event: Optional[Event],  # input event exit\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Consume data from the pipeline\n",
    "        \n",
    "        Args:\n",
    "            in_pipeline: Pipeline, the input pipeline\n",
    "            out_pipeline: Pipeline, the output pipeline\n",
    "            start_event: Event, start event\n",
    "            stop_event: Event, stop event\n",
    "            interrupt_event: Event, interrupt event\n",
    "            flash_event: Event, flash event\n",
    "            exit_event: Event, exit event\n",
    "        \"\"\"\n",
    "        thread = current_thread()\n",
    "        thread.name = \"cruncher_consume\"\n",
    "        running_reward = 0.0\n",
    "        epi_cnt = 0\n",
    "\n",
    "        logger_cruncher_consume = self.logger.getChild(\"consume\")\n",
    "        logger_cruncher_consume.info(\n",
    "            f\"Cruncher thread starts!\", extra=self.dict_logger\n",
    "        )\n",
    "        while not exit_event.is_set():  # run until program exit\n",
    "            if (\n",
    "                (not start_event.is_set())\n",
    "                or stop_event.is_set()\n",
    "                or interrupt_event.is_set()\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            # tf.summary.trace_on(graph=True, profiler=True)\n",
    "\n",
    "            logger_cruncher_consume.info(\n",
    "                \"----------------------\", extra=self.dict_logger\n",
    "            )\n",
    "            logger_cruncher_consume.info(\n",
    "                f\"{{'header': 'episode starts!', \" f\"'episode': {epi_cnt}}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            # mongodb default to UTC time\n",
    "\n",
    "            # Get the initial motion_power data for the initial quadruple (s, a, r, s')_{-1}\n",
    "            motion_power = None\n",
    "            # if any of the following events occurs, break out of the loop\n",
    "            while not (\n",
    "                exit_event.is_set() or stop_event.is_set() or interrupt_event.is_set()\n",
    "            ):\n",
    "                try:\n",
    "                    motion_power = in_pipeline.get(block=True, timeout=10)\n",
    "                    break  # break the while loop if we get the first data\n",
    "                except TimeoutError:\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"{{'header': 'No data in the input Queue, Timeout!!!', \"\n",
    "                        f\"'episode': {epi_cnt}}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    continue\n",
    "                except queue.Empty:\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"{{'header': 'No data in the input Queue, Empty!!!', \"\n",
    "                        f\"'episode': {epi_cnt}}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "            # prime the episode\n",
    "            self.agent.start_episode(ts=pd.Timestamp.now(tz=self.truck.site.tz))\n",
    "            step_count = 0\n",
    "            episode_reward = 0.0\n",
    "            prev_timestamp = self.agent.episode_start_dt\n",
    "            assert (\n",
    "                type(motion_power) is pd.DataFrame\n",
    "            ), f\"motion_power is {type(motion_power)}, not pd.DataFrame!\"\n",
    "            prev_state, table_start = assemble_state_ser(\n",
    "                motion_power.loc[:, [\"timestep\", \"velocity\", \"thrust\", \"brake\"]],\n",
    "                tz=self.truck.site.tz,\n",
    "            )  # s_{-1}\n",
    "            zero_torque_map_line = np.zeros(\n",
    "                shape=(1, 1, self.truck.torque_flash_numel),  # [1, 1, 4*17]\n",
    "                dtype=np.float32,\n",
    "            )  # first zero last_actions is a 3D tensor\n",
    "            prev_action = assemble_action_ser(\n",
    "                torque_map_line=zero_torque_map_line,\n",
    "                torque_table_row_names=self.agent.torque_table_row_names,\n",
    "                table_start=table_start,\n",
    "                flash_start_ts=pd.to_datetime(prev_timestamp),\n",
    "                flash_end_ts=pd.Timestamp.now(self.truck.site.tz),\n",
    "                torque_table_row_num_flash=self.truck.torque_table_row_num_flash,\n",
    "                torque_table_col_num=self.truck.torque_table_col_num,\n",
    "                speed_scale=self.truck.speed_scale,\n",
    "                pedal_scale=self.truck.pedal_scale,\n",
    "                tz=self.truck.site.tz,\n",
    "            )  # a_{-1}\n",
    "            step_reward = 0.0\n",
    "            # reward is measured in next step\n",
    "\n",
    "            logger_cruncher_consume.info(\n",
    "                f\"{{'header': 'episode init done!', \" f\"'episode': {epi_cnt}}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "            flash_event.set()  # kick off the episode capturing, reactivate data_transform\n",
    "            b_flashed = False\n",
    "            tf.debugging.set_log_device_placement(True)\n",
    "            with tf.device(\"/GPU:0\"):\n",
    "                while (not stop_event.is_set()) and (\n",
    "                    not interrupt_event.is_set() and (not exit_event.is_set())\n",
    "                ):\n",
    "                    observe_pipeline_size = in_pipeline.qsize()\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"observe pipeline size: {observe_pipeline_size}\"\n",
    "                    )\n",
    "                    if observe_pipeline_size > 2:\n",
    "                        # self.logc.info(f\"motion_power_queue.qsize(): {self.motion_power_queue.qsize()}\")\n",
    "                        logger_cruncher_consume.info(\n",
    "                            f\"{{'header': 'Residue in Queue is a sign of disordered sequence, interrupted!'}}\"\n",
    "                        )\n",
    "                        interrupt_event.set()\n",
    "\n",
    "                    try:\n",
    "                        motion_power = in_pipeline.get(block=True, timeout=1.55)\n",
    "                    except TimeoutError:\n",
    "                        logger_cruncher_consume.info(\n",
    "                            f\"{{'header': 'No data in the input Queue Timeout!!!', \"\n",
    "                            f\"'episode': {epi_cnt}}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        continue\n",
    "                    except queue.Empty:\n",
    "                        logger_cruncher_consume.info(\n",
    "                            f\"{{'header': 'No data in the input Queue empty Queue!!!', \"\n",
    "                            f\"'episode': {epi_cnt}}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"{{'header': 'start', \"\n",
    "                        f\"'step': {step_count}, \"\n",
    "                        f\"'episode': {epi_cnt}}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )  # env.step(action) action is flash the vcu calibration table\n",
    "\n",
    "                    # !!!no parallel even!!!\n",
    "                    # predict action probabilities and estimated future rewards\n",
    "                    # from environment state\n",
    "                    # for causal rl, the odd indexed observation/reward are caused by last action\n",
    "                    # skip the odd indexed observation/reward for policy to make it causal\n",
    "\n",
    "                    # assemble state\n",
    "                    timestamp = motion_power.loc[\n",
    "                        0, \"timestep\"\n",
    "                    ]  # only take the first timestamp,\n",
    "                    assert isinstance(\n",
    "                        timestamp, pd.Timestamp\n",
    "                    ), \"timestamp is not pd.Timestamp!\"\n",
    "                    # as frequency is fixed at 50Hz, the rest is saved in another col\n",
    "\n",
    "                    # motion_power.loc[:, ['timestep', 'velocity', 'thrust', 'brake']]\n",
    "                    state, table_start_row = assemble_state_ser(\n",
    "                        motion_power.loc[\n",
    "                            :, [\"timestep\", \"velocity\", \"thrust\", \"brake\"]\n",
    "                        ],\n",
    "                        tz=self.truck.site.tz,\n",
    "                    )\n",
    "\n",
    "                    # assemble reward, actually the reward from last action\n",
    "                    # pow_t = motion_power.loc[:, ['current', 'voltage']]\n",
    "                    reward = assemble_reward_ser(\n",
    "                        motion_power.loc[:, [\"current\", \"voltage\"]],\n",
    "                        self.truck.observation_sampling_rate,\n",
    "                        ts=pd.Timestamp.now(tz=self.truck.site.tz),\n",
    "                    )\n",
    "                    work = reward[(\"work\", 0)]\n",
    "                    episode_reward += float(work)\n",
    "\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"{{'header': 'assembling state and reward!', \"\n",
    "                        f\"'episode': {epi_cnt}}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "\n",
    "                    #  separate the inference and flash in order to avoid the action change incurred reward noise\n",
    "                    if b_flashed is False:  # the active half step\n",
    "                        #  at step 0: [ep_start, None (use zeros), a=0, r=0, s=s_0]\n",
    "                        #  at step n: [t=t_{n-1}, s=s_{n-1}, a=a_{n-1}, r=r_{n-1}, s'=s_n]\n",
    "                        #  at step N: [t=t_{N-1}, s=s_{N-1}, a=a_{N-1}, r=r_{N-1}, s'=s_N]\n",
    "                        reward[(\"work\", 0)] = (\n",
    "                            work + step_reward\n",
    "                        )  # reward is the sum of flashed and not flashed step\n",
    "                        self.agent.deposit(\n",
    "                            prev_timestamp,\n",
    "                            prev_state,\n",
    "                            prev_action,\n",
    "                            reward,  # reward from last action\n",
    "                            state,\n",
    "                        )  # (s_{-1}, a_{-1}, r_{-1}, s_0), (s_0, a_0, r_0, s_1), ..., (s_{N-1}, a_{N-1}, r_{N-1}, s_N)\n",
    "\n",
    "                        # Inference !!!\n",
    "                        # stripping timestamps from state, (later flatten and convert to tensor)\n",
    "                        # agent return the inferred action sequence without batch and time dimension\n",
    "                        torque_table_line = self.agent.actor_predict(\n",
    "                            state[[\"velocity\", \"thrust\", \"brake\"]]\n",
    "                        )  # model input requires fixed order velocity col -> thrust col -> brake col\n",
    "                        #  !!! training with samples of the same order!!!\n",
    "                        df_torque_table = assemble_flash_table(\n",
    "                            torque_table_line,\n",
    "                            table_start_row,\n",
    "                            self.truck.torque_table_row_num_flash,\n",
    "                            self.truck.torque_table_col_num,\n",
    "                            self.truck.speed_scale,\n",
    "                            self.truck.pedal_scale,\n",
    "                        )\n",
    "\n",
    "                        logger_cruncher_consume.info(\n",
    "                            f\"{{'header': 'inference done with reduced action space!', \"\n",
    "                            f\"'episode': {epi_cnt}}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        # flash the vcu calibration table and assemble action\n",
    "                        flash_start_ts = pd.Timestamp.now(self.truck.site.tz)\n",
    "                        out_pipeline.put_data(df_torque_table)\n",
    "                        logger_cruncher_consume.info(\n",
    "                            f\"{{'header': 'Action Push table', \"\n",
    "                            f\"'StartIndex': {table_start_row}, \"\n",
    "                            f\"'qsize': {out_pipeline.qsize()}}}\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "\n",
    "                        # wait for remote flash to finish\n",
    "                        flash_event.wait()  # clear the event flag in observe thread\n",
    "                        if interrupt_event.is_set() or exit_event.is_set():\n",
    "                            continue\n",
    "\n",
    "                        logger_cruncher_consume.info(\n",
    "                            f\"{{'header': 'flash lock released!\",\n",
    "                            extra=self.dict_logger,\n",
    "                        )\n",
    "                        flash_end_ts = pd.Timestamp.now(self.truck.site.tz)\n",
    "\n",
    "                        action = assemble_action_ser(\n",
    "                            torque_table_line,\n",
    "                            self.agent.torque_table_row_names,\n",
    "                            table_start,\n",
    "                            flash_start_ts,\n",
    "                            flash_end_ts,\n",
    "                            self.truck.torque_table_row_num_flash,\n",
    "                            self.truck.torque_table_col_num,\n",
    "                            self.truck.speed_scale,\n",
    "                            self.truck.pedal_scale,\n",
    "                            self.truck.site.tz,\n",
    "                        )\n",
    "\n",
    "                        prev_timestamp = timestamp\n",
    "                        prev_state = state\n",
    "                        prev_action = action\n",
    "                        b_flashed = True\n",
    "                    else:  # if bFlashed is True, the dummy half step\n",
    "                        step_reward = float(\n",
    "                            work\n",
    "                        )  # reward from the step without flashing action\n",
    "                        flash_event.set()  # kick off the episode capturing, reactivate data_transform\n",
    "                        b_flashed = False\n",
    "\n",
    "                    # TODO add speed sum as positive reward\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"{{'header': 'Step done',\"\n",
    "                        f\"'step': {step_count}, \"\n",
    "                        f\"'episode': {epi_cnt}}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "\n",
    "                    # during odd steps, old action remains effective due to learn and flash delay\n",
    "                    # so ust record the reward history\n",
    "                    # motion states (observation) are not used later for backpropagation\n",
    "\n",
    "                    # step level\n",
    "                    step_count += 1\n",
    "\n",
    "            if (\n",
    "                interrupt_event.is_set()  # episode not DONE\n",
    "            ):  # if user interrupt prematurely or exit, then ignore back propagation since data incomplete\n",
    "                logger_cruncher_consume.info(\n",
    "                    f\"{{'header': 'interrupted, waits for next episode to kick off!' \"\n",
    "                    f\"'episode': {epi_cnt}}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                # # send ready signal to trip server\n",
    "                # if self.ui == \"mobile\":\n",
    "                #     ret = self.rmq_producer.send_sync(self.rmq_message_ready)\n",
    "                #     logger_cruncher_consume.info(\n",
    "                #         f\"{{'header': 'Sending ready signal to trip server', \"\n",
    "                #         f\"'status': '{ret.status}', \"\n",
    "                #         f\"'msg-id': '{ret.msg_id}', \"\n",
    "                #         f\"'offset': '{ret.offset}'}}\",\n",
    "                #         extra=self.dict_logger,\n",
    "                #     )\n",
    "                epi_cnt += 1\n",
    "                continue  # otherwise assuming the history is valid and back propagate\n",
    "\n",
    "            self.agent.end_episode()  # deposit history\n",
    "\n",
    "            logger_cruncher_consume.info(\n",
    "                f\"{{'header': 'Episode end.', \"\n",
    "                f\"'episode': '{epi_cnt}', \"\n",
    "                f\"'timestamp': '{datetime.now(self.truck.site.tz)}'}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "            critic_loss = 0\n",
    "            actor_loss = 0\n",
    "            if self.infer_mode:\n",
    "                (critic_loss, actor_loss) = self.agent.get_losses()\n",
    "                # FIXME bugs in maximal sequence length for ungraceful testing\n",
    "                # self.logc.info(\"Nothing to be done for rdpg!\")\n",
    "                logger_cruncher_consume.info(\n",
    "                    \"{{'header': 'No Learning, just calculating loss.'}}\"\n",
    "                )\n",
    "            else:\n",
    "                logger_cruncher_consume.info(\n",
    "                    \"{{'header': 'Learning and updating 6 times!'}}\"\n",
    "                )\n",
    "\n",
    "                # self.logger.info(f\"BP{k} starts.\", extra=self.dict_logger)\n",
    "                if self.agent.buffer.pool.cnt > 0:\n",
    "                    for k in range(6):\n",
    "                        (critic_loss, actor_loss) = self.agent.train()\n",
    "                        self.agent.soft_update_target()\n",
    "                else:\n",
    "                    logger_cruncher_consume.info(\n",
    "                        f\"{{'header': 'Buffer empty, no learning!'}}\",\n",
    "                        extra=self.dict_logger,\n",
    "                    )\n",
    "                    logger_cruncher_consume.info(\n",
    "                        \"++++++++++++++++++++++++\", extra=self.dict_logger\n",
    "                    )\n",
    "                # Checkpoint manager save model\n",
    "                self.agent.save_ckpt()\n",
    "\n",
    "            logger_cruncher_consume.info(\n",
    "                f\"{{'header': 'losses after 6 times BP', \"\n",
    "                f\"'episode': {epi_cnt}, \"\n",
    "                f\"'critic loss': {critic_loss}, \"\n",
    "                f\"'actor loss': {actor_loss}}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "            # update running reward to check condition for solving\n",
    "            running_reward = 0.05 * (-episode_reward) + (1 - 0.05) * running_reward\n",
    "\n",
    "            # Create a matplotlib 3d figure for the last table, //export and save in log\n",
    "            fig = plot_3d_figure(df_torque_table)\n",
    "\n",
    "            # tf logging after episode ends\n",
    "            # use local episode counter epi_cnt_local tf.summary.writer;\n",
    "            # otherwise specify multiple self.logdir and automatic switch\n",
    "            with self.train_summary_writer.as_default():\n",
    "                tf.summary.scalar(\"WH\", -episode_reward, step=epi_cnt)\n",
    "                tf.summary.scalar(\"actor loss\", actor_loss, step=epi_cnt)\n",
    "                tf.summary.scalar(\"critic loss\", critic_loss, step=epi_cnt)\n",
    "                tf.summary.scalar(\"reward\", episode_reward, step=epi_cnt)\n",
    "                tf.summary.scalar(\"running reward\", running_reward, step=epi_cnt)\n",
    "                tf.summary.image(\"Calibration Table\", plot_to_image(fig), step=epi_cnt)\n",
    "                tf.summary.histogram(\n",
    "                    \"Calibration Table Hist\",\n",
    "                    df_torque_table.values,\n",
    "                    step=epi_cnt,\n",
    "                )\n",
    "                # tf.summary.trace_export(\n",
    "                #     name=\"veos_trace\", step=epi_cnt_local, profiler_out_dir=train_log_dir\n",
    "                # )\n",
    "\n",
    "            plt.close(fig)\n",
    "\n",
    "            logger_cruncher_consume.info(\n",
    "                f\"{{'episode': {epi_cnt}, \" f\"'reward': {episode_reward}}}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "            logger_cruncher_consume.info(\n",
    "                \"----------------------\", extra=self.dict_logger\n",
    "            )\n",
    "            if epi_cnt % 10 == 0:\n",
    "                logger_cruncher_consume.info(\n",
    "                    \"++++++++++++++++++++++++\", extra=self.dict_logger\n",
    "                )\n",
    "                logger_cruncher_consume.info(\n",
    "                    f\"{{'header': 'Running reward': {running_reward:.2f}, \"\n",
    "                    f\"'episode': '{epi_cnt}'}}\",\n",
    "                    extra=self.dict_logger,\n",
    "                )\n",
    "                logger_cruncher_consume.info(\n",
    "                    \"++++++++++++++++++++++++\", extra=self.dict_logger\n",
    "                )\n",
    "\n",
    "            epi_cnt += 1\n",
    "        # TODO terminate condition to be defined: reward > limit (percentage); time too long\n",
    "        # with self.train_summary_writer.as_default():\n",
    "        #     tf.summary.trace_export(\n",
    "        #         name=\"veos_trace\",\n",
    "        #         step=epi_cnt_local,\n",
    "        #         profiler_out_dir=self.train_log_dir,\n",
    "        #     )\n",
    "\n",
    "        self.agent.buffer.close()\n",
    "        plt.close(fig=\"all\")\n",
    "\n",
    "        logger_cruncher_consume.info(\n",
    "            f\"{{'header': 'Close Buffer, pool!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "        logger_cruncher_consume.info(\n",
    "            f\"{{'header': 'crunch thread dies!!!!'}}\", extra=self.dict_logger\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1678f56a0a69e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1935180d7b26b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cruncher.__post_init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee1d17a227bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Cruncher.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748147685e166f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
