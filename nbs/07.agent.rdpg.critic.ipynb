{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835970cab4923adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e1ec7eebc59e1",
   "metadata": {},
   "source": [
    "# SeqCritic\n",
    "\n",
    "> Sequential Critic class with LSTM layers for RDPG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b60ddab86ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agent.rdpg.seq_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4556fa4f6369a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from typing import ClassVar, Optional\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f3cb1e8e02a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from data_io_nbdev.agent.utils.hyperparams import HyperParamRDPG\n",
    "from data_io_nbdev.system.exception import ReadOnlyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc9728638caf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeqCritic:\n",
    "    \"\"\"Sequential Critic network for the RDPG algorithm.\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "        state_dim (int): Dimension of the state space.\n",
    "        action_dim (int): Dimension of the action space.\n",
    "        hidden_dim (int): Dimension of the hidden layer.\n",
    "        n_layers (int): Number of layers in the network.\n",
    "        batch_size (int): Batch size for the network.\n",
    "        padding_value (float): Value to pad the input with.\n",
    "        tau (float): Soft update parameter.\n",
    "        lr (float): Learning rate for the network.\n",
    "        ckpt_dir (str): Directory to restore the checkpoint from.\n",
    "        ckpt_interval (int): Interval to save the checkpoint.\n",
    "        logger (logging.Logger): Logger for the class.\n",
    "        dict_logger (dict): Dictionary to log the class.\n",
    "    \"\"\"\n",
    "\n",
    "    _hyperparams: ClassVar[\n",
    "        HyperParamRDPG\n",
    "    ] = HyperParamRDPG()  # for tf.function to get truck signal properties\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int = 0,  # dimension of the state space, 600 for cloud, 90 for kvaser\n",
    "        action_dim: int = 0,  # dimension of the action space, 68 for both cloud and kvaser\n",
    "        hidden_dim: int = 0,  # dimension of the hidden layer\n",
    "        n_layers: int = 0,  # layer number of the lstm\n",
    "        batch_size: int = 0,  # batch size for the network\n",
    "        padding_value: float = 0.0,  # value to pad the input with\n",
    "        tau: float = 0.0,  # soft update parameter $\\tau$\n",
    "        lr: float = 0.0,  # learning rate for the network\n",
    "        ckpt_dir: Path = Path(\".\"),  # directory to restore the checkpoint from\n",
    "        ckpt_interval: int = 0,  # interval to save the checkpoint\n",
    "        logger: Optional[logging.Logger] = None,  # logger for the class\n",
    "        dict_logger: Optional[dict] = None,  # format specs to log the class\n",
    "    ):\n",
    "        \"\"\"Initialize the critic network.\n",
    "\n",
    "        restore checkpoint from the provided directory if it exists,\n",
    "        initialize otherwise.\n",
    "        Args:\n",
    "            state_dim (int): Dimension of the state space.\n",
    "            action_dim (int): Dimension of the action space.\n",
    "            hidden_dim (int): Dimension of the hidden layer.\n",
    "            lr (float): Learning rate for the network.\n",
    "            ckpt_dir (str): Directory to restore the checkpoint from.\n",
    "        \"\"\"\n",
    "\n",
    "        self._state_dim = state_dim\n",
    "        self._action_dim = action_dim\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._n_layers = n_layers\n",
    "        self._lr = lr\n",
    "        self._tau = tau\n",
    "        self._padding_value = padding_value\n",
    "        self.logger = logger\n",
    "        self.dict_logger = dict_logger\n",
    "\n",
    "        states = keras.layers.Input(\n",
    "            batch_shape=(batch_size, None, state_dim), name=\"states\"\n",
    "        )\n",
    "        last_actions = keras.layers.Input(\n",
    "            batch_shape=(batch_size, None, action_dim), name=\"last_actions\"\n",
    "        )\n",
    "        actions = keras.layers.Input(\n",
    "            batch_shape=(batch_size, None, action_dim), name=\"actions\"\n",
    "        )\n",
    "        # concatenate state and action along the feature dimension\n",
    "        # both state and action are from padded minibatch, only for training\n",
    "        inputs_state_action = keras.layers.Concatenate(axis=-1)(\n",
    "            [states, last_actions, actions]\n",
    "        )  # feature dimension would be [states + actions + actions],\n",
    "        # where the first two tensor are the updates to states, Q(h_t, a_t),\n",
    "        # the last one is the current action before the env update\n",
    "\n",
    "        # attach mask to the inputs, & apply recursive lstm layer to the output\n",
    "        x = keras.layers.Masking(\n",
    "            mask_value=self.padding_value,\n",
    "            input_shape=(batch_size, None, state_dim + 2 * action_dim),\n",
    "        )(\n",
    "            inputs_state_action\n",
    "        )  # input (observation) padded with -10000.0\n",
    "\n",
    "        x = keras.layers.Dense(hidden_dim, activation=\"relu\")(\n",
    "            x\n",
    "        )  # linear layer to map [states, last actions, current cations] to [hidden dim]\n",
    "\n",
    "        # if n_layers <= 1, the loop will be skipped in default\n",
    "        for i in range(n_layers - 1):\n",
    "            x = keras.layers.LSTM(\n",
    "                hidden_dim,\n",
    "                batch_input_shape=(batch_size, None, hidden_dim),\n",
    "                return_sequences=True,\n",
    "                return_state=False,\n",
    "                stateful=True,  # stateful for batches of long sequences, and inference with single time step\n",
    "                name=f\"lstm_{i}\",\n",
    "            )(x)\n",
    "\n",
    "        lstm_output = keras.layers.LSTM(\n",
    "            hidden_dim,\n",
    "            batch_input_shape=(batch_size, None, hidden_dim),\n",
    "            return_sequences=True,\n",
    "            return_state=False,\n",
    "            stateful=True,\n",
    "            name=f\"lstm_{n_layers - 1}\",\n",
    "        )(\n",
    "            x\n",
    "        )  # stateful for batches of long sequences, and inference with single time step\n",
    "\n",
    "        critic_output = keras.layers.Dense(1, activation=None)(lstm_output)\n",
    "\n",
    "        self.eager_model = tf.keras.Model(\n",
    "            inputs=[states, last_actions, actions], outputs=critic_output\n",
    "        )\n",
    "\n",
    "        self.eager_model.summary()\n",
    "        # self.graph_model = tf.function(self.eager_model)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "        # restore the checkpoint if it exists\n",
    "        self.ckpt_dir = ckpt_dir\n",
    "        self._ckpt_interval = ckpt_interval\n",
    "        self.ckpt = tf.train.Checkpoint(\n",
    "            step=tf.Variable(tf.constant(1), name=\"step\"),\n",
    "            optimizer=self.optimizer,\n",
    "            net=self.eager_model,\n",
    "        )\n",
    "        self.ckpt_manager = tf.train.CheckpointManager(\n",
    "            self.ckpt, self.ckpt_dir, max_to_keep=10\n",
    "        )\n",
    "        self.ckpt.restore(self.ckpt_manager.latest_checkpoint)\n",
    "        if self.ckpt_manager.latest_checkpoint:\n",
    "            self.logger.info(\n",
    "                f\"Restored actor from {self.ckpt_manager.latest_checkpoint}\",\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "        else:\n",
    "            logger.info(f\"Critic Initializing from scratch\", extra=self.dict_logger)\n",
    "\n",
    "    def clone_weights(self, moving_net):\n",
    "        \"\"\"Clone weights from a model to another model.\"\"\"\n",
    "        self.eager_model.set_weights(moving_net.eager_model.get_weights())\n",
    "\n",
    "    def soft_update(self, moving_net):\n",
    "        \"\"\"Update the target critic weights.\"\"\"\n",
    "        self.eager_model.set_weights(\n",
    "            [\n",
    "                self.tau * w + (1 - self.tau) * w_t\n",
    "                for w, w_t in zip(\n",
    "                    moving_net.eager_model.get_weights(),\n",
    "                    self.eager_model.get_weights(),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def save_ckpt(self):\n",
    "        \"\"\"Save the checkpoint.\"\"\"\n",
    "        self.ckpt.step.assign_add(1)  # type: ignore\n",
    "        if int(self.ckpt.step) % self.ckpt_interval == 0:  # type: ignore\n",
    "            save_path = self.ckpt_manager.save()\n",
    "            self.logger.info(\n",
    "                f\"Saved ckpt for step {int(self.ckpt.step)}: {save_path}\",  # type: ignore\n",
    "                extra=self.dict_logger,\n",
    "            )\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[\n",
    "            tf.TensorSpec(\n",
    "                shape=[None, None, _hyperparams.NStates], dtype=tf.float32\n",
    "            ),  # [None, None, 600] for cloud / [None, None, 90] for kvaser  states\n",
    "            tf.TensorSpec(\n",
    "                shape=[None, None, _hyperparams.NActions], dtype=tf.float32\n",
    "            ),  # [None, None, 68] for both cloud and kvaser  last_actions\n",
    "            tf.TensorSpec(\n",
    "                shape=[None, None, _hyperparams.NActions], dtype=tf.float32\n",
    "            ),  # [None, None, 68] for both cloud and kvaser  actions\n",
    "        ]\n",
    "    )\n",
    "    def evaluate_q(self, states, last_actions, actions):\n",
    "        \"\"\"Evaluate the action value given the state and action\n",
    "\n",
    "        Args:\n",
    "\n",
    "            states (np.array): State in a minibatch\n",
    "            last_actions (np.array): Action in a minibatch\n",
    "            actions (np.array): Action in a minibatch\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            np.array: Q-value\n",
    "        \"\"\"\n",
    "        return self.eager_model([states, last_actions, actions])\n",
    "\n",
    "    @property\n",
    "    def state_dim(self):\n",
    "        return self._state_dim\n",
    "\n",
    "    @state_dim.setter\n",
    "    def state_dim(self, value):\n",
    "        raise ReadOnlyError(\"state_dim is read-only\")\n",
    "\n",
    "    @property\n",
    "    def action_dim(self):\n",
    "        return self._action_dim\n",
    "\n",
    "    @action_dim.setter\n",
    "    def action_dim(self, value):\n",
    "        raise ReadOnlyError(\"action_dim is read-only\")\n",
    "\n",
    "    @property\n",
    "    def hidden_dim(self):\n",
    "        return self._hidden_dim\n",
    "\n",
    "    @hidden_dim.setter\n",
    "    def hidden_dim(self, value):\n",
    "        raise ReadOnlyError(\"hidden_dim is read-only\")\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, value):\n",
    "        raise ReadOnlyError(\"lr is read-only\")\n",
    "\n",
    "    @property\n",
    "    def padding_value(self):\n",
    "        return self._padding_value\n",
    "\n",
    "    @padding_value.setter\n",
    "    def padding_value(self, value):\n",
    "        raise ReadOnlyError(\"padding_value is read-only\")\n",
    "\n",
    "    @property\n",
    "    def n_layers(self):\n",
    "        return self._n_layers\n",
    "\n",
    "    @n_layers.setter\n",
    "    def n_layers(self, value):\n",
    "        raise ReadOnlyError(\"n_layers is read-only\")\n",
    "\n",
    "    @property\n",
    "    def tau(self):\n",
    "        return self._tau\n",
    "\n",
    "    @tau.setter\n",
    "    def tau(self, value):\n",
    "        raise ReadOnlyError(\"tau is read-only\")\n",
    "\n",
    "    @property\n",
    "    def ckpt_interval(self):\n",
    "        return self._ckpt_interval\n",
    "\n",
    "    @ckpt_interval.setter\n",
    "    def ckpt_interval(self, value):\n",
    "        raise ReadOnlyError(\"ckpt_interval is read-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70aae41ce3be185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faedf1382957a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeqCritic.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dafaadd1381a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeqCritic.clone_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd029a71b12f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeqCritic.soft_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2aa88cafa4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeqCritic.save_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f94c129ff8a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeqCritic.evaluate_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c2d1e6c40da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
