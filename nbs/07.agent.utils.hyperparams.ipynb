{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fef710e7f5e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc857a6304032e23",
   "metadata": {},
   "source": [
    "# Hyperparameters \n",
    "\n",
    "> HyperParameter classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b94302c94882c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agent.utils.hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83573bb756f3ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from typing import TypeVar\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94619310036233dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from data_io_nbdev.config.vehicles import trucks_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143df1d3ba62a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# default_truck = trucks_by_id['default']\n",
    "default_truck = trucks_by_id[\"VB7_FIELD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9c6419bfb2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HyperParamDPG(BaseModel):\n",
    "    \"\"\"\n",
    "    Generic Hyperparameters for the RL agent\n",
    "\n",
    "    Attributes:\n",
    "    \n",
    "        - BatchSize: int = 4  # batch size for training\n",
    "        - NStates: int = (\n",
    "            default_truck.observation_numel\n",
    "        )  # number of states in the state space\n",
    "        - NActions: int = (\n",
    "            default_truck.torque_flash_numel\n",
    "        )  # number of actions in the action space\n",
    "        - ActionBias: float = 0.0  # bias for action output\n",
    "        - NLayerActor: int = 2  # number of layers for the actor network\n",
    "        - NLayerCritic: int = 2  # number of layers for the critic network\n",
    "        - Gamma: float = 0.99  # Gamma value for RL discount\n",
    "        - TauActor: float = 0.005  # Tau value for Polyak averaging for the actor network\n",
    "        - TauCritic: float = 0.005  # Tau value for Polyak averaging for the actor network\n",
    "        - ActorLR: float = 0.001  # learning rate for the actor network\n",
    "        - CriticLR: float = 0.002  # learning rate for the critic network\n",
    "        - CkptInterval: int = 5  # checkpoint interval\n",
    "    \"\"\"\n",
    "    BatchSize: int = 4  # batch size for training\n",
    "    NStates: int = (\n",
    "        default_truck.observation_numel\n",
    "    )  # number of states in the state space\n",
    "    NActions: int = (\n",
    "        default_truck.torque_flash_numel\n",
    "    )  # number of actions in the action space\n",
    "    ActionBias: float = 0.0  # bias for action output`\n",
    "    NLayerActor: int = 2  # number of layers for the actor network\n",
    "    NLayerCritic: int = 2  # number of layers for the critic network\n",
    "    Gamma: float = 0.99  # Gamma value for RL discount\n",
    "    TauActor: float = 0.005  # Tau value for Polyak averaging for the actor network\n",
    "    TauCritic: float = 0.005  # Tau value for Polyak averaging for the actor network\n",
    "    ActorLR: float = 0.001  # learning rate for the actor network\n",
    "    CriticLR: float = 0.002  # learning rate for the critic network\n",
    "    CkptInterval: int = 5  # checkpoint interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c210c7a048be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HyperParamDDPG(HyperParamDPG):\n",
    "    \"\"\"\n",
    "    Hyperparameters for the DDPG agent\n",
    "    \n",
    "    \n",
    "    Attributes:\n",
    "        \n",
    "        - CriticStateInputDenseDimension1: int = (\n",
    "            16  # output dimension for the state input (first) Dense layer\n",
    "        )\n",
    "        - CriticStateInputDenseDimension2: int = (\n",
    "            32  # output dimension for the state input second Dense layer\n",
    "        )\n",
    "        - CriticActionInputDenseDimension: int = (\n",
    "            32  # output dimension for the action input Dense layer\n",
    "        )\n",
    "        - CriticOutputDenseDimension1: int = (\n",
    "            256  # output dimension for the first critic output Dense layer\n",
    "        )\n",
    "        - CriticOutputDenseDimension2: int = (\n",
    "            256  # output dimension for the second critic output Dense layer\n",
    "        )\n",
    "        - ActorInputDenseDimension1: int = (\n",
    "            256  # output dimension for the first actor input Dense layer\n",
    "        )\n",
    "        - ActorInputDenseDimension2: int = (\n",
    "            256  # output dimension for the second actor input Dense layer\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    CriticStateInputDenseDimension1: int = (\n",
    "        16  # output dimension for the state input (first) Dense layer\n",
    "    )\n",
    "    CriticStateInputDenseDimension2: int = (\n",
    "        32  # output dimension for the state input second Dense layer\n",
    "    )\n",
    "    CriticActionInputDenseDimension: int = (\n",
    "        32  # output dimension for the action input Dense layer\n",
    "    )\n",
    "    CriticOutputDenseDimension1: int = (\n",
    "        256  # output dimension for the first critic output Dense layer\n",
    "    )\n",
    "    CriticOutputDenseDimension2: int = (\n",
    "        256  # output dimension for the second critic output Dense layer\n",
    "    )\n",
    "    ActorInputDenseDimension1: int = (\n",
    "        256  # output dimension for the first actor input Dense layer\n",
    "    )\n",
    "    ActorInputDenseDimension2: int = (\n",
    "        256  # output dimension for the second actor input Dense layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed8636d593c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HyperParamRDPG(HyperParamDPG):\n",
    "    \"\"\"\n",
    "    Hyperparameters for the RDPG agent\n",
    "    \n",
    "    Attributes:\n",
    "        \n",
    "        - HiddenDimension: int = 256  # hidden unit number for the action input layer\n",
    "        - PaddingValue: float = (\n",
    "            -10000\n",
    "        )  # padding value for the input, impossible value for observation, action or reward\n",
    "        - tbptt_k1: int = 200  # truncated backpropagation through time: forward steps,\n",
    "        - tbptt_k2: int = 200  # truncated backpropagation through time: backward steps\n",
    "    \"\"\"\n",
    "\n",
    "    HiddenDimension: int = 256  # hidden unit number for the action input layer\n",
    "    PaddingValue: float = (\n",
    "        -10000\n",
    "    )  # padding value for the input, impossible value for observation, action or reward\n",
    "    tbptt_k1: int = 200  # truncated backpropagation through time: forward steps,\n",
    "    # example: 100*4s=400s (6min40s), 200*4s=800s (13min20s) 400*4s=1600s (26min40s)\n",
    "    tbptt_k2: int = 200  # truncated backpropagation through time: backward steps,\n",
    "    # Note: keras only support k1=k2, ignite support k1!=k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c3449465eab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "HyperParam = TypeVar(\"HyperParam\", HyperParamDDPG, HyperParamRDPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8a9c9fb0172ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
